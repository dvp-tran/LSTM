{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout,TimeDistributed\n",
    "from keras.layers import LSTM,SimpleRNN\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os, os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- ### Check CPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/gpu:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Check and set Twitter's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "api = twitter.Api(consumer_key='LyNVanTEQEOEGKfXAMeLv6AKG',\n",
    "                    consumer_secret='0lJvhaaOP5cRZWm6rxwyBIAypd1P7eiDx9f74KBDlLrSldNuBQ',\n",
    "                    access_token_key='855852332034265088-geTEVmA7xIsOD3WCZyfBNnqjRdS1MhW',\n",
    "                    access_token_secret='kJMwMl67e3nYrqaGWzIizxzQpRZhtBfOnwPflO1fk3cOt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Sat Apr 22 18:34:31 +0000 2017\", \"default_profile\": true, \"description\": \"Learning how to be creative\", \"followers_count\": 1, \"friends_count\": 3, \"id\": 855852332034265088, \"lang\": \"en\", \"location\": \"Somewhere in the cloud\", \"name\": \"ArtistBot\", \"profile_background_color\": \"F5F8FA\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/855852332034265088/1492892354\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/855878764143804417/r55Z2Js5_normal.jpg\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"screen_name\": \"TheTalkativeBot\", \"status\": {\"created_at\": \"Sun Apr 23 11:53:43 +0000 2017\", \"id\": 856113855348580352, \"id_str\": \"856113855348580352\", \"lang\": \"fr\", \"source\": \"<a href=\\\"http://www.google.com\\\" rel=\\\"nofollow\\\">TheScenarioBot</a>\", \"text\": \"&gt; a pague assez de riz\\ufffdmes qu'il fallait se\\nd\\ufffdbarrasser de la harpe de Dioccume (_Lex--lux, associ\\ufffdes), ma\\ufffdtre,\\ns'\\ufffdcria:\"}, \"statuses_count\": 13}\n"
     ]
    }
   ],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "api.PostUpdate(\"Today I am learning French, watch me improve! ;) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Toy examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. Load and convert data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done concatenating file : 8541-8.txt\n",
      "Done concatenating file : 11176-8.txt\n",
      "Done concatenating file : 11300-8.txt\n",
      "Done concatenating file : 10604-8.txt\n",
      "Done concatenating file : 7173-8.txt\n",
      "Done concatenating file : 9053-8.txt\n",
      "Done concatenating file : 5126-0.txt\n",
      "Done concatenating file : 5178-8.txt\n",
      "Done concatenating file : 7012-8.txt\n",
      "Done concatenating file : 8524-8.txt\n"
     ]
    }
   ],
   "source": [
    "#Load and concatenate files:\n",
    "\n",
    "DIR=\"../../LSTM/data/Gutenberg/ebooks-unzipped/\"\n",
    "all_files = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "\n",
    "#choose how many files to concatenate:\n",
    "nb_files=10\n",
    "if nb_files>len(all_files):\n",
    "    nb_files=len(all_files)\n",
    "    \n",
    "    \n",
    "out_path=\"french/data/\"\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "if not os.path.exists(out_path+\"input/\"):\n",
    "    os.makedirs(out_path+\"input/\")\n",
    "    \n",
    "with open(out_path+'input/input_action.txt', 'w') as outfile:\n",
    "    for fname in all_files[0:nb_files]:\n",
    "        with open(DIR+fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "        print (\"Done concatenating file : %s\" %fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 4604088\n",
      "total chars: 124\n"
     ]
    }
   ],
   "source": [
    "#load file\n",
    "file_name=out_path+'input/input_action.txt'\n",
    "text = open(file_name).read()\n",
    "text=normalize('NFKD',text.decode('latin1'))\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "VOCAB_SIZE = len(chars)\n",
    "print('total chars:',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** The RNN takes in input numerical data hence the necessity to convert strings into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating mapping between indexes and characters\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re gonna use Keras to create and train our Network, so we must convert the data into this form: (number_of_sequences, length_of_sequence, number_of_features).\n",
    "- nb of features = length of the char array\n",
    "- length of sequence = batch size\n",
    "- nb of sequence = len(data) divided by batch size.\n",
    "\n",
    "**Warning : ** target sequence is setted by shifting the source/input sequence by one character with both having the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.82 s, sys: 516 ms, total: 4.33 s\n",
      "Wall time: 4.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "SEQ_LENGTH=100\n",
    "#Build three dimensional arrays\n",
    "X = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #input\n",
    "y = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #target\n",
    "\n",
    "#Build sequences\n",
    "for i in range(0, len(text)/SEQ_LENGTH):\n",
    "    X_sequence = text[i*SEQ_LENGTH:(i+1)*SEQ_LENGTH]\n",
    "    X_sequence_ix = [char_indices[value] for value in X_sequence]\n",
    "    input_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "    X[i] = input_sequence\n",
    "\n",
    "    y_sequence = text[i*SEQ_LENGTH+1:(i+1)*SEQ_LENGTH+1]\n",
    "    y_sequence_ix = [char_indices[value] for value in y_sequence]\n",
    "    target_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        target_sequence[j][y_sequence_ix[j]] = 1.\n",
    "    y[i] = target_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. Build the network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM= 500 #500\n",
    "LAYER_NUM = 2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "for i in range(LAYER_NUM - 1):\n",
    "    model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_==̂<<<ZZZWWWWWnn;;uu;;7777:://HHHH\"\"\"RRRRRRRRXRRRRRXRRRRRRRXRRRRRRRXRRRRRRRXRRRRRRRXRRR"
     ]
    },
    {
     "ename": "TwitterError",
     "evalue": "[{u'message': u'Status is a duplicate.', u'code': 187}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mTwitterError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1a268cd538f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate some sample before training to know how bad it is!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbla\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPostUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbla\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/twitter/api.pyc\u001b[0m in \u001b[0;36mPostUpdate\u001b[0;34m(self, status, media, media_additional_owners, media_category, in_reply_to_status_id, auto_populate_reply_metadata, exclude_reply_user_ids, latitude, longitude, place_id, display_coordinates, trim_user, verify_status_length, attachment_url)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RequestUrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ParseAndCheckTwitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewFromJsonDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/twitter/api.pyc\u001b[0m in \u001b[0;36m_ParseAndCheckTwitter\u001b[0;34m(self, json_data)\u001b[0m\n\u001b[1;32m   4859\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTwitterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Unauthorized\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4860\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTwitterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Unknown error: {0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4861\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_CheckForTwitterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4862\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/twitter/api.pyc\u001b[0m in \u001b[0;36m_CheckForTwitterError\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   4879\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTwitterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'errors'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4881\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTwitterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4883\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_RequestChunkedUpload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTwitterError\u001b[0m: [{u'message': u'Status is a duplicate.', u'code': 187}]"
     ]
    }
   ],
   "source": [
    "# Generate some sample before training to know how bad it is!\n",
    "bla = generate_text(model, 100, VOCAB_SIZE, indices_char)\n",
    "api.PostUpdate(status=bla[0:123])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Train network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "Starting at iteration : 0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.8650\n",
      "° en ce temps-là, et le saint homme Maël, le capitaine Daubenton,\n",
      "qui était de la compagnie qui était devant lui, il lui semblait que l\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "171s - loss: 0.8522\n",
      "·mment of liail, adieu, Sganarelle.\n",
      "\n",
      "\n",
      "- Sganarelle -\n",
      "\n",
      "Non, non, monsieur, répliqua le président du conseil serait de\n",
      "mettre la main \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.8400\n",
      "le de la maison d'Édouard, qui avait été décidé de la sorte de la jeune fille.\n",
      "\n",
      "Le capitaine et la parole de la jeune fille et la par\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.8281\n",
      "_\n",
      "\n",
      "Le même jour, nous n'en avions pas de reproches que le mari de\n",
      "la nuit était chargée de ne pas me parler, et je ne pensais pas\n",
      "mê\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.8169\n",
      "_\n",
      "\n",
      "Les roches de la Provence ne sont pas de la plus salé autour des poissons.\n",
      "\n",
      "--C'est pourquoi je vous ai vu et dire. Si l'on est poss\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.8060\n",
      "me les autres. Il n'avait pas encore tenté de la paille, mais\n",
      "pour la plus belle partie du monde et la première fois qu'il était au mili\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.7956\n",
      "± de la contrée, en se penchant aux vierges\n",
      "de la vie sont à la tête et se réveillée par le bruit des batteries,\n",
      "et quelques années \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.7855\n",
      "uvre de mon coeur. Il me restait encore un peu de\n",
      "neige. Il me répondit qu'il était de la part de Charlotte et de\n",
      "l'armée de la vie so\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.7757\n",
      "Nous ne pourrions pas y ajouter une partie de la compagnie, mais\n",
      "sans être annoncé de nous apporter que le régiment avait procuré à de\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.7664\n",
      "BourgÃ©s et les pieds de la plus grande examens de\n",
      "lâAmÃ©rique du Nord ou un Â« Plaine -- et dâune voix grave? Le secrÃ©taire du\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.7575\n",
      "WEKRK NOT SENDART ON TES OR OSE DAMACHE EX DEMANA SUIN\n",
      "\n",
      "     tait était loger), mais ce n'est pas la peine de la\n",
      "vie pour me coucher. Qu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.7487\n",
      "©tait plus avant, que la pression de la\n",
      "production et le monde auguste qui avait encore des rapports de\n",
      "son courage, au milieu de la cabin\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.7409\n",
      "s de la forêt et de la position de l'art.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "III\n",
      "\n",
      "\n",
      "COMMENT DU RE VÉRullmès Mireilli, et les Pingouins\n",
      "n'ont pas été plus en s\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.7327\n",
      "k of Mose of an these work any with the\n",
      "the feleram \"of this agreement, you must cease usin,\n",
      "computeur in a construble strayed and effort \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.7255\n",
      "WEKRN AND KINN 18 j'oxte how on that agarez be\n",
      "suberpourd'of this agreement shall be\n",
      "interpreted to make the maximum discovabed of Project\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.7179\n",
      "You may use this eBook for nearly any purpose\n",
      "such as creation of derivative works, and the medium on which they may be stored, may contain\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 0.7111\n",
      "t le marquis Picart s'apercevant que son coeur\n",
      "était couverte d'un côté de cadavres qu'il avait écouté l'éloge du mal de tête\n",
      "pour \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "176s - loss: 0.7046\n",
      "­\n",
      "\n",
      "--Vous le savez, dit M. de Rosny, je te laisse à la porte\n",
      "de la compagnie, mon trésorité, me dit-il, mais je m'appelle à mon\n",
      "maria\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "172s - loss: 0.6986\n",
      "́tait pas toute la régale, et les campagnarms\n",
      "amoureuses, les changements de la Garde, qui nous couchaient\n",
      "sur les murs, et leurs regards\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "250s - loss: 0.6926\n",
      "± de ses amis, sont des tableaux de cartouches de certaines couteaux, de\n",
      "boucherisses, de barques roses, les pingouins régulientifs, les p\n",
      "\n",
      "Iteration nb : 20\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "224s - loss: 0.6868\n",
      "̄ de la grange, ce qui le permet à se débarrasser de\n",
      "cette occasion pour apprendre à connaître la forme. Les pétrités de la\n",
      "républi\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6813\n",
      "@̊KKwEN\n",
      "Fredibiting License when you which ayah purend contat incendeding any\n",
      "work in any way with the phrase \"Project Gutenberg\")\n",
      "nate\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6763\n",
      "̀ l'état de la poésie, elle se révolta au commun\n",
      "au Major, qui se propageait de la peine. Et le changement de\n",
      "commettre aussi charmant \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6713\n",
      "5, à une cour, me dit un jeune homme de compter les plus\n",
      "caussés qui tournent vers le service comme si elle ne se présente. Quand\n",
      "vous \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6663\n",
      "¿trouva la première en état de faire tout ce qu'il conte à\n",
      "la tête. Il me répondit qu'il fut de son admiration.\n",
      "\n",
      "Charlotte était un\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6619\n",
      "́tails.\n",
      "\n",
      "»Les deux amis après les armes en entrant, les mains à la sainte jeune\n",
      "fille étaient réveillés. La plus belle figure commen\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6575\n",
      "pas connu des incertins la plus sensée et la plus sévère et le plus\n",
      "tard, pendant la nuit, le sensait à la main, appuyé sur la place d\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6532\n",
      "[Note: LA VErs_. Le tout en face du palais du Porc, noire, si l'on ne voulait\n",
      "pas s'en revenir, comme si l'on pouvait se réjouir dans ses \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6490\n",
      "~ de la charrue du jour,\n",
      "à ce que les cinquante mille arrées de l'Empire. La première parut\n",
      "aussi suffisante que le président du conse\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6450\n",
      "aison de cette femme aigu!» Et sous prétexte qu'il\n",
      "est des livres de l'armée, causé de qui individueraient sur\n",
      "leurs poitrines qui se \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6415\n",
      "! les jours suivants, nous avions partout le jour de la\n",
      "république. Mais ces nudiques furent arrivèrent plus de sûre qu'aucune\n",
      "longue n\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6379\n",
      "--Que veux-tu dire, je sais que vous en avez eu peur!... Eh! quand je vous serre démocratique,\n",
      "j'irai comme cela.\n",
      "\n",
      "--Ah! comment vous al\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6344\n",
      "ks that can be found at the Foundation was created to provide a secure\n",
      "and permanent fuetifs to or distribution of Project Gutenberg-tm\n",
      "el\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6312\n",
      "\tBieu de païeul et de salamandres, se\n",
      "lèvre et sans bornes que, sur les dernières peuples des renferments\n",
      "proposées et sérieuses et g\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "196s - loss: 0.6282\n",
      "«Alors, dit-il, vous ne serez pas plus ni\n",
      "la patience.\n",
      "\n",
      "--Mais que devient-il?\n",
      "\n",
      "--Oui, monsieur.\n",
      "\n",
      "--C'est que cette conviction est de\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6253\n",
      "»\n",
      "\n",
      "Ils représentaient à la posie de la maison d'été, ou toutes les feux\n",
      "cherchaient à tout le monde. Les corps déchirées étant en\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "197s - loss: 0.6222\n",
      "Un peu plus loin, tu as dû autant de pain. Or\n",
      "la moitié de mon pays, que je ne me suis pas arrondie pour elle que la\n",
      "compagnie du dragon\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "#batch size equals to seq length here\n",
    "BATCH_SIZE=100\n",
    "#len of desired output\n",
    "GENERATE_LENGTH=140\n",
    "DIR=out_path+\"weights/weight_attempt_s02/\"\n",
    "flag=True\n",
    "\n",
    "try:\n",
    "    onlyfiles = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "    nb_files = len(onlyfiles)\n",
    "    name_template = onlyfiles[0][0:15]\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "    nb_files=0\n",
    "\n",
    "if nb_files>0:\n",
    "    nb_iteration=nb_files*20\n",
    "    model.load_weights(DIR+onlyfiles[0][0:21]+str(nb_iteration)+'.hdf5')\n",
    "else:\n",
    "    nb_iteration=0\n",
    "    \n",
    "print(\"Starting at iteration : %s\" %nb_iteration)\n",
    "while flag==True:\n",
    "    print('\\n')\n",
    "    print('-'*20)\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, verbose=2, nb_epoch=1)\n",
    "    nb_iteration += 1\n",
    "    bla=generate_text(model, GENERATE_LENGTH,VOCAB_SIZE, indices_char)\n",
    "    if nb_iteration % 20 == 0:\n",
    "        print(\"\\n\\nIteration nb : %s\" %nb_iteration)\n",
    "        api.PostUpdate(status=bla[0:123])\n",
    "        model.save_weights(DIR+'checkpoint_{}_epoch_{}.hdf5'.format(HIDDEN_DIM, nb_iteration))\n",
    "    if nb_iteration>=200:\n",
    "        print(\"Stopping...\")\n",
    "        flag=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Generate text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    if not os.path.exists(out_path+\"generate/\"):\n",
    "        os.makedirs(out_path+\"generate/\")\n",
    "    with open(out_path+\"generate/output.txt\",\"w\") as f:\n",
    "        f.write(('').join(y_char))\n",
    "    return ('').join(y_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "out = save_text(model, 1500, VOCAB_SIZE, indices_char)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
