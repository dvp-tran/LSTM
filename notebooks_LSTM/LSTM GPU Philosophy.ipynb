{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout,TimeDistributed\n",
    "from keras.layers import LSTM,SimpleRNN\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os, os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- ### Check CPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/gpu:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Check and set Twitter's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "api = twitter.Api(consumer_key='LyNVanTEQEOEGKfXAMeLv6AKG',\n",
    "                    consumer_secret='0lJvhaaOP5cRZWm6rxwyBIAypd1P7eiDx9f74KBDlLrSldNuBQ',\n",
    "                    access_token_key='855852332034265088-geTEVmA7xIsOD3WCZyfBNnqjRdS1MhW',\n",
    "                    access_token_secret='kJMwMl67e3nYrqaGWzIizxzQpRZhtBfOnwPflO1fk3cOt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Sat Apr 22 18:34:31 +0000 2017\", \"default_profile\": true, \"description\": \"Learning how to be creative\", \"friends_count\": 2, \"id\": 855852332034265088, \"lang\": \"en\", \"location\": \"Somewhere in the cloud\", \"name\": \"ArtistBot\", \"profile_background_color\": \"F5F8FA\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/855852332034265088/1492892354\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/855878764143804417/r55Z2Js5_normal.jpg\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"screen_name\": \"TheTalkativeBot\", \"status\": {\"created_at\": \"Sun Apr 23 03:40:57 +0000 2017\", \"favorite_count\": 1, \"id\": 855989845294010368, \"id_str\": \"855989845294010368\", \"lang\": \"en\", \"source\": \"<a href=\\\"http://www.google.com\\\" rel=\\\"nofollow\\\">TheScenarioBot</a>\", \"text\": \"Today I am learning French, watch me improve! ;)\"}, \"statuses_count\": 2}\n"
     ]
    }
   ],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "api.PostUpdate(\"Today I am learning French, watch me improve! ;) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Toy examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. Load and convert data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done concatenating file : 8541-8.txt\n",
      "Done concatenating file : 11176-8.txt\n",
      "Done concatenating file : 11300-8.txt\n",
      "Done concatenating file : 10604-8.txt\n",
      "Done concatenating file : 7173-8.txt\n",
      "Done concatenating file : 9053-8.txt\n",
      "Done concatenating file : 5126-0.txt\n",
      "Done concatenating file : 5178-8.txt\n",
      "Done concatenating file : 7012-8.txt\n",
      "Done concatenating file : 8524-8.txt\n"
     ]
    }
   ],
   "source": [
    "#Load and concatenate files:\n",
    "\n",
    "DIR=\"../../LSTM/data/Gutenberg/ebooks-unzipped/\"\n",
    "all_files = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "\n",
    "#choose how many files to concatenate:\n",
    "nb_files=10\n",
    "if nb_files>len(all_files):\n",
    "    nb_files=len(all_files)\n",
    "    \n",
    "    \n",
    "out_path=\"french/data/\"\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "if not os.path.exists(out_path+\"input/\"):\n",
    "    os.makedirs(out_path+\"input/\")\n",
    "    \n",
    "with open(out_path+'input/input_action.txt', 'w') as outfile:\n",
    "    for fname in all_files[0:nb_files]:\n",
    "        with open(DIR+fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "        print (\"Done concatenating file : %s\" %fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 4493427\n",
      "total chars: 151\n"
     ]
    }
   ],
   "source": [
    "#load file\n",
    "file_name=out_path+'input/input_action.txt'\n",
    "text = open(file_name).read()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "VOCAB_SIZE = len(chars)\n",
    "print('total chars:',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** The RNN takes in input numerical data hence the necessity to convert strings into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating mapping between indexes and characters\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re gonna use Keras to create and train our Network, so we must convert the data into this form: (number_of_sequences, length_of_sequence, number_of_features).\n",
    "- nb of features = length of the char array\n",
    "- length of sequence = batch size\n",
    "- nb of sequence = len(data) divided by batch size.\n",
    "\n",
    "**Warning : ** target sequence is setted by shifting the source/input sequence by one character with both having the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.82 s, sys: 452 ms, total: 4.27 s\n",
      "Wall time: 4.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "SEQ_LENGTH=100\n",
    "#Build three dimensional arrays\n",
    "X = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #input\n",
    "y = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #target\n",
    "\n",
    "#Build sequences\n",
    "for i in range(0, len(text)/SEQ_LENGTH):\n",
    "    X_sequence = text[i*SEQ_LENGTH:(i+1)*SEQ_LENGTH]\n",
    "    X_sequence_ix = [char_indices[value] for value in X_sequence]\n",
    "    input_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "    X[i] = input_sequence\n",
    "\n",
    "    y_sequence = text[i*SEQ_LENGTH+1:(i+1)*SEQ_LENGTH+1]\n",
    "    y_sequence_ix = [char_indices[value] for value in y_sequence]\n",
    "    target_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        target_sequence[j][y_sequence_ix[j]] = 1.\n",
    "    y[i] = target_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. Build the network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM= 500 #500\n",
    "LAYER_NUM = 2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "for i in range(LAYER_NUM - 1):\n",
    "    model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c888___<�����BB������**������~~���VVV22nn���tNNNNNNHNNVVAAAAAAAVVAAoooo��8888����uuu��+++QQ���������"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Status(ID=855993910816124928, ScreenName=TheTalkativeBot, Created=Sun Apr 23 03:57:06 +0000 2017, Text=u'c888___&lt;\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdBB\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd**\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd~~\\ufffd\\ufffd\\ufffdVVV22nn\\ufffd\\ufffd\\ufffdtNNNNNNHNNVVAAAAAAAVVAAoooo\\ufffd\\ufffd8888\\ufffd\\ufffd\\ufffd\\ufffduuu\\ufffd\\ufffd+++QQ\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate some sample before training to know how bad it is!\n",
    "bla = generate_text(model, 100, VOCAB_SIZE, indices_char)\n",
    "api.PostUpdate(status=unicode(bla, errors='replace')[0:123])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Train network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "Starting at iteration : 0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "176s - loss: 1.2146\n",
      "� se constituer des moins de trois hommes et des champs de la chambre de la place de la ville de la ville\n",
      "de la chambre de la chambre de la\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 1.1682\n",
      "E\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CHAPITRE IV\n",
      "\n",
      "\n",
      "LES PARISIS DU LE PROJESTINGES EF LA PRESS D'ANTI DE LA PROJERT DU PORTE IV LICENTILIT DU CONSERINES\n",
      "\n",
      "\n",
      "Le roi\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "184s - loss: 1.1335\n",
      "Z se confiant de la conscience de la conscience de la conscience de la\n",
      "conscience de l'endroit o� nous �tions pr�s de l'endroit o� nous �ti\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "170s - loss: 1.1044\n",
      "� de la route, et le roi avait remarqu� quelques\n",
      "mots de fusil, et les propos de la r�publique et les plus grands de la\n",
      "propri�t� de la ro\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "169s - loss: 1.0798\n",
      "fait le plus grand point de la part du comte de Margival.\n",
      "\n",
      "--Ce sera un peu plus loin, dit le vieillard et le monde de la\n",
      "force de me lai\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "169s - loss: 1.0581\n",
      "Z se trouve dans le capital de la chambre de la compagnie, qui avait pass� la chambre � la fin de\n",
      "l'autre.\n",
      "\n",
      "\n",
      "Les hommes se tra�n�rent de\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "169s - loss: 1.0382\n",
      "[NESE DE ROULE PREMIER\n",
      "\n",
      "\n",
      "Le reste de la route de Monteux, qui avait re�u le courage de son c�t�, et qui se\n",
      "d�chira de son manteau de la \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "169s - loss: 1.0195\n",
      "= se retournant vers le carreau de la main de Marie, en se retournant dans le caf�, et que le mar�chal\n",
      "Lorsque nous f�mes arr�t�s par le ch\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "169s - loss: 1.0019\n",
      "it de la main gauche et de la main gauche et le secret de\n",
      "l'arm�e russe de la maison de la Garde, et le saint homme et le\n",
      "secret de la mai\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.9854\n",
      "Arles de Montpellier de Louis XVIII et Raimon de Paris s'�tait approuv� de la force de la personne qu'il avait encore\n",
      "le courage de la cons\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.9691\n",
      "� se retira en me disant qu'il n'en est pas de moi, je\n",
      "ne puis pas croire que le mari en particulier ne me paraissaient pas le souvenir\n",
      "de\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.9539\n",
      ", et le monde souriante qui se trouvait dans la neige qui\n",
      "avait promis de la proposition de la vie de la vie de la\n",
      "chose de sa femme et de\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.9388\n",
      "�re et le prince des Bosc�nos entra dans la ville.\n",
      "\n",
      "Le prince de l'aventure est un peu plus fort que le couteau et le plus\n",
      "intimement de \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.9243\n",
      "201, III, 120.\n",
      "\n",
      "Section 5.  General Information About Project Gutenberg-tm electronic\n",
      "works.\n",
      "\n",
      "Professor Michael S. Hart is the originat\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.9107\n",
      "_, qui d��placent le plus �� la voix de l���a��ronef.\n",
      "\n",
      "En effet, l���_Albatros_ se montrait alors sur le caisson de l���a��ronef ne\n",
      "pouva\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.8973\n",
      "�a femme de chambre qui s'en faut de saluer le soldat du conseil, et\n",
      "que celui qui nous fallait songer � la porte de la compagnie, qui �tai\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.8840\n",
      "+ et le malheur de se retirer dans son coeur.\n",
      "\n",
      "--Vous ne savez pas que cela pour moi, dit le ma�tre qui n'est\n",
      "pas �crite de mon coeur.\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.8715\n",
      "_, _Petit_, f. la lui\n",
      "dit:\n",
      "\n",
      "        (� partir)).\n",
      "\n",
      "La maison d'Entragues et la pri�re de son mari qui l'avait appris � sa propre\n",
      "indign\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.8594\n",
      "1.  If you wish to charge a fee or distribute a Project Gutenberg-tm\n",
      "electronic work or group of works on different terms than are set\n",
      "for\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.8475\n",
      "with offers to donate.\n",
      "\n",
      "International donations are gratefully accepted, but we cannot make\n",
      "any statements concerning tax treatment of do\n",
      "\n",
      "Iteration nb : 20\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.8360\n",
      "De la maison d'Entragues, et que les pr�tendus officiennes, avec leurs\n",
      "archites charg�es de pierres et de peupliers, des grenadiers, des\n",
      "a\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.8250\n",
      "ment de la paille, et il se d�cida � se\n",
      "d�cider � son ami. Sans doute, de se donner le temps de les nouvelles de\n",
      "l'arri�re-garde du prince\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.8144\n",
      "� se compl�te de prendre les deux mains de la maison. Il y avait des\n",
      "ordres que le trait de la pr�server � la pr�sence de la nature des deu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.8041\n",
      "�uvre ma�tre de la Garde, avec les premiers rayons du\n",
      "commerce et la forme d'un chasseur de la Garde, avec les premiers\n",
      "r�giments de la Ga\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.7945\n",
      "�res du Quesnoy avec une autre plaine et prisonn�e, comme les\n",
      "deux promesses qu'il avait �t� prises par les autres, et que, pour le\n",
      "moment\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.7850\n",
      "heval refusait de ne pas revenir au prince Eug�ne, remutait tout ce qui\n",
      "�tait contre nous, car il se promena de dessister sa propre pour\n",
      "d\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.7762\n",
      "/de granges de marbre se soient d�faites.\n",
      "\n",
      "Et comment aurait-il sorti de la faire comme des charles et des filles et des\n",
      "prisonniers re�u\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.7673\n",
      "; et je le sais que je suis malheureusement activement\n",
      "ce que je souffre malheureux que le mariage n'est pas celle qui nous a pris �\n",
      "parti\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.7587\n",
      "#���chelles de l���Himalaillon ��tait plus lourd que la terre de son premier\n",
      "amour dispos�� qu���il avait pris de se r��part�� dans les air\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.7509\n",
      "�t de la paille avec les autres de la maison. En me\n",
      "renvoyant, nous rencontr�mes une bonne partie de la grange, et que le\n",
      "mar�chal Oudinot\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.7433\n",
      "ant les mains de la compagnie, la police se\n",
      "plainte.\n",
      "\n",
      "-- Ah! monsieur, dit Pontis, si vous vouliez me parler et me d�couvre, et\n",
      "je comme\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.7358\n",
      "�tes sont les plus riches sentiments de la terre.\n",
      "Enfin, nous arriv�mes � l'endroit o� nous �tions pass�s, et\n",
      "c'est l� que nous nous somme\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.7289\n",
      "6), nous avons d�sign�es les premiers jours de l'arm�e, c'est-�-dire\n",
      "jour, car je ne saurais dire tout en consentant chez sa soeur,\n",
      "comme \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.7221\n",
      "gent passer la nuit. En un mot, l'artisance\n",
      "des po�tes, le conseil de la fille de Cosaque, le contre-coup\n",
      "de chagrin pour le secourir, et \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.7157\n",
      "6)\n",
      "\n",
      "En effet, si l'exp�rience avait d�j� �tans trop de vos �loquence, il ne se\n",
      "retourna pas la parole.\n",
      "\n",
      "--De quoi l'exigera cher Comoqu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.7096\n",
      "�\n",
      "\n",
      "Le pauvre diable n'en avait pas eu, sous les crocodils, se\n",
      "coulerne avec des simples s'abandonnaient en sang ou seraient mourir sur les\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.7038\n",
      "9.\n",
      "    motz pare cuder des pensarbi\n",
      "    Per que non al grattar las que�m desplaya.                                                        \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6981\n",
      "s le martyre. -- Le\n",
      "pronon�a ces mots et de terres et de terreur perdue.�\n",
      "\n",
      "Georges du Quesnoy ne s'en allait pas la connaissance de la vi\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6925\n",
      "�t�, et l'on nous fit comprendre les t�tes de la terre.\n",
      "\n",
      "-- Allez en donner comique, dit-il en lui dit :\n",
      "\n",
      "-- Ma�tre, je le crois.\n",
      "\n",
      "--P\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6874\n",
      "�messe et de particulier sur les grands diverses\n",
      "des figures et des plantations nouvelles. Le banquier avait accord� son poignard\n",
      "en trop \n",
      "\n",
      "Iteration nb : 40\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6827\n",
      "us de l���oc��an Att, de\n",
      "Maillane ne lui reprocha d�����tre de la cabine des passes\n",
      "qui d��passent la vie d���air, en d��barrassement des \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6778\n",
      "Orie Touchant avait commenc� par un si grand pardon.\n",
      "\n",
      "Le comte Cl�na avait tout perdu la naissance de son corps d'arm�e qui\n",
      "j'avais comme\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6735\n",
      "! la campagne du Cosaque �tait assise � deux chasseurs �\n",
      "vos aventures. Je vous prie de ce ch�teau.\n",
      "\n",
      "Il avait d�j� les cheveux blanchis d\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6690\n",
      "000), de liverter insistants: un combat de mariage ne tarda pas � se\n",
      "connaissance dans les airs. Le malheureux en �tait un tel grand nombre\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6649\n",
      "5, _Tierte_, c. 66; XI, fr�re R�gion (_sonter_, VIII, 15.\n",
      "    escarnit, _tromp�_, X, 1.\n",
      "    parlador (mal), _m�disant_, XIII, 41.\n",
      "    ret\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6609\n",
      "�tenir la province des autres.\n",
      "\n",
      "On avait p�nibl� pour la compagnie un jour l'indignation des postes et des\n",
      "projets de nouveaut�. Mais le \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6569\n",
      "$����l, m�das, monte derri�re la deuxi�me ou le parcour en regardant le plus\n",
      "indiffaction. Ils se d�tendions contre les armes et leurs cont\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6532\n",
      "�en parlent avec moi son coeur. Je croyais avec moi\n",
      "en allant saint Paul. Comme la vie sacr�e de l'oeuvre imp�riale\n",
      "se posent de bonne gor\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6494\n",
      "� la mati�re du ch�teau de Margival.\n",
      "\n",
      "--Eh bien, dit-elle, suppliant � Arien (son identimation.\n",
      "\n",
      "--Qu'en avez-vous prononc� ce billet du\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6462\n",
      "�en saurait le besoin de tout le monde, sire, et ce\n",
      "feu divin.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CHAPITRE II\n",
      "\n",
      "\n",
      "LES GRINEBUS ET DE CHAT MILER.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LE MARIAGE\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6428\n",
      "�uvre les portes. Elles ne sont pas les campagnes d'�gypte. Il\n",
      "avait eu soin de la main gauche, sans le savoir, un tombe du ma�tre,\n",
      "tandis\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6400\n",
      "Zannis, deux charretiers et des campagnes en robe froide �\n",
      "la presse, les fleurs de la foule et de ses rails. Ils ne se trombent pas de l'a\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6371\n",
      "re de la grange en\n",
      "d�lirant comme dans le parti soir dans une chambre volante. Et\n",
      "par compl�ment, que ce la Ram�e ne nous a rapportera le \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6338\n",
      "> avait �t� trouv� un poudre, nous pouvions les\n",
      "m�mes de la premi�re beaut�, elles ne sont pas encore vus\n",
      "devent substant au milieu de la \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6308\n",
      "par la peur, elle �tait si d�sagr�able, et\n",
      "c'est �clair� sur les derni�res tables et des cartes et des autres\n",
      "pr�cautions; il semblait que\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6281\n",
      "�ait la terre, et les funestes. Et il\n",
      "approcha tout � coup dans deux batailles de vin blanc, le salut de\n",
      "ses voeux les plus vivants partem\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6255\n",
      "47, VIII, 25.\n",
      "    MALESPINA ILE RAPOSE PEUT-ES DU JOURNAL D'ET TION IS QUILL PROPRES JOURANS PLEL MITS L'ORMINE\n",
      "\n",
      "L'Amour et l'espoir de c\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6232\n",
      "Mais il n'y avait pas de mort et que nous nous\n",
      "prenons pour de l'eau-de-vie, que nous nous contenterons de la chambre � coucher.\n",
      "\n",
      "--Monsi\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6206\n",
      "�cipions, ma grande\n",
      "volupt� � son mari les mains dans le m�me r�giment que je puis me\n",
      "faire comprendre la main � sa femme. Enfin, je lui p\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6184\n",
      "he de Malasque, Gabrielle Descen davantage pour le comte, d�autres mesures,\n",
      "toujours eux-m�mes les plus courts de nos qu'il ne puisse parle\n",
      "\n",
      "Iteration nb : 60\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6159\n",
      "]\n",
      "\n",
      "[Note 6: Nom :\n",
      "\n",
      "La ville �tait d�j� et courir � ses souliers, tout en se d�barrassant de\n",
      "l'int�rieur verme la liste du ch�teau.\n",
      "\n",
      "L\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6141\n",
      "ait pas mal � la main de tous ces pr�cautions. Mais ce n'�tait\n",
      "pas plus d'une lieue de mon amour, mais je ne vois que cela m�me quelques\n",
      "m\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6115\n",
      ", et je le faisais de la soupe et de la maison.\n",
      "\n",
      "--Ce prol�re, dit-il, que les larmes de la raison.\n",
      "\n",
      "--Des histoires des diamants, dis-j\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6093\n",
      "Je n'ai pas\n",
      "mal ambition. J'ai remarqu� aujourd'hui celui qui traita les arts; elle me\n",
      "rendit entre elle en un ciel rouge et de la pens�e \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6076\n",
      "(c'�tait le plus pr�s de celle de Krasno�,\n",
      "avait d�j� la conscience de son mari, et lui faire d�chir les\n",
      "assiettants lorsqu'il les rempla�\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6060\n",
      "XIV. D�moins, au matin, 1, jacol pour voir les\n",
      "fonds ni regarder sur le corps de l'alluse majestue de Bruges, qui la suivait\n",
      "la mort de la\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6030\n",
      "pas pour qu'on fasa\n",
      "moine.\n",
      "\n",
      "Et il me sembla entendre un grand bourg o� de mesure, et de la tombe, et que\n",
      "l'on aper�ut un instant dans un\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6020\n",
      "ait plus que d'accompagner le\n",
      "secret de l'auteur des dieux. Son adresse venait de s'�tendre � manger en\n",
      "duel!�\n",
      "\n",
      "C'est avec M. de Margiva\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.6001\n",
      "je n'ai pas de chevaux mortes.\n",
      "\n",
      "Ma pour estait, c'est la plupart des peuples de cette admirable compassion\n",
      "de cons�quences avec tous les \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5986\n",
      "YOU AGREE THAT THE FOUNDATION, THE\n",
      "TRADEMARK OWNER, AND ANY DISTRIBUTOR UNDER THIS AGREEMENT WILL NOT DIS\n",
      "LICEMENT T OF REMENT LE FONJEPRE\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5965\n",
      "� la rencontre de la ville.\n",
      "\n",
      "Apr�s le d�ner, il s'aper�ut qu'il ne se laissait pas compromettre de voir quelque\n",
      "chagrin qui cherchait � l\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5950\n",
      "ment ce que nous avions besoin d'ouvrir les\n",
      "discours suphanants, nous pr�mes sur l'emplacement de la grande cons�quence, et il\n",
      "ne lui dit \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5936\n",
      "�res du cher franchement et de la paille et du bois, nous all�mes\n",
      "d'une voix parfaite inutilement, ce n'�tait que par les coll��gues. Et il\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5920\n",
      "7, _Tirottin_.\n",
      "\n",
      "Au _Chons-l�-l�_: que l'esprit d'esprit et dont j'ai tant port�\n",
      "norreux bien rare! Je continue donc � ses amis; je ne sai\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5907\n",
      "�le r�gime actif, elle le savait appoindier les mains des femmes, tels\n",
      "qu'en valait se relever, et de la porte cette belle taste.\n",
      "\n",
      "Cepend\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5886\n",
      "�cher avec la ligue des formes en la chana�tre dans les\n",
      "cavernes des Europ�ens de la vie et de la nature, ils ne purent\n",
      "rien exag�rales. L\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5869\n",
      "), VIII, 25.\n",
      "    essonor, _manifocx de _C_zin_.\n",
      "\n",
      "[9] salt disposed to and treste donations from things yous explayer\n",
      "tatz you widest on \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5860\n",
      "> de la Garde. Mes compatriotes, en tenue de son ami\n",
      "l'�motion future de se livrer � devenir passa soumis au pied de\n",
      "l'approche. Le caract\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5850\n",
      "�rent. Ils paraissaient � se rencontrer.\n",
      "Sans doute le crime est fort heureusement de son arriv�e, et alors il se\n",
      "reprendra: �Quelle nuit,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5828\n",
      "Un moment existait alors les pav�s et les\n",
      "personnes qui le suivaient malgr� lour. Cependant leur console et les sciences et\n",
      "les peines, et\n",
      "\n",
      "Iteration nb : 80\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5818\n",
      "nt de la politesse que des\n",
      "campagnes de plusieurs adversaires pour leur bouteille. Leurs\n",
      "actions ne se partagent � l'accusion des id�es po\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5808\n",
      "00, collat,\n",
      "or mude the public domain in the United States and you are\n",
      "located in the United States, we do not claim a right to prevent yo\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5794\n",
      "\" associated with or appearing on the\n",
      "work, you must comply either with the requirements of paragraphs 1.E.1\n",
      "through 1.E.7 or obtain permi\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5783\n",
      "6) Lebel est copyright (or by the Eterx\n",
      "\n",
      "1IT.- The fela ses  romest.  On phant with anyone.  You may incares (d'y and to heau with your ag\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5770\n",
      "�cinq mille mots moins qu'� leur conseiller?\n",
      "\n",
      "Mais ce qui est la destruction que j'avais jusqu'� une femme. Comme j'en raison de\n",
      "l'�cole,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5767\n",
      "�le r�giment. Je me disposai � changer de demander � marcher plus\n",
      "d'un silence. L'�tranger trouvait mon homme qui ne manque pas de commence\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5747\n",
      "t de se voir sans �tre vus, nous avons\n",
      "commis une forte colie en ce geau. Il y a une demi-heure que je\n",
      "confiais � lui faire revenir dans m\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5737\n",
      " le pauvre Paris, et il lui fut impossible de se livrer � notre arriv�e\n",
      "pr�s d'une grange pour nous, se croisait sans contraire. Mme\n",
      "Rosi�\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5730\n",
      "_ c'est sourire) � demi vous sacrier s'il verra comme\n",
      "un interpr�te, dit Charlotte, que le malheureux printesta un peu de vivres cependant\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5718\n",
      "Le plus int�ressant se leva lentement vers elle, et prot�gea\n",
      "le roi et Phil Evans et de ses deux anciens angles voulus et sa\n",
      "m�le, de vign\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5707\n",
      "8.  You may charge a reasonable fee for copies of or providing\n",
      "access to or distributing Project Gutenberg-tm electronic works to\n",
      "protect \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5697\n",
      "� III, 130.\n",
      "\n",
      "    En tan (mos'et al\n",
      "per mien cui ren failleman.                 25\n",
      "    E sap qar pretz so guir qe�m tot bes,\n",
      "    Servint\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5683\n",
      "� la main de Ces harmais.\n",
      "Et, moins qu���il se retira pour luirer plus de deux lieues �� l���avant-peaut de\n",
      "l���aviation.\n",
      "\n",
      "�� On foulera\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5679\n",
      "� Instant alors de sa famille\n",
      "enfin de sa main de la Garde, avait d�j� invisible, par une petite\n",
      "table dans sa chambre � coucher, elle rep\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5659\n",
      "ce qu'ils n'ont que des id�es de la vie publique. Et pourtant la\n",
      "voile tendit la main droite et nous nous r�unions dans les champs. Il se\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5649\n",
      "Tu demanderas � parler � Mlle Enquine.\"\n",
      "\n",
      "Et le _Go a head_ avait ��t�� march�� �� la porte de la c��te - tu penses qu���il\n",
      "y avait des mo\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5644\n",
      "�\n",
      "\n",
      "Malheureusement il y avait la fi�vre. � la porte de la compagnie,\n",
      "avait disparu. Il est des difficult�s que le roi suivait sa douleur,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5631\n",
      "�t les\n",
      "camarades, dit-on. Ils ont peu de courageux, que les autres s'occupent\n",
      "du trissement. Alors les �tats mustrales ne sont pas encore \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5620\n",
      "Dieu, sans mal.�\n",
      "\n",
      "Ce n'�tait pas la pens�e de la vie pour le seconde langue avec une\n",
      "vitesse de cent francs en m�moire, il marcha devant \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5612\n",
      "�e! la nature communique, - puisqu���il n���a pas aussi ce\n",
      "que l���on vit les affaires pour se disputer les esprits plus\n",
      "favorat��s de l��\n",
      "\n",
      "Iteration nb : 100\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5610\n",
      "#�� la retraite en d�pouill� de son habitu� aux accords qu'il portait � sa tout d�centeur. On leur\n",
      "avait ordonn� de l'arr�ter pour nous deu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5603\n",
      "it pas plus que jamais.\n",
      "\n",
      "Celui-ci, sans s'�tourder avec l'ardement de la main droite. Avant que je\n",
      "suis si heureusement permis de vue une\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5591\n",
      "�le r�union, le proconsul.\n",
      "\n",
      "�Le menute, gros sacs d'une autre charrette et se dirigea vers la course\n",
      "de mon ateligint. Sur ces rochets, p\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5582\n",
      "), � ce qu'on dit,\n",
      "leur union des ann�es � la boutique. A peine les voit �tabli\n",
      "les bourgs de la chambre o� �taient les pierres, les riche\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5573\n",
      "heval deriv� et vert,\n",
      "_Sus ambillan_ de proven�al) m�autre � part honreure, la seconde\n",
      "nuit du 16, le roi courrait du fieux pour faire la \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5570\n",
      "�autre, les bras croits, des pistolets d�arreut. Parbleux, un crac de la compagnie, le prince Eurang contre les Cosaques, une\n",
      "compagne de v\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5554\n",
      "\" associated with or appearing on the\n",
      "work, you must comply either with the requirements of paragraphs 1.E.1\n",
      "through 1.E.7 or obtain permi\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5551\n",
      "�le de la montagne qui s'�l�ve sur la paille �tait sur le dos\n",
      "du grand chemin.\n",
      "\n",
      "Quand la beaut� conclut non plus la force de ma chapelle \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5541\n",
      "), VIII, 25.\n",
      "    MALASAIT, 20.\n",
      "\n",
      "    PARASA BUR NOQUL, 19, II, 29.\n",
      "    PENSADRA OR, 2003, p. 34. Corneille Friennent* Tapparit et\n",
      "Vol ad\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5534\n",
      "��tait ��cri�� la rive\n",
      "charg��e de son ind��tistre, - sauteur de l���appareil dans la mer distance.\n",
      "\n",
      "�� Bon ni tard dans le norg-d��, cas\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5531\n",
      "�ERGONE LE CONTE LE CONTER DE LA CEMPENTITE .�\n",
      "\n",
      "  X.\n",
      "    Si dont les sens volers une sonorg      adz tot bas, engrent e cadotal\n",
      "    E pa\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5521\n",
      "� se poser ainsi d'autres ne purent aller plus\n",
      "tout � la mani�re dont elle �tait la premi�re en froid; c'�tait le seul barchement\n",
      "aux dang\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5517\n",
      "@pglaf.org\n",
      "\n",
      "Section 4.  Information about Donations to the Project Gutenberg\n",
      "Literary Archive Foundation are tax deductible to the full e\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5507\n",
      "ment de la fi�vre et de sa cassette. Le courant des\n",
      "autres, pour cela que les hommes de l'ordinaire les trouperaient\n",
      "sous un point de la c\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5503\n",
      "47: Seige, de Gabrielle et d'une voix �mue la foille\n",
      "mith�e ne tarderaient pas un mot, �blouissant les royalistes et qui\n",
      "touches et soulev\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5496\n",
      "% de regrets de diff�rence comme les signes de\n",
      "son roman, et que l'ordre au monde aime toutefois plus doux!�\n",
      "\n",
      "Georges du Quesnoy se redre\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5489\n",
      "je n'ai pas retenu. C'est un haut sage.\n",
      "\n",
      "Elle s'enfuit en toute h�te, car il savait que sa proc�dation\n",
      "ne pourrait opposer aucui fait: �E\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5475\n",
      "��abri des p��les contr��es\n",
      "sur un banc de fruits, de mani��re �� prendre quelques hommes,\n",
      "surtout, par secourir de plus de deux cents kil\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5473\n",
      "! c�����tait l���_Albatros_ facile de\n",
      "renvoyer les Etats-Unis d���Un entendant la proie publiques du monde! Elle avait\n",
      "��t�� du soixant qu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5464\n",
      "Zan D.C NO BORNIBNA THIT MORBOUBNE TE TACOR\n",
      "\n",
      "T  N'adlors Ottilie part des ann�aturnalit�s, de Saph, qui �tais de sonder ses\n",
      "�l�ves sur to\n",
      "\n",
      "Iteration nb : 120\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5454\n",
      "Au m�me instant il jeterait ces peuples de robusque.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "XIII\n",
      "\n",
      " DRUCHAU AU QUVIT\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Pouss��ment, on obscurd de q\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5443\n",
      "Au mueut de sa cage et de membrant\n",
      "celle de sa jambe battue lui convenait de recevoir une bonne\n",
      "arm�e sur mon coeur.�\n",
      "\n",
      "Elle �tait d�cid�\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5440\n",
      "= Annalogue, Goutonne, en Provence.\n",
      "\n",
      "Pontis se couche de bonne heure, cela trime:\n",
      "\n",
      "�En v�rit�, il rentre dans le chair. Les jeunes gens \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5431\n",
      "�le r�giment avait march� autour de l'adjudant-major.\n",
      "\n",
      "Crillon boira son �poux � la convicalisation et la d�fense et\n",
      "l'exp�rience d�serte\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5435\n",
      "WARRANTIESSE DES INGOUNNGE POSS�LIT DI SON LAISSITL, DISTILIES\n",
      "TO PHESSAGENTINE OF SENT* DOMAIN\n",
      "\n",
      "The Foundation's E1oni, 200) 5903 8198\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5430\n",
      "�res, et une ��norme couleuve, dont les brumeurs qui ressemblaient de ses\n",
      "pieds le 23 doucet de son sud. Il s���arr��ta. Il pouvait rester \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5420\n",
      "ant de moi, cette belle pierre que je ne puisse n'y pas\n",
      "tromper le monde mieux qui portait le pas pour me faire accravaquer\n",
      "du c�t� de la \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5413\n",
      "�rent par le chevalier.\n",
      "\n",
      "Le Capitaine s'�tait remis en cent mille hommes, nous ne p�mes se tromper.\n",
      "\n",
      "[Note 27: Non-seulement ce point qu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5404\n",
      "k in any binary,\n",
      "compressed, vers wassed topla equ limpie 100, 2013, with hompde nous\n",
      "parlers prophyatuds ophores      grnes bo aissible\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5399\n",
      "� se retrouv�rent\n",
      "�douard et en son allure, car il n'y a plus de douze pour\n",
      "les autres. L'�ducation qui avait de la farine et du si�cle\n",
      "m\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5400\n",
      "�re Robert.\n",
      "\n",
      "--C'est par l�-bas. Tous les jours o� vous faites cette pernepenchant,\n",
      "comme je sachais, moi, je ne puis plus manquer, et no\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5391\n",
      "e la vie domestique, les parcouris les\n",
      "valeurs et les chauves, en attendant des secours. Deux mains\n",
      "clairass�s et si malheureux, que je m'\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5389\n",
      "WARRANTIES OF MERCHANTABILITY OR FITNESS FOR ANY PURPOSE.\n",
      "\n",
      "1.F.5.  See no retige or refund agot electronic work or\n",
      "reter state or charma \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5375\n",
      "\n",
      "\n",
      "-- Saint-Apoussid, ma femme, lui dit la ma�tresse de la route, un bon\n",
      "champ et � la retrouver, pendant que le paysan nous dit\n",
      "que nous\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5370\n",
      "�tives tranquilles et nos malades de\n",
      "charrettes sur le ciel, et que les autres me regardaient de nouveaux\n",
      "�paissants; mais les pauvres plu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5371\n",
      "Project Gutenberg-tm electronic works provided\n",
      "that\n",
      "      lo phot for copies of the works possessed in a physical mademued.  If you racait\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5361\n",
      "�a ne pas\n",
      "passer vide comme moi, un bon ciel par un de ces mots seule que je\n",
      "n'ai pu consoler en lisant la fin de l'homme, car il est des \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5353\n",
      "re la lettre que je vous aiderai m�me pas encore\n",
      "par la peine de modifier sur son coeur. Il m'assait assez devenu plus\n",
      "longtemps que des c\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5352\n",
      "le mariage, mon fr�re,\n",
      "qui te la donnerais-tu par cette faute!� Des petits gens ne\n",
      "firent planer. L'un des traces riches font au r�giment \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5342\n",
      "ment de la main droite. Au reste, le pass� se\n",
      "prodiguait en sanglots guidi�raient garni de morts. Cela suffisait d'une\n",
      "famille dont la loi\n",
      "\n",
      "Iteration nb : 140\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5338\n",
      "Oui, je me suis charg�e de m'y sentir. Je m'en �du\n",
      "verquement malade, parce qu'elle �tait sur de bruit: on allait\n",
      "continuer la marreanisse\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5330\n",
      "�re, qui se\n",
      "passait � cette �poque ce que les partisans sortir de l'art parule �\n",
      "cent �l�gations, il le fallait, la t�te envoy� par la sag\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5329\n",
      "+\n",
      "\tNous adolors toutes sur le roufre d�un coup\n",
      "d�ourg�re, r�citaient les dracophiles. Ils n'en vinient pas de\n",
      "lien, et en arrivant, comme\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5318\n",
      "= Anaberte se d�veloppe avec bonde et, setour�,\n",
      "mais non sans avoir pu apprendre sa vie. Pauvre petit cours de la compagnie\n",
      "dit � Dieu, ce\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5310\n",
      "\" associated with or appearing on the\n",
      "il k, you must comply e wh.Prodiors viewed and Michanging ourse requert or entrabing in payed val\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5312\n",
      "� les montagnes en avons-n���altitude de ses\n",
      "embarras?\n",
      "\n",
      "- Non! on dit trois milles qui sont vaut le fort �� couper\n",
      "sous la porte. Koussy\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5308\n",
      "You provide a secure\n",
      "and permanent future for Project Gutenberg-tm and et the copyright holder convienner with\n",
      "ak honeer that you hane rea\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5299\n",
      "Project Gutenberg-tm electronic works in your possession.\n",
      "If you paid a fee for obtaing it to you agree to and reald of yous le cof donatio\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5299\n",
      "Un jour de sainte Orberose fut impossible de retourner dans sa lectrative\n",
      "en souvenir d'une partie de la grandeur dont le coeur se fut enco\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5293\n",
      "_ et _N_, v. 37, pette dame\n",
      "    CHAPITRE V.--Les suspensates et\n",
      "reconnaissaient les partis et les gars, ils prirent le parti de se\n",
      "faire \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5287\n",
      "?\n",
      "\n",
      "--Ce sont des d�bris de pr�parer aux hommes qui me donnait venir un\n",
      "tra�neau et le d�sir de m'en abandonner. Je me ris en contact\n",
      "la \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5278\n",
      "_ et _Mis�me\n",
      "et _trouver_ (?), [6]tes Varbode 29ectel, est concembi�e (811, 190).\n",
      "\n",
      "Nous v�mes une sinc�re po�tique serre_, cela va de la \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5273\n",
      "re plus de deux cents quarante mille belles et\n",
      "mangeaies; elle me dit en marche. Un instant apr�s, elle nous\n",
      "donna � des tra�neurs modeste\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5270\n",
      "�douard avait �t� tu� le reste de la civilisation. Il r�solut\n",
      "tout en s'applaques et tout ce qu'elle �tait arriv�e � la tr�verie\n",
      "� Saint-G\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5268\n",
      "�\n",
      "--Nolle rousse avec nous en termes par le bruit du canon, mais\n",
      "je ne le connais pas.\n",
      "\n",
      "--Formole ?\n",
      "\n",
      "- Sganarelle -\n",
      "\n",
      "Non.\n",
      "\n",
      "- Pancra\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5268\n",
      "5, 2013 [EBook #9Ch9166�K), 1K03, (20), and any other party distributing a Project\n",
      "Gutenberg-tm electronic works if you follow the terms of\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5256\n",
      "�uvr�� l���appareil sentent de\n",
      "l�����lecission des peupli��res qui commen��rent �� d��diacer simille �� un\n",
      "ph��nom��ne, mais il n�����tait\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5259\n",
      "Quelques moments de merluche brute et sa ni�ve!\n",
      "\n",
      "Et encore les Pingouins croisaient contre les procurateurs que le Baron lui avait\n",
      "dit qu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5256\n",
      "� 19, v. 15, o_ne put vai g�nis,\n",
      "    Cun                                                                                                   \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5251\n",
      "> a pague assez de riz�mes qu'il fallait se\n",
      "d�barrasser de la harpe de Dioccume (_Lex--lux, associ�es), ma�tre,\n",
      "s'�cria:\n",
      "\n",
      "-- Mais Esp�ra\n",
      "\n",
      "Iteration nb : 160\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5242\n",
      " de la maison qui �tait � la main, ouvrit le\n",
      "si�ge de Pais o� j'avais �t� constre le fr�re R�gimente. Nous en avons\n",
      "encore un peu de ce qu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5228\n",
      "), _d�sirer_, VI, 41.\n",
      "    corster), _sin_, 2, au far genor vantaren;\n",
      "    _mervec (a_; v. 26, grif_ (.), 18.\n",
      "mais Rovaldie la lune mariati\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5237\n",
      "�uvr�� l���appareil suppos�� par la lune, et, sans\n",
      "doute, c���est que le valet Frycollin ��tait pr��s du feu son appuy��e aux interpr��ts d\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5229\n",
      "que l'on n'a pas le droit de m'apprendre �\n",
      "m'endreter au moyen de perdre. Nous ne trouvions pas sans mes\n",
      "routres, mais que, pour nous arr�\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5232\n",
      "@pglaf.org\n",
      "\n",
      "Section 4.  Information about Donations to the Project Gutenberg\n",
      "Literary Archive Foundation at the Exclus pendred by\n",
      "the op\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5224\n",
      "it de son bonheur, c'�tait sur le boulevard de\n",
      "ces Trobbes, les pauvres p�lerins qui arrivaient. L'on\n",
      "voyait qu'il �tait de la palette, de\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5214\n",
      "), _d�sirer_, VI, 41.\n",
      "    candotar, _amanar. _en car son cor artamenz_, cRodeil\n",
      "nouveau_. Tr�du Toublet. - Le para�tre est le secret de so\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5207\n",
      "XIV).\n",
      "\n",
      "\n",
      "Les autres �taient des pierres, des charretiers noirs, et de\n",
      "leurs verses, et l'on pr�parait de ses l�vres si doucouronner dans \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "168s - loss: 0.5202\n",
      "~ Gentil selin sous la conversation sur le mur de l'arm�e.\n",
      "\n",
      "--C'est une vieille bouche.�\n",
      "\n",
      "Georges allait sourdre et qui n'est pas connu \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "169s - loss: 0.5201\n",
      "\n",
      "\n",
      "Le roi dont le coup sur son temps promessait aux\n",
      "hommages rudes et r�compense pour les autres. Oh! coquin dans la\n",
      "ville, qui le suivai\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "186s - loss: 0.5200\n",
      "�ME SAC\n",
      "\n",
      "\n",
      "La constitution des �pous le trouvait chaque fois qu'il\n",
      "n'est plus pr�s d'une fois de bataille, son inqui�tude nous dit\n",
      "encor\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "172s - loss: 0.5201\n",
      ".  Contributions to the Project Gutenberg\n",
      "Literary Archive Foundation are tax deductible to the full extent\n",
      "permitted avait donations to t\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3c953c4116c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mnb_iteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mbla\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGENERATE_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#batch size equals to seq length here\n",
    "BATCH_SIZE=100\n",
    "#len of desired output\n",
    "GENERATE_LENGTH=140\n",
    "DIR=out_path+\"weights/weight_attempt_s01/\"\n",
    "flag=True\n",
    "\n",
    "try:\n",
    "    onlyfiles = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "    nb_files = len(onlyfiles)\n",
    "    name_template = onlyfiles[0][0:15]\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "    nb_files=0\n",
    "\n",
    "if nb_files>0:\n",
    "    nb_iteration=nb_files*20\n",
    "    model.load_weights(DIR+onlyfiles[0][0:21]+str(nb_iteration)+'.hdf5')\n",
    "else:\n",
    "    nb_iteration=0\n",
    "    \n",
    "print(\"Starting at iteration : %s\" %nb_iteration)\n",
    "while flag==True:\n",
    "    print('\\n')\n",
    "    print('-'*20)\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, verbose=2, nb_epoch=1)\n",
    "    nb_iteration += 1\n",
    "    bla=generate_text(model, GENERATE_LENGTH,VOCAB_SIZE, indices_char)\n",
    "    if nb_iteration % 20 == 0:\n",
    "        print(\"\\n\\nIteration nb : %s\" %nb_iteration)\n",
    "        api.PostUpdate(status=unicode(bla, errors='replace')[0:123])\n",
    "        model.save_weights(DIR+'checkpoint_{}_epoch_{}.hdf5'.format(HIDDEN_DIM, nb_iteration))\n",
    "    if nb_iteration>=200:\n",
    "        print(\"Stopping...\")\n",
    "        flag=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xb0 in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-b57c68d18fbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"latin1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xb0 in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "print(out.(\"latin1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Generate text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    if not os.path.exists(out_path+\"generate/\"):\n",
    "        os.makedirs(out_path+\"generate/\")\n",
    "    with open(out_path+\"generate/output.txt\",\"w\") as f:\n",
    "        f.write(('').join(y_char))\n",
    "    return ('').join(y_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "� 190, ��vitement de la\n",
      "ville, nous venions de viendre �� l���o�� les accumulateurs de l���a��ronef s�����taient\n",
      "apais��s au-dehors �� l���horizon.\n",
      "\n",
      "A cette ��pout��, occupaient avec le ma��tre aux trompettes de ce\n",
      "r��fuse ou deux s��riens propulseurs un ton attach�� �� l���avant. A sa surface\n",
      "s�����tait d��pass��e en un si grand degr�� fut acc��t��, foust�� entre deux heures et\n",
      "volantes sous une ��norme balle du silence, l���occasion de l���a��ronef avec le\n",
      "coucherks - ce qui se passe tr��s revenues sur toute sa\n",
      "voix. Si Uncle Prudent et Phil Evans se pr��cipit��rent par la place de l���a��ronef.\n",
      "\n",
      "En somme, aux experts du parc, l���appareil avec lui, il reconnut que, plaisant des\n",
      "nombres ouvriers comme un homme de fianc��e, comme des a��rospates, les autres des\n",
      "montagnes, des plaines qu���il convient de maintenir cette science, ce mot d���avantigue e��t agen\n",
      "de peines et de prendre un moyen finir��ment. De longs nuits glaci��\n",
      "plus bien r��clament en effet ceci d���une succr�he ��\n",
      "ces gratiers. Trus citoyen, dit-il, que cet ��tat se\n",
      "passerait homme. La Bar��e s�����tait fait dans la nuit du 27 au 28, ��ais\n",
      "que la lueur ne f��t pr��s peu de retraite. Pendant les presse au-dessus de\n",
      "l���a��rostat, - _tupiduluille_ riche et astro_ome et de la\n",
      "Lithuanielle martelle de la mer. Mais, tous ceux qui\n",
      "tombaient �� l���horizon pour leur d��monchissement, au m��ridien de Paris, au reste,\n",
      "peut-��tre ne leur contente pas, et, cr��e encore l���homination,\n",
      "ils s�����taCPU times: user 6min 8s, sys: 620 ms, total: 6min 8s\n",
      "Wall time: 6min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = save_text(model, 1500, VOCAB_SIZE, indices_char)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
