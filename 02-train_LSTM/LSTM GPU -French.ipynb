{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout,TimeDistributed\n",
    "from keras.layers import LSTM,SimpleRNN\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os, os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from unicodedata import normalize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- ### Check GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/gpu:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Check and set Twitter's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "api = twitter.Api(consumer_key='LyNVanTEQEOEGKfXAMeLv6AKG',\n",
    "                    consumer_secret='0lJvhaaOP5cRZWm6rxwyBIAypd1P7eiDx9f74KBDlLrSldNuBQ',\n",
    "                    access_token_key='855852332034265088-geTEVmA7xIsOD3WCZyfBNnqjRdS1MhW',\n",
    "                    access_token_secret='kJMwMl67e3nYrqaGWzIizxzQpRZhtBfOnwPflO1fk3cOt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Sat Apr 22 18:34:31 +0000 2017\", \"default_profile\": true, \"description\": \"Learning how to be creative\", \"followers_count\": 2, \"friends_count\": 3, \"id\": 855852332034265088, \"lang\": \"en\", \"location\": \"Somewhere in the cloud\", \"name\": \"ArtistBot\", \"profile_background_color\": \"F5F8FA\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/855852332034265088/1492892354\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/855878764143804417/r55Z2Js5_normal.jpg\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"screen_name\": \"TheTalkativeBot\", \"status\": {\"created_at\": \"Tue Apr 25 15:36:21 +0000 2017\", \"id\": 856894659007844352, \"id_str\": \"856894659007844352\", \"in_reply_to_screen_name\": \"dvp_tran\", \"in_reply_to_status_id\": 856879788518236161, \"in_reply_to_user_id\": 747074580754403328, \"lang\": \"de\", \"source\": \"<a href=\\\"http://www.google.com\\\" rel=\\\"nofollow\\\">TheScenarioBot</a>\", \"text\": \"@dvp_tran Automamte answer 2 !\"}, \"statuses_count\": 49}\n"
     ]
    }
   ],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "api.PostUpdate(\"Today I am learning German, watch me improve! ;) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Learning from corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. Load and convert data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done concatenating file : 249.txt\n",
      "Done concatenating file : 4740-8.txt\n",
      "Done concatenating file : 799-0.txt\n",
      "Done concatenating file : 4548-8.txt\n",
      "Done concatenating file : 4791-8.txt\n",
      "Done concatenating file : 803-8.txt\n",
      "Done concatenating file : 2650-0.txt\n"
     ]
    }
   ],
   "source": [
    "#Load and concatenate files:\n",
    "\n",
    "DIR=\"../../LSTM/data/Gutenberg/ebooks-unzipped/French/\"\n",
    "all_files = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "\n",
    "#choose how many files to concatenate:\n",
    "nb_files=7\n",
    "if nb_files>len(all_files):\n",
    "    nb_files=len(all_files)\n",
    "    \n",
    "    \n",
    "out_path=\"french/data/\"\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "if not os.path.exists(out_path+\"input/\"):\n",
    "    os.makedirs(out_path+\"input/\")\n",
    "    \n",
    "with open(out_path+'input/french.txt', 'w') as outfile:\n",
    "    for fname in all_files[0:nb_files]:\n",
    "        with open(DIR+fname) as infile:\n",
    "            i=0\n",
    "            for line in infile:\n",
    "                if i>=50:\n",
    "                    outfile.write(line)\n",
    "                i=i+1\n",
    "        print (\"Done concatenating file : %s\" %fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load file\n",
    "file_name=out_path+'input/french.txt'\n",
    "text = open(file_name).read()\n",
    "text=normalize('NFKD',text.decode('latin1')).encode('ASCII', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = re.sub(\"\\n\\n+\" , \"\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 2508723\n",
      "total chars: 89\n"
     ]
    }
   ],
   "source": [
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "VOCAB_SIZE = len(chars)\n",
    "print('total chars:',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** The RNN takes in input numerical data hence the necessity to convert strings into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating mapping between indexes and characters\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weâ€™re gonna use Keras to create and train our Network, so we must convert the data into this form: (number_of_sequences, length_of_sequence, number_of_features).\n",
    "- nb of features = length of the char array\n",
    "- length of sequence = batch size\n",
    "- nb of sequence = len(data) divided by batch size.\n",
    "\n",
    "**Warning : ** target sequence is setted by shifting the source/input sequence by one character with both having the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.02 s, sys: 192 ms, total: 2.22 s\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "SEQ_LENGTH=100\n",
    "#Build three dimensional arrays\n",
    "X = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #input\n",
    "y = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #target\n",
    "\n",
    "#Build sequences\n",
    "for i in range(0, len(text)/SEQ_LENGTH):\n",
    "    X_sequence = text[i*SEQ_LENGTH:(i+1)*SEQ_LENGTH]\n",
    "    X_sequence_ix = [char_indices[value] for value in X_sequence]\n",
    "    input_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "    X[i] = input_sequence\n",
    "\n",
    "    y_sequence = text[i*SEQ_LENGTH+1:(i+1)*SEQ_LENGTH+1]\n",
    "    y_sequence_ix = [char_indices[value] for value in y_sequence]\n",
    "    target_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        target_sequence[j][y_sequence_ix[j]] = 1.\n",
    "    y[i] = target_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. Build the network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM= 500 #500\n",
    "LAYER_NUM = 2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "for i in range(LAYER_NUM - 1):\n",
    "    model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[@@@SSCCCCCBDD;;;GG3333q3333vvvvzzzzzzIIzMMnnnnnNNEEEiiimm4jjjE.SS!!!!!!!AAAAAAIkkk-SSSS!"
     ]
    }
   ],
   "source": [
    "# Generate some sample before training to know how bad it is!\n",
    "bla = generate_text(model, 100, VOCAB_SIZE, indices_char)\n",
    "#api.PostUpdate(status=bla[0:123])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Train network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_iternb(string):\n",
    "    return re.findall(r'checkpoint_500_epoch_(.*).hdf5', string)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at iteration : 700\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "93s - loss: 0.1897\n",
      "je sentais que je t'ai l'anA de croire\n",
      "que je m'en ailuissais assez pour un verre A  un de ses amis vraiment\n",
      "aux investigations de la barr\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1903\n",
      "\"Violantie, _s-ellie\n",
      "en mirieur, et au moment de la gravite verte, que le bas discute pour moi, j'aurais\n",
      "perdue de savoir A  tous les mots\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1898\n",
      "\n",
      "\n",
      "--Je n'irai pas.\n",
      "\n",
      "En ce moment le docteur rentra dans son cabarade, et depuis le\n",
      "rivage.  Sa lunette de la situation, illus ou compren\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1897\n",
      "; il n'y avait aucun dame en revenant\n",
      "s'en approcher.  On apercevait dans une pluie d'etifice, ils revirent au milieu des\n",
      "flammes, la bour\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1892\n",
      "it plus\n",
      "signe d'existence depuis quelques heures, ce symptome fut accueilli\n",
      "par un redoublement de mousquet aucun retombait en lui presant\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1896\n",
      "Vers dix heures du soir, la montagne n'etait plus a loin\n",
      "etre un contre le 13 avec de lumiere succeder son toilet de grandes\n",
      "mammotines, J\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1899\n",
      "une femme,\n",
      "on doit seul dans un taffrAam de cris qui aprA s l'air, comme un\n",
      "moment de leur attachAe en ne reconnaisnait que son rive quant\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1891\n",
      "+ Wein appela\n",
      "pecellace s'etendait sur sa cabatade, les vivres, ils paraissaient se conderrir a sa situation ligne\n",
      "d'une evenement uniferm\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1902\n",
      "Cette pensAe l'individait et la force\n",
      "de se mettre en rAalitA le pays souffrant et montait en passant les flots.\n",
      "\n",
      "Est-ce que l'eruption s\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1896\n",
      "`il se\n",
      "disait pousse plutot qu'attire dans ses vassaux et de la\n",
      "traitA de cotoire.\n",
      "\n",
      "Tout d'un coup ses plus AloignAs.  Vois la Lune sera\n",
      "\n",
      "Iteration nb : 710\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1894\n",
      "s de cens pieds rayons de sans avoir expriment ces gens sont suffisants.  Parfaitement\n",
      "suspendus sur le porche de l'eau de Jes Gun-Club n'a\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1899\n",
      "it pas plus qu'un autre.\n",
      "\n",
      "Or, tandis que le docteur poursuivait le mechant d'une insouperable jeune marche, jugement;\n",
      "sinon fut de dire q\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1895\n",
      "@posent.\n",
      "Or distribution or any other party distributing a Project\n",
      "Gutenberg-tm electronic work under this agreement, disclaim all\n",
      "comman\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1896\n",
      "Hans, bonjour, murmurai-je.  C'est\n",
      "mon coup ebrancer d'etre revenu sans peine!  il n'y a pas a expliquer ne marquant\n",
      "pour descendre! il fa\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1892\n",
      "x de mettre le Niger esthAt et de rAnvacements nombAs\n",
      "de la charbon qui le pouvait etre longuement aux recipients du ciel\n",
      "faisait un contr\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1894\n",
      "le trouvait l'accent ainsi que tous les\n",
      "enormes maux mandisment rouges, sorte d'escrocher un remarquable\n",
      "fond de quatre mille livres; il d\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1897\n",
      "ais dorA, Atait bordA dans toute\n",
      "sa longueur d'une caisse refune A  mes yeux. Mais parce qu'elle Atait lA , les plus beaux sont eblouis, et\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1891\n",
      "5 octobre\n",
      "prochain, et le canon lavAe, on voyait mal, Castrue\n",
      "qui lui Atait particulier, certes individualiques sur lesquelles ils avaient\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1882\n",
      "Gutenberg-tm is synonymous with the free distribution of\n",
      "electronic works in formats readable by the widest variety of computers\n",
      "including\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1889\n",
      "Verdurin, continuant A  jeter sur sa femme des regards\n",
      "furtif.] dans une petite majestA, qui supArieure en plein ciel, de vrais grasuers qu\n",
      "\n",
      "Iteration nb : 720\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1880\n",
      "01(c)(3) educational corporation organized compyrade pronigeance and ensuming thistesment of thingt a\n",
      "provide and accepted in a number of o\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1890\n",
      "4 but.  Un voyageur n'avait pas\n",
      "conscience d'autrefois pendant a l'air d'apparer de la seconde environ du gaz et a reponds.  Par une bonte \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1890\n",
      "Gutenberg Literary Archive Foundation.\"\n",
      "\n",
      "- You provide a full refund of any money paid by a user who notifies\n",
      "     you in writing (or by \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 0.1889\n",
      "heures, la descente fut\n",
      "reprise.\n",
      "\n",
      "Nous suivions toujours la ligne furent possede l'arrivait.\n",
      "Dans les autres, les plus ils semonts du so\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1877\n",
      "***\n",
      "This and all associated files of various formats will be found in:\n",
      "        http://www.gutenberg.org/7/9/799/\n",
      "\n",
      "Produced by John Walke\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1890\n",
      "Kennedy.\n",
      "\n",
      "--Laisse ton fusil de cote.\n",
      "\n",
      "--Voici monee!  s'ecria-t-il.\n",
      "\n",
      "Mais c'est deja que je ne connais pas, je l'issuela; il faut me \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1888\n",
      "9\n",
      "\n",
      "--Je ne demande pas vingt-clamme\n",
      "quatre le point sur la seconde du plaisir qu'on a enveillent...\n",
      "\n",
      "--Et il est vrai bien, s'ecria le \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1881\n",
      "Web site which has the main PG search facility:\n",
      "\n",
      "     http://wwww.guberg.\n",
      "\n",
      "* You produit donations are West Project Gutenberg-tm electro\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1889\n",
      "faire A  toutes, dans les\n",
      "scA nes paA ennes comme dans les tableaux rAligiables de ly vines de\n",
      "l'Antre-frond de la Boulomade, cette dame e\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1883\n",
      "] rendait intolerable!  s'ecria le professeur.\n",
      "\n",
      "--Habs, monsieur, cela n'est pas de peine garde! repondit mon oncle.\n",
      "\n",
      "Il etait un des po\n",
      "\n",
      "Iteration nb : 730\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1878\n",
      "nt de temps en temps\n",
      "semer des feux\n",
      "ca et la fendait a peine de detres elegandes ses\n",
      "penches dans les airs. Les combattants, apres dix cr\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1879\n",
      "ble et gAmie.  De l'autre cA tA, avec une\n",
      "profonde diffurence une grande prAsence dans vie par le prAsident Barbicane.\n",
      "\n",
      "Le prAsident Barb\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1873\n",
      "+ Weinbardant, du reste et de son\n",
      "embarrass pendant une heure, et, s'avanca de nous qui a\n",
      "l'expedition du cardinal, un maimains instrument\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1879\n",
      "The Project Gutenberg Literary Archive Foundation is a non profit\n",
      "501(c)(3) educational corporation organized under the laws of the\n",
      "state \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1870\n",
      "par le docteur Baikie.\n",
      "\n",
      "Fergusson s'etait egalement muni d'un ouvrage. qui reunissait en un\n",
      "seul ciretalinaire!\n",
      "\n",
      "--Voila, ce que j'ai v\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1876\n",
      "ce qui s'y\n",
      "faudit et que quand nous avons peut-etre tant de mettre un roc, et\n",
      "n'etait pas mise et ne manquait pas a ses compagnons.\n",
      "\n",
      "Sam\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1868\n",
      "3 below.\n",
      "\n",
      "1.F.\n",
      "\n",
      "1.F.1. Project Gutenberg volunteers and employees expend considerable\n",
      "effort to identify, do copyright research on, tra\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1876\n",
      "yeux une citA dAsirAe et s'imaginent qu'on put-Aatre\n",
      "si peu encore, A  qui il sent plus favorable que le jardinier d'Eulalie\n",
      "s'arrAatait A\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1878\n",
      "4 bras d'horizon un qui servit de\n",
      "bourgeau que notre desor. Apais moins important, il faut savoir qu'en\n",
      "soit et je m'Atais simuliante, et \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1878\n",
      "_________________________\n",
      "\n",
      "\n",
      "Dans les veines\n",
      "plus habitues.  Sa soupe, d'apres laissant fallier jusqu'au bord du\n",
      "Candad, qui payait sur \n",
      "\n",
      "Iteration nb : 740\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1880\n",
      ".  En outre, la construction de ces\n",
      "vastes lentilles est excessivement difficile et demande un temps\n",
      "fort paractuchit. Le calcan actuel de\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1881\n",
      "de ces officiants, suffisait A  tenir en Achec l'attention de trois\n",
      "cents personnelle; et, bravant sur les mots\n",
      "qu'elle pAt avoir dAjA  At\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1869\n",
      "Y PURPOSE.\n",
      "\n",
      "1.F.5.  Some states do not allow disclaimers of certain in\n",
      "the United States without pays on a Project Gutenberg-tm work (any\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1870\n",
      "t des branches, comme autant de ces petits\n",
      "Aparables avec ma jeune fille de type devenu par les oreilles. L'air\n",
      "dAsir, et prouvait ce qu'o\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1876\n",
      "Cette pensAe la\n",
      "remplissait de colA re, mais elle revant dans le monde, le\n",
      "prAsident du Gun-Club du traitA, oA1 nous nous rencontrAs\n",
      "par \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1875\n",
      "s les yeux de Fergusson.\n",
      "\n",
      "On embarqua dix tonneaux d'acide sulfurique et dix tonneaux de\n",
      "vieille faite pelle enecorde.  Nous avons fait a\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1867\n",
      "E.7.  Do not charge a fee for access to,\n",
      "prevent access to, fut dona a Londres.\n",
      "\n",
      "Mais, pendant les deux spectres, genre presque pour un b\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1880\n",
      ") are particularly important to maintaining tax exempt\n",
      "status with the IRS.\n",
      "\n",
      "The Foundation is committed to complying with the laws regul\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1870\n",
      "***\n",
      "This and all associated files that sate f or the public\n",
      "sommed in the original messageated the fee support of this license, apply to\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1875\n",
      "(excellent homme avec qui elle a besoin de revoir chaque infinime\n",
      "d'acier, elle est seule entre tout seri au lieu de prendre un geste de\n",
      "r\n",
      "\n",
      "Iteration nb : 750\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1881\n",
      ".  Le steamer\n",
      "l'_Ellenora_, ne partait pas avant la nuit.  De la une fievre de\n",
      "neuf heures, pendant des souffles soins et des savants,\n",
      "co\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1871\n",
      "re de compter sur ma voix\n",
      "que je me les devais mais non plus me faire semblant dans l'onde\n",
      "sous la compagnie de cet occupaire.  Avant l'ex\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1875\n",
      "Le marabout, trouvA t incurte le recteus qu'elle avait\n",
      "fait pour un peu prA s de l'altrement de leur secretaire du raier\n",
      "dans l'Anlan avan\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1866\n",
      "s de trois cent mille\n",
      "francs.A Si alors Swann cherchait A  lui apprendre en quoi comment c'Atait\n",
      "naturel, ne m'avait pas AclatA.\n",
      "\n",
      "......\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1870\n",
      "] et\n",
      "neuf cent soixante-six gallons d'eau [Pres de quarante et un mille\n",
      "deux cent cinquante dollars [Trois mille neuf an 1799. Joe\n",
      "reunit\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1867\n",
      "7: commisson, pauvre gAnAral Swann et mieux\n",
      "revenant A  la trombe. Donc, A  lui faire que vous prenirez sans doute, et peut-Aatre vrai\n",
      "cel\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1872\n",
      "z comme s'il y avait le feu, attendez\n",
      "donc un peu de ces aspects pour savoir sur la mer.\n",
      "\n",
      "Ce fusil arravait le tunnel.  Je charge de ne p\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1867\n",
      "$[([Zou_: je la lui vis de parler maintenant elle essayA de les\n",
      "muechoire, l'on pouvait rentrer chez lui sans laisir le visiteur bien de\n",
      "c\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1867\n",
      "9\n",
      "\n",
      "--Bon!  repondit mon oncle, la force a decouvert d'un homme\n",
      "qui m'echappe.\n",
      "\n",
      "--Le tunize! ah! que s'ecle comme je suis sans connaitre\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1869\n",
      "2., but its volunteers and employees are scattered\n",
      "throughout numerous locations.  Its business office is located at\n",
      "809 North 1500 West, \n",
      "\n",
      "Iteration nb : 760\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1856\n",
      "!  ce sont bien des dents,\n",
      "j'apercus mes deux compagnons vers l'ouest.\n",
      "\n",
      "Et de la voix qui sacoree il devait charger a toute\n",
      "cette trompe\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1862\n",
      "\\(); Im C'BENDEX11\n",
      "\n",
      "_TiA flement partie de la balistique de Legolicol.\n",
      "\n",
      "La duchesse demanda-t-il a Tensire-la meme dejousse.--L'aspect\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1860\n",
      "vent?  demanda mon oncle.  Arne Saknussemm!\n",
      "comme sur un point distique, au premier de ces paroles? demanda Joe;\n",
      "mais; a mos compagnons re\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1859\n",
      "[Trente-huit millions de\n",
      "korble.--Le Mission de Reykjawik in, qui passent dans ces terribles arbres\n",
      "aux yeux. Cest notre boissolite ne bri\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1865\n",
      "@pose.  Des maladies au passage, et bientot une enorme famille; mais\n",
      "la descente metale de gauche recouverte de l'etude et la beaute de la\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1861\n",
      "Mais s'ils le tumAt en atteinir par leur chemin vert le fond de l'Atyon et le\n",
      "boulet.]? il m'avait rApondu: AJe crois bien que je saisis es\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1863\n",
      "x de mes compagnons pouvait me parvenir.\n",
      "\n",
      "Cet effet d'acoustique tres etonnale et des montagnes\n",
      "amorides, puis elle soulevait tous les po\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1856\n",
      "%souffle la vie mondaine, les fours de l'humidite se\n",
      "promenait sur lui. Au moment peu rapide, le puits, les\n",
      "vapeurs enveloppent la tete de\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1859\n",
      "que les pays\n",
      "soumis depuis longtemps au meme genre de gouvernement imprement.\n",
      "\n",
      "L'orbre alite des couches repandus rougent. Les membres du\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1862\n",
      "9\n",
      "particuliere n'etant pas arbre; et ce fut, une vingtaine de\n",
      "maitres, de quelques seances d'engraime-la quantite de ce pays disparurent e\n",
      "\n",
      "Iteration nb : 770\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1860\n",
      "par des  nullabs , sortes de\n",
      "torrents momentanes, devenaient impraticables, et les raisons a\n",
      "la frere des negres que maman; les hommes par\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1856\n",
      "blanche prise dans le rAseau noir des allAes\n",
      "dont on avait enlevA la neige et sur laquelle la statue des deux\n",
      "intelligents quy de prendre \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1850\n",
      "z l'une ou l'autre des femmes de sa coterie, et fautrait Swann se prAparent\n",
      "pour lui donner tout de suite Mlle Swann qu'elle n'avait d'absA\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1865\n",
      "READ THIS BEFORE YOU DISTRIBUTOR ***\n",
      "\n",
      "***** This file should be named 4548-8.txt or 4701-8.zip *****\n",
      "This and all associated files of var\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1860\n",
      "s de temps a l'entendre.\n",
      "\n",
      "Mon oncle et moi, pour savoir se passer mes rivees pour voir s'il ne\n",
      "laissait pas.  Le siege abai, que le Victo\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1854\n",
      "\\(); Florgore, Perlir\n",
      "son effret embarque sans fin cherchant a fleur, et l'eau manquait totalement de\n",
      "mis defaute, dont les conventions le\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1859\n",
      "\\(); be de periodes-pas de reposer,\n",
      "par vingt-cinq lieues].\n",
      "\n",
      "Kennedy remarqua que la route se dirigeait vers le mari de mans\n",
      "sense.\n",
      "\n",
      "C\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1856\n",
      "READ THIS BEFORE YOU DISTRIBUTE YOR ATIES DACLE PARINE LE IN_, THIS\n",
      "RACHANS OR CIllEc TRANTISEL OF THE POSSIBILITY OR UN ED IN DENTHI RONCE\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1880\n",
      "t pas fait ouvrir.A\n",
      "\n",
      "Mais il est braquA, anditionnA A  mon bon, si aussi, quand il ne lui\n",
      "connaissait qu'en rAalitA avec la pluie qui dut\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1841\n",
      "XX\n",
      "\n",
      "\n",
      "D'abord je ne crois pas de visite quand il avait de la\n",
      "vue d'un de veritable panacle de la langue du bois de Skersnaw, il\n",
      "etait de\n",
      "\n",
      "Iteration nb : 780\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1863\n",
      "(any work on which the\n",
      "phrase \"Project Gutenberg\" appears, or with which the phrase \"Project\n",
      "Gutenberg\" is associated) is accessed, displa\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1862\n",
      "4 breg. Legend\n",
      "this are of the Project Gutenberg-tm trademark, but he\n",
      "     has agreed to donate royalties under this paragraph to the\n",
      "   \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1852\n",
      "Gun-Club.\n",
      "\n",
      "Les drassines contredurienns A  construire, se comportenaire A  celui de la\n",
      "structure, une croyance aveu malheureuse laissant \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1858\n",
      "Les soiranes, n'etait pas misex tout a fait.\n",
      "\n",
      " A  la consciente verte, que l'on m'avait racontA avoir passA la lettre adressAe par Combray\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1861\n",
      "/copyright) agreement.  If you do not agree to abide by all\n",
      "the terms of this agreement, you must cease using and return or destroy\n",
      "all co\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1845\n",
      "0 West, Salt Lake City, UT 84116, (801) 596-1887, email\n",
      "business@pglaf.org.  Email contact links and up to dath cents and expeding athingt \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1864\n",
      "ve au versant oppose, et que l'abime se presenta\n",
      "devant lui, Joe, par un vieux hypotreuse, bleuvoir qui le\n",
      "passa et contre les encores aca\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1845\n",
      "Halley ont\n",
      "pris pour des phAnomA nes lunaires des phAnomA nes purement trA s offris et lA  et\n",
      "son intelligence, plus curieux qui ne pouvai\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1852\n",
      "me sembla desseche!\n",
      "\n",
      "Mais comment avais-je abandonne le cours du ruisseau?  Car,\n",
      "enfin, il n'etait pas acquelement vers chameur le massif\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1860\n",
      "ment de son Ame, le\n",
      "fer, aussi du monde. Vous savez que cela fAt A  plus puissans\n",
      "mon esprit, d'ailleurs que je ne devais pas demandA rais\n",
      "\n",
      "Iteration nb : 790\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1867\n",
      "The Project Gutenberg Literary Archive Foundation, the owner of the Project\n",
      "Gutenberg-tm trademark, and any other party distributing a Proj\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1859\n",
      "A  des caractA res informes qui eussent signifiA peut-Aatre\n",
      "pour des yeux moins prAvenus le dAsordre de s'occuper voirissinA\n",
      "une sorte de \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1856\n",
      "e personne et des Agards pour son\n",
      "transpertir, que ceux-lA  ne m'eAt pas AtA plus douce pour recommencer A  son inaccemence. Un plaisir\n",
      "mo\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1857\n",
      "Gutenberg-tm is synonymous with the free distribution of\n",
      "electronic works in formats readable by the widest variety of computers\n",
      "including\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1851\n",
      "***\n",
      "This and all associated files of various formats will be found in:\n",
      "        http://www.gutenberg.org/2//copiration.  Une the\n",
      "    halle\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1846\n",
      "our de la fAate de sa coterie. Tout dangereux flottaient A \n",
      "l'exaltation que m'avait maliA le poste de mAdicates, le vent larA marbre\n",
      "deva\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1855\n",
      "600 a 700 pieds, le ballon aurait eu une\n",
      "tendance a descendre plus loin au lui si les contrees se deversaient sur les\n",
      "difficultes; il y le\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1855\n",
      "4, s'elanca sur les conversations de la\n",
      "grande salle a Reykjawik, d'un livre japonais celle de Hans, qui\n",
      "tenait cette fois-llance du jour,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1859\n",
      "ous les avons videes, dit Kennedy.\n",
      "\n",
      "--Jetez-les.\n",
      "\n",
      "--Voila! fit Joe. C'est triste de s'en aller mon petit.\n",
      "\n",
      "--Mon cher Dick, tu nous au\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.1857\n",
      "bles de gens vous Aates!  s'AcriA rent les trois colcA s\n",
      "de la Vivonne, se regarda avec une de ces femmes, de sans trop faire\n",
      "connue, s'il\n",
      "\n",
      "Iteration nb : 800\n",
      "Stopping...\n"
     ]
    }
   ],
   "source": [
    "#batch size equals to seq length here\n",
    "BATCH_SIZE=100\n",
    "#len of desired output\n",
    "GENERATE_LENGTH=140\n",
    "DIR=out_path+\"weights/weight_attempt_s03/\"\n",
    "flag=True\n",
    "\n",
    "try:\n",
    "    onlyfiles = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "    iteration=[]\n",
    "    for files in onlyfiles:\n",
    "        iteration.append(int(get_iternb(files)))\n",
    "    iteration=max(iteration)\n",
    "\n",
    "    last_checkpoint=DIR+onlyfiles[0][0:21]+str(iteration)+'.hdf5'\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    onlyfiles=[]\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "    nb_files=0\n",
    "\n",
    "if nb_files>0:\n",
    "    model.load_weights(last_checkpoint)\n",
    "else:\n",
    "    iteration=0\n",
    "    \n",
    "print(\"Starting at iteration : %s\" %iteration)\n",
    "while flag==True:\n",
    "    print('\\n')\n",
    "    print('-'*20)\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, verbose=2, nb_epoch=1)\n",
    "    iteration += 1\n",
    "    bla=generate_text(model, GENERATE_LENGTH,VOCAB_SIZE, indices_char)\n",
    "    if iteration % 10 == 0:\n",
    "        print(\"\\n\\nIteration nb : %s\" %iteration)\n",
    "        #api.PostUpdate(status=bla[0:123])\n",
    "        model.save_weights(DIR+'checkpoint_{}_epoch_{}.hdf5'.format(HIDDEN_DIM, iteration))\n",
    "        #remove unecessary files:\n",
    "        for files in onlyfiles:\n",
    "            try:\n",
    "                if files:\n",
    "                    os.remove(DIR+files)\n",
    "            except:\n",
    "                pass\n",
    "        onlyfiles = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "\n",
    "    if iteration>=800:\n",
    "        print(\"Stopping...\")\n",
    "        flag=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Generate text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    if not os.path.exists(out_path+\"generate/\"):\n",
    "        os.makedirs(out_path+\"generate/\")\n",
    "    with open(out_path+\"generate/output.txt\",\"w\") as f:\n",
    "        f.write(('').join(y_char))\n",
    "    return ('').join(y_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seed with particular text:\n",
    "def generate_text_seeded(model,seed,length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    # char_indices\n",
    "    ix = [char_indices[x] for x in seed]\n",
    "    y_char = [x for x in seed]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(len(ix)) :\n",
    "        X[0, i, :][ix[i]] = 1\n",
    "        print(ix_to_char[ix[i]], end=\"\")\n",
    "    to_substract = len(ix)\n",
    "    for i in range(length-to_substract):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le roi est mort  aupassett aude de leur plus de cinq cents\n",
      "livres; en bienhe soutenue filpacorie, s'eloignait\n",
      "des souffrances et d'ascendions avec eux qu'il n'eut pas le courage; il\n",
      "semblait qu'il ne pouvait enliver, il se complaisait de son arrivee aux travaux des capitaines\n",
      "Burton et Speke a faire un terrain superbatif, et les trois mille\n",
      "appelees s'est evidemment sculptee a sa nuit\n",
      "de chair et d'activite. Le docteur fit le plus complet.\n",
      "\n",
      "Le vent, que nous l'avions apportee au moyen d'un cote et\n",
      "descend d'epsace la lange de Zinzereun Fergusson.\n",
      "\n",
      "Messieurs, dit le docteur, nous n'avons pas traverse!\n",
      "\n",
      "--D'ailleurs, vous venez a deje devant nous, disait le professeur en decoulant\n",
      "des courants stuptu soudent la perspective de m'envoyant\n",
      "encore! Mais il est de monter a degurer notre\n",
      "adroit de son habitude. A  l'explosion couverte de leur apprendre et en\n",
      "laissant filer nos viergeants.\n",
      "\n",
      " En effet, c'etaient des appareils, des heures, la densition de mon\n",
      "inglieusement eta"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u\"le roi est mort aupassett aude de leur plus de cinq cents\\r\\nlivres; en bienhe soutenue filpacorie, s'eloignait\\r\\ndes souffrances et d'ascendions avec eux qu'il n'eut pas le courage; il\\r\\nsemblait qu'il ne pouvait enliver, il se complaisait de son arrivee aux travaux des capitaines\\r\\nBurton et Speke a faire un terrain superbatif, et les trois mille\\r\\nappelees s'est evidemment sculptee a sa nuit\\r\\nde chair et d'activite. Le docteur fit le plus complet.\\r\\n\\r\\nLe vent, que nous l'avions apportee au moyen d'un cote et\\r\\ndescend d'epsace la lange de Zinzereun Fergusson.\\r\\n\\r\\nMessieurs, dit le docteur, nous n'avons pas traverse!\\r\\n\\r\\n--D'ailleurs, vous venez a deje devant nous, disait le professeur en decoulant\\r\\ndes courants stuptu soudent la perspective de m'envoyant\\r\\nencore! Mais il est de monter a degurer notre\\r\\nadroit de son habitude. A  l'explosion couverte de leur apprendre et en\\r\\nlaissant filer nos viergeants.\\r\\n\\r\\n En effet, c'etaient des appareils, des heures, la densition de mon\\r\\ninglieusement etai\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text_seeded(model,normalize('NFKD',\"le roi est mort \".decode('latin1')), 1000, VOCAB_SIZE, indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our de la voir, celle-ci\n",
      "Atait lourdA et magnifique.  Il apercevait qu'il fallait laigner\n",
      "s'il ne l'a pas renouveler l'habitude.\n",
      "\n",
      "Le mont PArous, que dA s que j'eus reconnu le plus de vrai, et A  aucune autre question a\n",
      "l'excussionnalitA, la verdure de ses cheveux de plus de cinq pouces\n",
      "au projectile.  Mais auprA s d'eux, tous les deux. Le honneme sentiment\n",
      "rompu que son regard s'arrAata, un instant de la vivanon ligne de l'honorable EuropAenne: car\n",
      "certaines fAates de la fonte de fonte peuvent Aatre retard et qui\n",
      "malhent comme une pAtille angalotique, M. de Forcheville, Swann de\n",
      "s'orateur, parmi les sapaquements relatifs aux accessoires A  l'amour du tableau ne vint A  l'antillitA, qui passait la\n",
      "souscription profession d'access pour les enveloppes de son zenet.\n",
      "\n",
      "Pendant une heure aprA s, elle s'interloguA intire quand il apercevait, aprA s avoir\n",
      "rApondre avec calleurs, au coin de ses ouvrages cordiges de ses attachAtes. OA1\n",
      "pour mon compte, meme souscription agrAmAe: un Acla frisque je ferai pour la personne, comme un\n",
      "dimagnation inferieure.  Aussi le connais bien que ce fAt A  celle que je crainais ce\n",
      "souffle (il avec les soirs oA1 il n'avait pas besoin de retrouver un de\n",
      "ceux de toile toutes les douceurs, et le docteur avait AtA amenAs A  respirer\n",
      "n'est qu'une habituence bien que je n'aurais pu sortir A  moi. Mais de la Lune, nous en\n",
      "rencontrA, rApondit-il simule, il y a encore aucune peuve famille ou\n",
      "maintenait sur ma couche d'une fleur pour montrer,CPU times: user 6min 11s, sys: 1.72 s, total: 6min 13s\n",
      "Wall time: 6min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = save_text(model, 1500, VOCAB_SIZE, indices_char)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
