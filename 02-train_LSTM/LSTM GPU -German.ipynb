{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/duc-vinh/anaconda2/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout,TimeDistributed\n",
    "from keras.layers import LSTM,SimpleRNN\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os, os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from unicodedata import normalize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- ### Check GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/gpu:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Check and set Twitter's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-27 20:45:00.084187. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import twitter\n",
    "api = twitter.Api(consumer_key='LyNVanTEQEOEGKfXAMeLv6AKG',\n",
    "                    consumer_secret='0lJvhaaOP5cRZWm6rxwyBIAypd1P7eiDx9f74KBDlLrSldNuBQ',\n",
    "                    access_token_key='855852332034265088-geTEVmA7xIsOD3WCZyfBNnqjRdS1MhW',\n",
    "                    access_token_secret='kJMwMl67e3nYrqaGWzIizxzQpRZhtBfOnwPflO1fk3cOt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Sat Apr 22 18:34:31 +0000 2017\", \"default_profile\": true, \"description\": \"Learning how to be creative\", \"followers_count\": 2, \"friends_count\": 1, \"id\": 855852332034265088, \"lang\": \"en\", \"location\": \"Somewhere in the cloud\", \"name\": \"ArtistBot\", \"profile_background_color\": \"F5F8FA\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/855852332034265088/1492892354\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/855878764143804417/r55Z2Js5_normal.jpg\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"screen_name\": \"TheTalkativeBot\", \"status\": {\"created_at\": \"Tue Apr 25 22:31:31 +0000 2017\", \"id\": 856999137753145349, \"id_str\": \"856999137753145349\", \"in_reply_to_screen_name\": \"TheTalkativeBot\", \"in_reply_to_status_id\": 856894659007844352, \"in_reply_to_user_id\": 855852332034265088, \"lang\": \"en\", \"media\": [{\"display_url\": \"pic.twitter.com/lMV1EeegY0\", \"expanded_url\": \"https://twitter.com/TheTalkativeBot/status/856999137753145349/photo/1\", \"id\": 856999135043620864, \"media_url\": \"http://pbs.twimg.com/media/C-SsLDkXkAAvT-S.jpg\", \"media_url_https\": \"https://pbs.twimg.com/media/C-SsLDkXkAAvT-S.jpg\", \"sizes\": {\"large\": {\"h\": 1200, \"resize\": \"fit\", \"w\": 900}, \"medium\": {\"h\": 1200, \"resize\": \"fit\", \"w\": 900}, \"small\": {\"h\": 680, \"resize\": \"fit\", \"w\": 510}, \"thumb\": {\"h\": 150, \"resize\": \"crop\", \"w\": 150}}, \"type\": \"photo\", \"url\": \"https://t.co/lMV1EeegY0\"}], \"source\": \"<a href=\\\"http://www.google.com\\\" rel=\\\"nofollow\\\">TheScenarioBot</a>\", \"text\": \"@dvp_tran Here what's your picture evokes to me ! https://t.co/lMV1EeegY0\"}, \"statuses_count\": 41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-27 20:45:00.534350. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "api.PostUpdate(\"Today I am learning German, watch me improve! ;) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Learning from corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. Load and convert data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done concatenating file : 2146-8.txt\n",
      "Done concatenating file : 2779-8.txt\n",
      "Done concatenating file : 2409-8.txt\n",
      "Done concatenating file : 4013-8.txt\n",
      "Done concatenating file : 2947-8.txt\n",
      "Done concatenating file : 3498-8.txt\n",
      "Done concatenating file : 2314-8.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-27 20:45:00.978848. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#Load and concatenate files:\n",
    "\n",
    "DIR=\"../../LSTM/data/Gutenberg/ebooks-unzipped/German/\"\n",
    "all_files = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "\n",
    "#choose how many files to concatenate:\n",
    "nb_files=7\n",
    "if nb_files>len(all_files):\n",
    "    nb_files=len(all_files)\n",
    "    \n",
    "    \n",
    "out_path=\"german/data/\"\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "if not os.path.exists(out_path+\"input/\"):\n",
    "    os.makedirs(out_path+\"input/\")\n",
    "    \n",
    "with open(out_path+'input/german.txt', 'w') as outfile:\n",
    "    for fname in all_files[0:nb_files]:\n",
    "        with open(DIR+fname) as infile:\n",
    "            i=0\n",
    "            for line in infile:\n",
    "                if i>=50:\n",
    "                    outfile.write(line)\n",
    "                i=i+1\n",
    "        print (\"Done concatenating file : %s\" %fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-27 20:45:01.241985. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#load file\n",
    "file_name=out_path+'input/german.txt'\n",
    "text = open(file_name).read()\n",
    "text=normalize('NFKD',text.decode('latin1')).encode('ASCII', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-27 20:45:01.365770. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#text = text.replace(to_delete,\"\").replace('Digitized by',\"\").replace('Google',\"\") \n",
    "text = re.sub(\"\\n\\n+\" , \"\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 2215861\n",
      "total chars: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-27 20:45:01.386392. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "VOCAB_SIZE = len(chars)\n",
    "print('total chars:',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** The RNN takes in input numerical data hence the necessity to convert strings into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-27 20:45:01.509417. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#creating mapping between indexes and characters\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re gonna use Keras to create and train our Network, so we must convert the data into this form: (number_of_sequences, length_of_sequence, number_of_features).\n",
    "- nb of features = length of the char array\n",
    "- length of sequence = batch size\n",
    "- nb of sequence = len(data) divided by batch size.\n",
    "\n",
    "**Warning : ** target sequence is setted by shifting the source/input sequence by one character with both having the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.06 s, sys: 204 ms, total: 2.26 s\n",
      "Wall time: 2.27 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-27 20:45:01.576155. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "SEQ_LENGTH=100\n",
    "#Build three dimensional arrays\n",
    "X = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #input\n",
    "y = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #target\n",
    "\n",
    "#Build sequences\n",
    "for i in range(0, len(text)/SEQ_LENGTH):\n",
    "    X_sequence = text[i*SEQ_LENGTH:(i+1)*SEQ_LENGTH]\n",
    "    X_sequence_ix = [char_indices[value] for value in X_sequence]\n",
    "    input_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "    X[i] = input_sequence\n",
    "\n",
    "    y_sequence = text[i*SEQ_LENGTH+1:(i+1)*SEQ_LENGTH+1]\n",
    "    y_sequence_ix = [char_indices[value] for value in y_sequence]\n",
    "    target_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        target_sequence[j][y_sequence_ix[j]] = 1.\n",
    "    y[i] = target_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. Build the network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-27 20:45:04.503872. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM= 500 #500\n",
    "LAYER_NUM = 2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "for i in range(LAYER_NUM - 1):\n",
    "    model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-27 20:45:09.047030. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Af}}k!<<<jjj---XSSS,d<<<jjj---Bdddddppp######IPZ     \"\"\"1111b[[[lllxbb0nnn[[kOOOO####}}     \"\"\"X7XN"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-27 20:45:09.055077. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# Generate some sample before training to know how bad it is!\n",
    "bla = generate_text(model, 100, VOCAB_SIZE, indices_char)\n",
    "#api.PostUpdate(status=bla[0:123])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Train network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-27 20:45:16.482911. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "def get_iternb(string):\n",
    "    return re.findall(r'checkpoint_500_epoch_(.*).hdf5', string)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at iteration : 450\n",
      "\n",
      "\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/site-packages/keras/models.py:834: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "258s - loss: 0.1558\n",
      "$K. Welche ohne Schaffe sei nicht nach;\n",
      "Sie sind die Lindenbuch, die zwei verbrennen!\n",
      "Doch im nachtlichen Gehnal hat die krufte Haus,\n",
      "Dru\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1242\n",
      ") da ein Anderer, der sich die\n",
      "Fehler dieser Vorganger zu Nutzen zu machen wite, wenig Muhe haben wurde, wenn er sich\n",
      "befordern, nicht als\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1194\n",
      "You provide, or agree to also provide on request at\n",
      "          no additional cost, fee or expense, a copy of the\n",
      "          etext in its ori\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1178\n",
      "(welches auf eine oder die\n",
      "andere Art doch allemal der stillschweigende Vorsatz einer jeden ist, die Krankunftigkeit\n",
      "des Prinzen hatte ich\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1161\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aus der Harzreise\n",
      "1824\n",
      "\n",
      "\n",
      "Prolog\n",
      "\n",
      "Schwarze Rocke, seidne Strumpfe,\n",
      "Weie, hofliche Manspier die Zange machten\n",
      "Mir fur den Stu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1177\n",
      "6. Der Lauf des Mondpfades ist fur die Gerechten Licht, aber fur die Sunder\n",
      "ist er Finsternis, in den Augen der vornehmigen Freunde schreib\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1141\n",
      "y to:\n",
      "\n",
      "Michael S. Hart <hart@pobox.com>\n",
      "\n",
      "hart@pobox.com forwards to hart@prairienet.org and archive.org\n",
      "if your mail bounces from archi\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1135\n",
      "2. Wasser flo gegen den Berg herab, und sollten ihre Liebe zu ihm, und\n",
      "ihn auch von Summen verschmahten den Herrn der Geister. Und sie werd\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1131\n",
      "'s wahr?  Ist er verurteilt?\n",
      "\n",
      "Brackenburg.  Er ist's!  Ich wei es ganz genau.\n",
      "\n",
      "Klarchen.  Und leb' und bore Provinz!\n",
      "Geogrtes Hohe!\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1130\n",
      "XXXIII\n",
      "\n",
      "Sie liebten sich beide, doch keiner\n",
      "Wollt es dem andern gestehn;\n",
      "Sie sahen sich an so fein alles in seiner Zeit,\n",
      "Wie Leuten sin\n",
      "\n",
      "Iteration nb : 460\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "255s - loss: 0.1125\n",
      "bei den alten\n",
      "Griechen lange nicht so selten war, ein Trinkferrachte seyn?--und Kinder, Fliegen\n",
      "und Vorscheinungen wenden ihr euch so gar \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1116\n",
      "Herz.  Der erste\n",
      "letzte sich darum zu ihm nahm zu schreiben, uns ich mochte kein einziges\n",
      "Frau.  Als Erzahlung war es so!  Freilich\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1130\n",
      "Anstalten, sich in\n",
      "Besitz zu setzen, nicht verbergen.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Zweites Kapitel\n",
      "\n",
      "\n",
      "\n",
      "Sangen fuhrte mich angenommen.  Da meine \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1125\n",
      "{\n",
      "Freunde vorlieen die Furcht beschiedeter Bewohner zuruck zu erwerben.\n",
      "Er aber hatte zu ruhieren, fur welche seine Weise an einem Anstauf,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1132\n",
      "n den Handen, und hierauf\n",
      "die Raubritter, Rauber, Monche, Nonnen, Geister und\n",
      "Gespenster aus der Homer und der Welt,\n",
      "4. der Mangel an Hol\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "255s - loss: 0.1104\n",
      " die Sache beim richtigen\n",
      "Namen genannt, um eine rein personliche Abschrecke und\n",
      "eine Erlosund uber mich zu werden anfind, an ware ich mir\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1104\n",
      ">\n",
      "\n",
      "Der Titel Hutter sei, so mu ich dich liebe,\n",
      "  Der Weisheit ruht wollt ich einst auf dem Landbebanne,\n",
      "  Und kehrt sich leicht gleich e\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1105\n",
      "Ihr Verdorrte am Herzen, kein Friede wird euch zu Teil werden!\n",
      "6. Darum werdet ihr eure Tage verfluchen, und aus dem Ende des Himmels, welc\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "255s - loss: 0.1101\n",
      "Anstalten, sich in\n",
      "Besitz zu setzen, nicht verbergen.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Zweites Kapitel\n",
      "\n",
      "\n",
      "\n",
      "Sankam Regent allem schlauende Hof,\n",
      "Geiste\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1102\n",
      "____________________________________________________________________________________________________________________________________________\n",
      "\n",
      "Iteration nb : 470\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1098\n",
      "Mark und\n",
      "drei Teufel, und sein Haupt und der Herr der Herrlichkeit und der\n",
      "Gerechten sie wegen der Sonder; denn du, kurzet euch jene Schaf\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "255s - loss: 0.1105\n",
      "und der Freiheit\n",
      "des einbrechenden Tages steigt Egmont frohlich entgegen.  Wie manch\n",
      "bekannt Gesichter, den ich mir also sehr gerne zu hab\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1105\n",
      "Zeit ein Apelles gewegen ware, und um noch forts und\n",
      "wir zu halten und das Schwert des Herrn Caraas und reichte die nutzliche Stelle.\n",
      "\n",
      "  \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1098\n",
      "8. Und nun ist kurz die Ruhe, welche wir wunschen, aber wir werden (sie)\n",
      "nicht finden; wir mochten sie nicht fremden, welche auf der Erde, \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1109\n",
      "Cardauns\n",
      "glauben, das wei ich nicht; ich kann da nur vermuten.\n",
      "Was sie behaupten, gilt fur mich noch festgespen,\n",
      "Haust in der Welt, das m\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1089\n",
      "ben, so prophetisch war er) stellte ihm die\n",
      "Notwendigkeit der schleunigsten Flucht so dringend vor, da ich mich richte, da ich\n",
      "jetzt nun v\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1104\n",
      "zu erreichen, gibt er die hier in     |\n",
      "| Arbeit liegende Broschure heraus.                |\n",
      "\n",
      "|     Der \"Vorwarts\" hat Karl May als ich w\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1098\n",
      "; sie wurde aber, als man\n",
      "nach ihr suchte, gefunden.  So vernichtete mich also die\n",
      "Luge, anstatt da es meine Begriffe, seine Rat und Dien \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1084\n",
      "4.\n",
      "\n",
      "Endlich wird recht die blaue, und ein kreiser Blumleik im Busen trief gewissen.\n",
      "\n",
      "Silva.  Und nun zeigt, damit Sie herzugeht der Koni\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1107\n",
      "90 through etext99 or etext00 through etext02, etc.\n",
      "dir [to see files]\n",
      "get or mget [to get files. . .set bin for zip files]\n",
      "GET GUTINDEX.\n",
      "\n",
      "Iteration nb : 480\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1093\n",
      "Qualt mich Erinnerung, da ich verubet\n",
      "war ich, da das Herz ist nur und ganzlich abscheinen, da\n",
      "Mitgal ist Bacchunsitzen, Ihre Nachten und \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1088\n",
      "Clonarion mit der noch\n",
      "unmundigen Psyche eine hinlangliche Summe Gelds ubergeben, und befohlen,\n",
      "sieht er der Stadt, und in der Luge waren \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1091\n",
      "welche in der Bestrebung, uber die Grenzen des menschlichen Verstandes\n",
      "hinauszugehen, verungluckt waren; so hatte er doch ohne Umgebung nac\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "255s - loss: 0.1088\n",
      "~\n",
      "2: Or aderion, soltere, Ku Dana,\n",
      "Dein sitzferwirtet anderes Reich;\n",
      "Bit er die Arbeit ist durch Klugen Brannte und Bettlergebein,\n",
      "Ihn di\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1088\n",
      "n darstellt.\"  Er blickte zu gleicher Zeit\n",
      "nach der Ture und sah die Mutter Gottes von gestern mit den Staunen stieh,\n",
      "der da sich durch di\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1083\n",
      "Herz dieses Prinzen in deiner\n",
      "Hand zu haben, du der sich das groe Werk zutraute, einen Weisen und\n",
      "tun das Land hinaus, um mit den Fall neu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1089\n",
      "; wohin, wohin, das beachtete ich gar\n",
      "nicht.  Es kam mir vor, als ob die inneren Gestalten aus\n",
      "mir herubt, und in einem Lichte finden nach\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1080\n",
      "quemen voranzusteigen hat, um das von unsern\n",
      "Pionat gesehen, noch einige Jahre fur seche Stunde vor\n",
      "Angstlange immer Geheimnis der ehrlich\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1088\n",
      "Proce den Redlichen betrogen;\n",
      "Des Tagelohners Blut, der Witwen Schwei gesogen,\n",
      "Und sich davon ein Hutalicker Horr,\n",
      "Was nur der Mund und W\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1083\n",
      "1739 University Ave.\n",
      "Oxford, MS 38655-4109\n",
      "\n",
      "\n",
      "The Project Gutenberg Literary Archive Foundation is a Priblicty; and and you!  It\n",
      "and by \n",
      "\n",
      "Iteration nb : 490\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1085\n",
      "m groen Tiere, und an ihm, auf seinem Kopfe, waren groe schwarze\n",
      "Horner.\n",
      "48. Und der Herr der Schafe ward zornig uber sie in groem Zorn, u\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1083\n",
      "90 through etext99 or etext00 through etext01, etc.\n",
      "dir [to see files]\n",
      "get or mget [to get files. . .set bin for zip files]\n",
      "GET GUTINDEX.\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1080\n",
      "Jahre Polizeiaufsicht.  So schwer es mir fallt,\n",
      "dies fur die Oeffentlichkeit niederzuschreiben, da ich den Schung\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "des weisen Spiel der Net\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1097\n",
      "8. Und nun ist kurz den Herrn der Herrlichkeit, der in unserer Seele  sagte: \"Und wenn ist es einst zu vermeiden,\n",
      "welches ich verwundern, d\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1084\n",
      "Geschaftspolitik, deren Wirkungen ich\n",
      "erst spater und obfahrener mir zu lesen anfing, nablechte er den erstaunten, der in hohemaligen\n",
      "Tage\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1075\n",
      "Kapitel: Veranderung der Szene. Charakter der Syracusaner,\n",
      "                    des Dionysius und seine Garbe,\n",
      "wo Pilhaso naturhierte ihm m\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "255s - loss: 0.1083\n",
      "\n",
      "Waagschale einer kalten unparteiischen uberlegung gemacht, und vermutlich\n",
      "den entgegenstehenden Grundsatzen das Buch wir, so hatte er\n",
      "wo\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1076\n",
      "Ihr Mann\n",
      "war stolz darauf.  Noch stolzer fast war ihre Mutter,\n",
      "eine einfach gewohnte, sehr arbeitsam, ihne mir\n",
      "menschlich man schon erzub\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1082\n",
      "8. Und nun ist kurz die Ruhe, welche wir wunderbirt, die Hand der\n",
      "Helden, und wurden bestehen das Gebet der Sonne.\n",
      "4. Da sahen meine Augen\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "256s - loss: 0.1076\n",
      "Carnegie-Mellon University, and an\n",
      "assortment of sporadic gifts; this salary is only good for a few\n",
      "more years, so we are looking for some\n",
      "\n",
      "Iteration nb : 500\n",
      "Stopping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-27 20:45:16.487355. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#batch size equals to seq length here\n",
    "BATCH_SIZE=300\n",
    "#len of desired output\n",
    "GENERATE_LENGTH=140\n",
    "DIR=out_path+\"weights/weight_attempt_s02/\"\n",
    "flag=True\n",
    "\n",
    "try:\n",
    "    onlyfiles = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "    iteration=[]\n",
    "    for files in onlyfiles:\n",
    "        iteration.append(int(get_iternb(files)))\n",
    "    iteration=max(iteration)\n",
    "\n",
    "    last_checkpoint=DIR+onlyfiles[0][0:21]+str(iteration)+'.hdf5'\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    onlyfiles=[]\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "    nb_files=0\n",
    "\n",
    "if nb_files>0:\n",
    "    model.load_weights(last_checkpoint)\n",
    "else:\n",
    "    iteration=0\n",
    "    \n",
    "print(\"Starting at iteration : %s\" %iteration)\n",
    "while flag==True:\n",
    "    print('\\n')\n",
    "    print('-'*20)\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, verbose=2, nb_epoch=1)\n",
    "    iteration += 1\n",
    "    bla=generate_text(model, GENERATE_LENGTH,VOCAB_SIZE, indices_char)\n",
    "    if iteration % 10 == 0:\n",
    "        print(\"\\n\\nIteration nb : %s\" %iteration)\n",
    "        #api.PostUpdate(status=bla[0:123])\n",
    "        model.save_weights(DIR+'checkpoint_{}_epoch_{}.hdf5'.format(HIDDEN_DIM, iteration))\n",
    "        #remove unecessary files:\n",
    "        for files in onlyfiles:\n",
    "            try:\n",
    "                if files:\n",
    "                    os.remove(DIR+files)\n",
    "            except:\n",
    "                pass\n",
    "        onlyfiles = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "\n",
    "    if iteration>=500:\n",
    "        print(\"Stopping...\")\n",
    "        flag=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Generate text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-28 00:26:37.364112. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "def save_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    if not os.path.exists(out_path+\"generate/\"):\n",
    "        os.makedirs(out_path+\"generate/\")\n",
    "    with open(out_path+\"generate/output.txt\",\"w\") as f:\n",
    "        f.write(('').join(y_char))\n",
    "    return ('').join(y_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-28 00:26:37.375971. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#seed with particular text:\n",
    "def generate_text_seeded(model,seed,length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    # char_indices\n",
    "    ix = [char_indices[x] for x in seed]\n",
    "    y_char = [x for x in seed]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(len(ix)) :\n",
    "        X[0, i, :][ix[i]] = 1\n",
    "        print(ix_to_char[ix[i]], end=\"\")\n",
    "    to_substract = len(ix)\n",
    "    for i in range(length-to_substract):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich bin  kh Alssirr nicht erwahnen.\n",
      "\n",
      "Es ist ein schones Wort, das verrater schlafen,\n",
      "Und was denn"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'ich bin kh Alssirr nicht erwahnen.\\r\\n\\r\\nEs ist ein schones Wort, das verrater schlafen,\\r\\nUnd was denn '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-28 00:26:37.519624. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "generate_text_seeded(model,normalize('NFKD',\"ich bin \".decode('latin1')), 100, VOCAB_SIZE, indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "Freund by th' err of our etext refund of ther cannon by the Project Gutenberg legal advisor**\n",
      "\n",
      "(Three Pages)\n",
      "\n",
      "\n",
      "***START**THE SMALL PRINT!**FOR PUBLIC DOMAIN ETEXTS**START***\n",
      "Why is this \"Small Print!\" statement here?  You know: lawyers.\n",
      "They tell us you might sue us if there is something wrong with\n",
      "your copy of this etext, even if you got it for free from\n",
      "someone other than us, and even if what's wrong is not our\n",
      "fault.  So, among other things, this \"Small Print!\" statement\n",
      "disclaims most of our liability to you.  It also tells you how\n",
      "you can distribute copies of this etext if you want to.\n",
      "\n",
      "*BEFORE!* YOU USE OR READ THIS ETEXT\n",
      "By using or reading any part of this PROJECT GUTENBERG-tm\n",
      "etext, you indicate that you understand, agree to and accept\n",
      "this \"Small Print!\" statement.  If you do not, you can receive\n",
      "a refund of the money (if any) you paid for this etext by\n",
      "sending a request within 30 days of receiving it to the person\n",
      "you got it from.  If you received this etext on a physical\n",
      "medium (such as a disk), you must return it with your request.\n",
      "\n",
      "ABOUT PROJECT GUTENBERG-TM ETEXTS\n",
      "This PROJECT GUTENBERG-tm etext, like most PROJECT GUTENBERG-tm etext, like most PROJECT GUTENBERG-tm etexts,\n",
      "is a \"public domain\" work distributed by Professor\n",
      "Michael S.  Hart through the Project Gutenberg Literary\n",
      "Archive Foundation and with by wist nor our ation by the arthor to the etext collections, use FTP or any\n",
      "Web browser to visit a Project Gutenberg mirror (mirCPU times: user 13min 25s, sys: 3min 28s, total: 16min 54s\n",
      "Wall time: 16min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-28 00:26:41.675267. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = save_text(model, 1500, VOCAB_SIZE, indices_char)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
