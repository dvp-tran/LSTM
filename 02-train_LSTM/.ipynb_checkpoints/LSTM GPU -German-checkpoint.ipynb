{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/duc-vinh/anaconda2/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout,TimeDistributed\n",
    "from keras.layers import LSTM,SimpleRNN\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os, os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from unicodedata import normalize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- ### Check GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/gpu:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Check and set Twitter's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-25 03:42:31.645632. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import twitter\n",
    "api = twitter.Api(consumer_key='LyNVanTEQEOEGKfXAMeLv6AKG',\n",
    "                    consumer_secret='0lJvhaaOP5cRZWm6rxwyBIAypd1P7eiDx9f74KBDlLrSldNuBQ',\n",
    "                    access_token_key='855852332034265088-geTEVmA7xIsOD3WCZyfBNnqjRdS1MhW',\n",
    "                    access_token_secret='kJMwMl67e3nYrqaGWzIizxzQpRZhtBfOnwPflO1fk3cOt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Sat Apr 22 18:34:31 +0000 2017\", \"default_profile\": true, \"description\": \"Learning how to be creative\", \"followers_count\": 2, \"friends_count\": 3, \"id\": 855852332034265088, \"lang\": \"en\", \"location\": \"Somewhere in the cloud\", \"name\": \"ArtistBot\", \"profile_background_color\": \"F5F8FA\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/855852332034265088/1492892354\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/855878764143804417/r55Z2Js5_normal.jpg\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"screen_name\": \"TheTalkativeBot\", \"status\": {\"created_at\": \"Mon Apr 24 13:46:57 +0000 2017\", \"id\": 856504737352601601, \"id_str\": \"856504737352601601\", \"in_reply_to_screen_name\": \"dvp_tran\", \"in_reply_to_status_id\": 856504560373911552, \"in_reply_to_user_id\": 747074580754403328, \"lang\": \"en\", \"source\": \"<a href=\\\"http://www.google.com\\\" rel=\\\"nofollow\\\">TheScenarioBot</a>\", \"text\": \"@dvp_tran Automate answer !\"}, \"statuses_count\": 47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-25 03:42:31.692501. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "api.PostUpdate(\"Today I am learning German, watch me improve! ;) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Learning from corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. Load and convert data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done concatenating file : 2499-8.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-25 03:42:32.846133. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#Load and concatenate files:\n",
    "\n",
    "DIR=\"../../LSTM/data/Gutenberg/ebooks-unzipped/German/\"\n",
    "all_files = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "\n",
    "#choose how many files to concatenate:\n",
    "nb_files=7\n",
    "if nb_files>len(all_files):\n",
    "    nb_files=len(all_files)\n",
    "    \n",
    "    \n",
    "out_path=\"german/data/\"\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "if not os.path.exists(out_path+\"input/\"):\n",
    "    os.makedirs(out_path+\"input/\")\n",
    "    \n",
    "with open(out_path+'input/german.txt', 'w') as outfile:\n",
    "    for fname in all_files[0:nb_files]:\n",
    "        with open(DIR+fname) as infile:\n",
    "            i=0\n",
    "            for line in infile:\n",
    "                if i>=50:\n",
    "                    outfile.write(line)\n",
    "                i=i+1\n",
    "        print (\"Done concatenating file : %s\" %fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-25 03:42:32.861870. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#load file\n",
    "file_name=out_path+'input/german.txt'\n",
    "text = open(file_name).read()\n",
    "text=normalize('NFKD',text.decode('latin1')).encode('ASCII', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-25 03:42:32.989221. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#text = text.replace(to_delete,\"\").replace('Digitized by',\"\").replace('Google',\"\") \n",
    "text = re.sub(\"\\n\\n+\" , \"\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 235625\n",
      "total chars: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-25 03:42:33.052306. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "VOCAB_SIZE = len(chars)\n",
    "print('total chars:',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** The RNN takes in input numerical data hence the necessity to convert strings into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-25 03:42:33.150699. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#creating mapping between indexes and characters\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weâ€™re gonna use Keras to create and train our Network, so we must convert the data into this form: (number_of_sequences, length_of_sequence, number_of_features).\n",
    "- nb of features = length of the char array\n",
    "- length of sequence = batch size\n",
    "- nb of sequence = len(data) divided by batch size.\n",
    "\n",
    "**Warning : ** target sequence is setted by shifting the source/input sequence by one character with both having the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 208 ms, sys: 16 ms, total: 224 ms\n",
      "Wall time: 222 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-25 03:42:33.201706. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "SEQ_LENGTH=100\n",
    "#Build three dimensional arrays\n",
    "X = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #input\n",
    "y = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #target\n",
    "\n",
    "#Build sequences\n",
    "for i in range(0, len(text)/SEQ_LENGTH):\n",
    "    X_sequence = text[i*SEQ_LENGTH:(i+1)*SEQ_LENGTH]\n",
    "    X_sequence_ix = [char_indices[value] for value in X_sequence]\n",
    "    input_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "    X[i] = input_sequence\n",
    "\n",
    "    y_sequence = text[i*SEQ_LENGTH+1:(i+1)*SEQ_LENGTH+1]\n",
    "    y_sequence_ix = [char_indices[value] for value in y_sequence]\n",
    "    target_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        target_sequence[j][y_sequence_ix[j]] = 1.\n",
    "    y[i] = target_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. Build the network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-25 03:42:33.508556. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM= 500 #500\n",
    "LAYER_NUM = 2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "for i in range(LAYER_NUM - 1):\n",
    "    model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-25 03:42:35.192928. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RbbbbbbMFFFFFeee--jjMM999-9999:::rrv000033099999999::rrBBBBeevvvvMMww@@@@9999999:::rrvv0000330999999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-25 03:42:35.201260. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# Generate some sample before training to know how bad it is!\n",
    "bla = generate_text(model, 100, VOCAB_SIZE, indices_char)\n",
    "#api.PostUpdate(status=bla[0:123])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Train network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-25 03:42:40.380899. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "def get_iternb(string):\n",
    "    return re.findall(r'checkpoint_500_epoch_(.*).hdf5', string)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-vinh/anaconda2/lib/python2.7/site-packages/keras/models.py:834: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at iteration : 10\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "44s - loss: 2.1329\n",
      "Un der Wer der Somanas an der Wer der Somanas an der Wer der Somanasten sor der Wer der Somanasten sor der Wer der Somanasten sor der Wer de\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 2.0250\n",
      "Qaund der Warten seinen und der Wer seinen und der Wer seinen und der Wer seinen und der Wer seinen und der Wer seinen und der Wer seinen un\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.9663\n",
      "9\n",
      " der er er er er er er und er er er und er er er und er er er und er er er und er er er und er er er und er er er und er er er und er er e\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.9190\n",
      "3 der Samanasand auf der Samanasanas der Samanasand auf der Samanasanas der Samanasand auf der Samanasanas der Samanasand auf der Samanasana\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.8638\n",
      "5\n",
      " dieser dieser der Siddhartha sie einem sieden sie er sie er sieben, war der Siddhartha sieben sie er sie er sieben, war der Siddhartha si\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.8172\n",
      "% der Schalt der Schmand das Schalt der Schalt der Schalt der Schalt der Schalt der Schalt der Schalt der Schalt der Schalt der Schalt der S\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.7671\n",
      "ren sich sie er sich sie er sich sie er sich sie er sich sie er sich sie er sich sie er sich sie er sich sie er sich sie er sich sie er sich\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.7296\n",
      "inder seinen Sternen, das er sich von der Sternen, das er sich von der Sternen, das er sich von der Sternen, das er sich von der Sternen, da\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.6818\n",
      "QZaufte er sich nicht mit der Stante sich der Weiten der Werten und der Stante seine Schleigen und der Stante seine Schleigen und der Stante\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "44s - loss: 1.6421\n",
      "Weinen und dan Samanas auf der Flussen und das er seinen Samanas auf den Flussen und das er seinen Samanas auf den Flussen und das er seinen\n",
      "\n",
      "Iteration nb : 20\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.6082\n",
      "/her seinen Stern und der Stramen seinen Sternen seinen Sternen seinen Sternen seinen Sternen seinen Sternen seinen Sternen seinen Sternen s\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.5700\n",
      "(\n",
      "der Schalten der Flussein und der Stimmen der Flusser der Flu der Stimme seinen Schlief und der Stimmen der Flusser der Flu der Stimme sei\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.5309\n",
      "Genden zu seinen und seiner Sternen, da du mir gescheiten, da er sich nicht mit der Stadt ander dieser Sternen, da er sich von der Stadt and\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.4970\n",
      "/herte sich von der Stadt aus dem Walde seine Stern und der Sterben, der ihn der Welt und der Sterben der Flusse von der Stammen geschehen, \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.4623\n",
      "Hausten sein Leben zu seinem Herzen zu seinen Schmerz und den Stern nicht mehr als den Stern und der Stern und der Stern und der Stern und d\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.4270\n",
      "gen den Togen den Tagen den Weisen der Weisen und den Stimmen der Stadt zu seinem Herzen der Stimme seine Sterben, der ihn nicht von den Sta\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.3965\n",
      "Ich war ein Schlafen, und der Stimmen des Wegen, der Stimmen, der Stimmen, der Stimmen, der Stunde geworden, war er einen Schlafen der Stimm\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.3601\n",
      "ben seine Schlafen haben sie ihn nicht zu seinem Schlafen hast du den Schmerzen den Schlafenden und den Schmerzen des Samanas gesehen hatte,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.3264\n",
      "Geler seine Lehre zu sprechen war das Leben der Stadt geworden.  Da er sah sie ihn zu seinem Hander zu verlassen hatte, das er nicht mehr wa\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.3110\n",
      " der Flu seine Stimme und Geld zuruck und auf der Stimme des Buddha, der Weisen, der ihn nicht vor dem Wegen der Flu schenken, und da er sic\n",
      "\n",
      "Iteration nb : 30\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.2580\n",
      "Hausen beseinet hatten seiner Sterne gesehen hatte,\n",
      "und wenn er seiner Sternen und begannen und begannen und alles alles alles alles alles\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.2326\n",
      "Den Schale und Geschaft, und der Stramen des Geschachtes, der er sich von der Stadt aus der Stadt und der Stadt, und der Sterne und der Ster\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.1985\n",
      "; wenn er nicht mehr sind wie dieser Stimme sich niemals ist ein Schlafen und Weisenden zu sprechen, wie eine Stimme hatte er sie hatte, was\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.1626\n",
      "x\n",
      "eine Stimme hatte er sich von den Schacten und Gelerntenschen war, da er alles letzten Wege zu seinem Hause, und war den Knabe an den Stun\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.1285\n",
      "Y Augenblick erwachtete den Wegen zu den Sprechen zu geben.  Dies\n",
      "Wellte er ihnen hatte er in den Stadt zu denken, da er nicht mehr sindlic\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.0928\n",
      "der sein Herz nicht der Schlaf ihn still und sein Hauster der Brahmanensohn, und da dies nicht mehr solchen war, und da du selbst du mir so \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "43s - loss: 1.0579\n",
      "leigen Beist, und er habe ich geben und der Bettlagen der Stellen, der Siddhartha aber nicht den\n",
      "Schatten der Sananas, der Samana, der Budd\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "#batch size equals to seq length here\n",
    "BATCH_SIZE=100\n",
    "#len of desired output\n",
    "GENERATE_LENGTH=140\n",
    "DIR=out_path+\"weights/weight_attempt_s01/\"\n",
    "flag=True\n",
    "\n",
    "try:\n",
    "    onlyfiles = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "    iteration=[]\n",
    "    for files in onlyfiles:\n",
    "        iteration.append(int(get_iternb(files)))\n",
    "    iteration=max(iteration)\n",
    "\n",
    "    last_checkpoint=DIR+onlyfiles[0][0:21]+str(iteration)+'.hdf5'\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    onlyfiles=[]\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "    nb_files=0\n",
    "\n",
    "if nb_files>0:\n",
    "    model.load_weights(last_checkpoint)\n",
    "else:\n",
    "    iteration=0\n",
    "    \n",
    "print(\"Starting at iteration : %s\" %iteration)\n",
    "while flag==True:\n",
    "    print('\\n')\n",
    "    print('-'*20)\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, verbose=2, nb_epoch=1)\n",
    "    iteration += 1\n",
    "    bla=generate_text(model, GENERATE_LENGTH,VOCAB_SIZE, indices_char)\n",
    "    if iteration % 10 == 0:\n",
    "        print(\"\\n\\nIteration nb : %s\" %iteration)\n",
    "        #api.PostUpdate(status=bla[0:123])\n",
    "        model.save_weights(DIR+'checkpoint_{}_epoch_{}.hdf5'.format(HIDDEN_DIM, iteration))\n",
    "        #remove unecessary files:\n",
    "        for files in onlyfiles:\n",
    "            try:\n",
    "                if files:\n",
    "                    os.remove(DIR+files)\n",
    "            except:\n",
    "                pass\n",
    "        onlyfiles = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "\n",
    "    if iteration>=500:\n",
    "        print(\"Stopping...\")\n",
    "        flag=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Generate text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    if not os.path.exists(out_path+\"generate/\"):\n",
    "        os.makedirs(out_path+\"generate/\")\n",
    "    with open(out_path+\"generate/output.txt\",\"w\") as f:\n",
    "        f.write(('').join(y_char))\n",
    "    return ('').join(y_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "out = save_text(model, 1500, VOCAB_SIZE, indices_char)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
