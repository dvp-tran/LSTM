{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout,TimeDistributed\n",
    "from keras.layers import LSTM,SimpleRNN\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os, os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from unicodedata import normalize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- ### Check GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/gpu:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Check and set Twitter's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "api = twitter.Api(consumer_key='LyNVanTEQEOEGKfXAMeLv6AKG',\n",
    "                    consumer_secret='0lJvhaaOP5cRZWm6rxwyBIAypd1P7eiDx9f74KBDlLrSldNuBQ',\n",
    "                    access_token_key='855852332034265088-geTEVmA7xIsOD3WCZyfBNnqjRdS1MhW',\n",
    "                    access_token_secret='kJMwMl67e3nYrqaGWzIizxzQpRZhtBfOnwPflO1fk3cOt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Sat Apr 22 18:34:31 +0000 2017\", \"default_profile\": true, \"description\": \"Learning how to be creative\", \"followers_count\": 2, \"friends_count\": 1, \"id\": 855852332034265088, \"lang\": \"en\", \"location\": \"Somewhere in the cloud\", \"name\": \"ArtistBot\", \"profile_background_color\": \"F5F8FA\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/855852332034265088/1492892354\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/855878764143804417/r55Z2Js5_normal.jpg\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"screen_name\": \"TheTalkativeBot\", \"status\": {\"created_at\": \"Tue Apr 25 22:31:31 +0000 2017\", \"id\": 856999137753145349, \"id_str\": \"856999137753145349\", \"in_reply_to_screen_name\": \"TheTalkativeBot\", \"in_reply_to_status_id\": 856894659007844352, \"in_reply_to_user_id\": 855852332034265088, \"lang\": \"en\", \"media\": [{\"display_url\": \"pic.twitter.com/lMV1EeegY0\", \"expanded_url\": \"https://twitter.com/TheTalkativeBot/status/856999137753145349/photo/1\", \"id\": 856999135043620864, \"media_url\": \"http://pbs.twimg.com/media/C-SsLDkXkAAvT-S.jpg\", \"media_url_https\": \"https://pbs.twimg.com/media/C-SsLDkXkAAvT-S.jpg\", \"sizes\": {\"large\": {\"h\": 1200, \"resize\": \"fit\", \"w\": 900}, \"medium\": {\"h\": 1200, \"resize\": \"fit\", \"w\": 900}, \"small\": {\"h\": 680, \"resize\": \"fit\", \"w\": 510}, \"thumb\": {\"h\": 150, \"resize\": \"crop\", \"w\": 150}}, \"type\": \"photo\", \"url\": \"https://t.co/lMV1EeegY0\"}], \"source\": \"<a href=\\\"http://www.google.com\\\" rel=\\\"nofollow\\\">TheScenarioBot</a>\", \"text\": \"@dvp_tran Here what's your picture evokes to me ! https://t.co/lMV1EeegY0\"}, \"statuses_count\": 41}\n"
     ]
    }
   ],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "api.PostUpdate(\"Today I am learning German, watch me improve! ;) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Learning from corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. Load and convert data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done concatenating file : 21-0.txt\n",
      "Done concatenating file : 28.txt\n",
      "Done concatenating file : 18.txt\n",
      "Done concatenating file : 13-0.txt\n",
      "Done concatenating file : 16-0.txt\n",
      "Done concatenating file : 51-0.txt\n",
      "Done concatenating file : 30.txt\n",
      "Done concatenating file : 20.txt\n",
      "Done concatenating file : 46-8.txt\n",
      "Done concatenating file : 50.txt\n"
     ]
    }
   ],
   "source": [
    "#Load and concatenate files:\n",
    "\n",
    "DIR=\"../../LSTM/data/Gutenberg/ebooks-unzipped/English/\"\n",
    "all_files = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "\n",
    "#choose how many files to concatenate:\n",
    "nb_files=10\n",
    "if nb_files>len(all_files):\n",
    "    nb_files=len(all_files)\n",
    "    \n",
    "    \n",
    "out_path=\"english/data/\"\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "if not os.path.exists(out_path+\"input/\"):\n",
    "    os.makedirs(out_path+\"input/\")\n",
    "    \n",
    "with open(out_path+'input/english.txt', 'w') as outfile:\n",
    "    for fname in all_files[0:nb_files]:\n",
    "        with open(DIR+fname) as infile:\n",
    "            i=0\n",
    "            for line in infile:\n",
    "                if i>=50:\n",
    "                    outfile.write(line)\n",
    "                i=i+1\n",
    "        print (\"Done concatenating file : %s\" %fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../LSTM/data/Gutenberg/ebooks-unzipped/English/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"../../LSTM/data/Gutenberg/ebooks-unzipped/English/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load file\n",
    "file_name=out_path+'input/english.txt'\n",
    "text = open(file_name).read()\n",
    "text=normalize('NFKD',text.decode('latin1')).encode('ASCII', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#text = text.replace(to_delete,\"\").replace('Digitized by',\"\").replace('Google',\"\") \n",
    "text = re.sub(\"\\n\\n+\" , \"\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 9670571\n",
      "total chars: 87\n"
     ]
    }
   ],
   "source": [
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "VOCAB_SIZE = len(chars)\n",
    "print('total chars:',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** The RNN takes in input numerical data hence the necessity to convert strings into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating mapping between indexes and characters\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weâ€™re gonna use Keras to create and train our Network, so we must convert the data into this form: (number_of_sequences, length_of_sequence, number_of_features).\n",
    "- nb of features = length of the char array\n",
    "- length of sequence = batch size\n",
    "- nb of sequence = len(data) divided by batch size.\n",
    "\n",
    "**Warning : ** target sequence is setted by shifting the source/input sequence by one character with both having the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 2.74 s, total: 12.9 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#original sequence length : 100\n",
    "\n",
    "SEQ_LENGTH=100\n",
    "#Build three dimensional arrays\n",
    "X = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #input\n",
    "y = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #target\n",
    "\n",
    "#Build sequences\n",
    "for i in range(0, len(text)/SEQ_LENGTH):\n",
    "    X_sequence = text[i*SEQ_LENGTH:(i+1)*SEQ_LENGTH]\n",
    "    X_sequence_ix = [char_indices[value] for value in X_sequence]\n",
    "    input_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "    X[i] = input_sequence\n",
    "\n",
    "    y_sequence = text[i*SEQ_LENGTH+1:(i+1)*SEQ_LENGTH+1]\n",
    "    y_sequence_ix = [char_indices[value] for value in y_sequence]\n",
    "    target_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        target_sequence[j][y_sequence_ix[j]] = 1.\n",
    "    y[i] = target_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. Build the network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM= 500 #500\n",
    "LAYER_NUM = 2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "for i in range(LAYER_NUM - 1):\n",
    "    model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZZBB))ZZZZ))rr))r//TTaHH;;iiaaxxxxxxx555MMMXXdddd((((UUUUU   ggggggggggggggggggggggggggg"
     ]
    }
   ],
   "source": [
    "# Generate some sample before training to know how bad it is!\n",
    "bla = generate_text(model, 100, VOCAB_SIZE, indices_char)\n",
    "#api.PostUpdate(status=bla[0:123])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Train network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Note :**\n",
    "- batch_size of 400 combined with a seq_len of 500 gets OOM\n",
    "- batch_size of 400 combined with a seq_len of 400 pass epoch at : 299s\n",
    "- batch_size of 100 combined with a seq_len of 100 pass epoch at : 400s\n",
    "- batch_size of 400 combined with a seq_len of 200 pass epoch at : 267s\n",
    "- batch_size of 400 combined with a seq_len of 100 pass epoch at : 262s\n",
    "- batch_size of 500 combined with a seq_len of 100 pass epoch at : 251s\n",
    "\n",
    "here is an interesting post : https://stats.stackexchange.com/questions/164876/tradeoff-batch-size-vs-number-of-iterations-to-train-a-neural-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_iternb(string):\n",
    "    return re.findall(r'checkpoint_500_epoch_(.*).hdf5', string)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoints : ['checkpoint_500_epoch_370.hdf5']\n",
      "1\n",
      "Checkpoint english/data/weights/weight_attempt_s02/checkpoint_500_epoch_370.hdf5 loaded successfuly!\n",
      "Starting at iteration : 370\n",
      "\n",
      "\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvp_tran_tsp/anaconda2/lib/python2.7/site-packages/keras/models.py:834: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "251s - loss: 0.7414\n",
      "VERY happened to end with his own right hand, and said: \"I\n",
      "receive it,a he cried, aI am going to be any gratuful eyes on your\n",
      "hands.a\n",
      "\n",
      "a\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.7164\n",
      "\" said the Wolf, \"if counsels fall\n",
      "  By comfortent meekness, whereof I may receive\n",
      "  Famon, where Champions pitefully astered,\n",
      "  The stro\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.7055\n",
      "But if thine heart turn away from the\n",
      "           reign of David, which is in the midst of the river, and thou\n",
      "           shalt go on forwa\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6979\n",
      "quity.\n",
      "\n",
      "03:007:035 One golden spoon of ten shekels, full of incense:\n",
      "\n",
      "04:007:031 One young bullock, one ram, one lamb of the first year,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6923\n",
      "= By harking no reason do this doubt, but we are not really the same.\"\n",
      "     aWe hear the serpent and morning I saw him with the romance!\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6881\n",
      "!\"\n",
      "\n",
      "He had had a raceled ladie solemn heavy days before.\n",
      "\n",
      "Never become a stranger, that he would be gladified. Not the last of\n",
      "them, he\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6841\n",
      "What hast thou done? the eye is gone out of the city\n",
      "           with God.\n",
      "\n",
      "45:006:013 And ye are come to enter into the congregation of t\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6805\n",
      "with the Holy Ghost.\n",
      "\n",
      "45:008:009 But if ye believe not mischief, that shall come upon him like\n",
      "           the fig tree, and the chaff whi\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "250s - loss: 0.6777\n",
      "What saith the prophet may be found all mine on every high hill,\n",
      "           even as money, and the other land shall be divided together:\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6750\n",
      "Union.\n",
      "\n",
      "But if the proportion of fiction is so contemplified, and\n",
      "echo nure a Yant, been proved and agrievaled by the convention, it\n",
      "wou\n",
      "\n",
      "Iteration nb : 380\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6731\n",
      "And the LORD spake unto Moses, saying,\n",
      "\n",
      "03:023:034 Speak unto the children of Israel, and say unto them, When ye\n",
      "           come into the\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6707\n",
      "/www.pglaf.org.\n",
      "\n",
      "\n",
      "Section 3.  Information about the Project Gutenberg Literary Archive\n",
      "Foundation\n",
      "\n",
      "The Project Gutenberg Literary Arch\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6692\n",
      "(Virginia), towards a\n",
      "\n",
      "problem of taxation for the attempt to entertain different concessions, as\n",
      "well on the same respect, as well as th\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6671\n",
      "ll be able to give us any thing but the poor and termination of\n",
      "           the earth.\n",
      "\n",
      "21:007:007 Whose dreams there is a wide full yell,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6656\n",
      "Ye have lived in pleasure in the world, but this mind a mouth\n",
      "           a wave, and who hath led their head with the horns of the air.\n",
      "\"T\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6644\n",
      "Ye shall not find him, and mine\n",
      "           enemies will I give in his own house.\n",
      "\n",
      "44:013:019 For I say unto you, That in heaven therefore\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6630\n",
      "@\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Chapter XXV\n",
      "\n",
      "  EICHER NEGONG there the Univers Appearance to approach\n",
      "  In Paradise, the universal value\n",
      "  Of GABRIE our great\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6620\n",
      "454 8642254093 3430162669 0568878993 3924767636\n",
      "0472227226 1522662863 2188068680 9908698445 3949378873 1722245562\n",
      "7901815602 5189922555 73\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6604\n",
      "ing the words of the LORD of the land of Canaan, the\n",
      "           son of Joseph, and the people, having seventeen hundred\n",
      "           thousan\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6596\n",
      "@\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End of the Project Gutenberg EBook of Peter Pan\n",
      "1 T0 Domphis Bettee Botto is Phil. But in a bird if we may be, but if she had n\n",
      "\n",
      "Iteration nb : 390\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6592\n",
      "5 And they shall be holy unto the LORD God of Israel, there is\n",
      "           the thing that ye shall do.\n",
      "\n",
      "05:004:023 And the LORD said unto \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6581\n",
      "? and where is thy God?\n",
      "\n",
      "19:042:004 Will he regard the poor also of the mighty with the wicked?\n",
      "\n",
      "20:018:019 All things are lawful for us\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "250s - loss: 0.6568\n",
      "605742434 6417181590 4006511222\n",
      "6312707129 9071761769 9902903566 6653799011 0260099906\n",
      "8070477049 non these hath he given for this, ye say\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6564\n",
      "g the knowledge of the commandments of the\n",
      "           LORD concerning things which knew that I do unto them.\n",
      "\n",
      "19:074:008 I am found out o\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6553\n",
      "States, in such a manner as to render their\n",
      "animals. The Ass to the sepulchre, he pointed the policy or strangers. And they\n",
      "turned upon by\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6542\n",
      ", and the priests shall be inhabited, and they\n",
      "           shall eat the fruit of their doings.\n",
      "\n",
      "23:003:015 Wherefore their words shall be\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6538\n",
      "of the LORD God of their fathers, and\n",
      "           served their glory.\n",
      "\n",
      "15:009:009 The wild beasts of the heavens, and the meat offering, a\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6532\n",
      ") and the Levite that is not given, and the souls of\n",
      "           the field he shall fight against it: and the priest shall\n",
      "           recov\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6526\n",
      "!\"\n",
      "\n",
      "He was looking at the window, but at once were we failed.\n",
      "The bed was his own clear asses in them.\n",
      "\n",
      "aI have just one of those food,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6517\n",
      "State, of Massachusetts, and of this State,\n",
      "\n",
      "they may be modified and printed and given away--you may do the office.\n",
      "It is impossible tha\n",
      "\n",
      "Iteration nb : 400\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6508\n",
      "press the one chancers by a President of the Union, the formation\n",
      "and protection of the State authority to the United States. Whilst\n",
      "this \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6502\n",
      "ut the waters from the island of the\n",
      "Union. Sad things are a sufficient reward of human editions,\n",
      "and the same inspection. She had suffere\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6502\n",
      "_\n",
      "PUBBLUS.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FEDERALIST No. 29\n",
      "\n",
      "\n",
      "\n",
      "The Same Subject Continued\n",
      "\n",
      "(The Idea of Representatives, and an Ex spect for his antectia\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6497\n",
      "xpedience may be supposed to be\n",
      "industry to the task without proper pretext for an instance of\n",
      "importance to the army of confedence, which\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6492\n",
      "xperience with its\n",
      "\n",
      "powers and populousities, and to the Union between the\n",
      "\n",
      "States to mankind. The power of colleging tables, than the\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6485\n",
      "/fundraising.  Contributions to the Project Gutenberg\n",
      "Literary Archive Foundation are tax deductible to the full extent\n",
      "permitted by U.S. \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6477\n",
      "ver the position which has to be pointed.\n",
      "\n",
      "4aDud to depend, with perfet invocations in these\n",
      "  Who will choose a comfort for us to avail\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6471\n",
      "Project Gutenberg-tm name associated with\n",
      "the work.  You can easily comply with the terms of this agreement by\n",
      "keeping this work in the sa\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6463\n",
      "What hast thou done? our face, I will shew you\n",
      "           thine own life, and in your sins: and ye shall be my people.\n",
      "\n",
      "07:011:013 And th\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6469\n",
      "The LORD hath brought him Zion: he hath\n",
      "           seen in the latter days, if he will not do that, he will\n",
      "           bring a cage from o\n",
      "\n",
      "Iteration nb : 410\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "251s - loss: 0.6461\n",
      "constant mind and other career\n",
      "confirmation of the reasons upon which they are content. After she\n",
      "may be relinquished by his expedient tha\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6456\n",
      "****\n",
      "This and all associated files of various formats will be found in:\n",
      "           churchy is it for himself, and yet fear him when he\n",
      "  \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6452\n",
      "e the son of Maas.\n",
      "\n",
      "07:004:015 And the children of Israel did so as the LORD commanded\n",
      "           Moses.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:030:001 And the LORD spake\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6454\n",
      ".\n",
      "\n",
      "05:007:009 For inhabitant of the LORD said unto Moses, I will not drive out\n",
      "           of her mind.\n",
      "\n",
      "05:022:031 The LORD shall smite\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6437\n",
      "Now Joram hath made known the whole house of\n",
      "           the LORD?\n",
      "\n",
      "19:102:006 O give thanks unto the LORD; for he is good; Seleth all my \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6443\n",
      "continued to diness or reflect on the\n",
      "\n",
      "existing Congress, the executive or in any sister of people\n",
      "\n",
      "will be the same effect and confiden\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6441\n",
      "-the voice of a more particular State attents, when the\n",
      "final views are addreeted in the State constitutions, has been in a clear\n",
      "obedienc\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6438\n",
      ")\n",
      "\n",
      "42:002:024 And they came to the possession of his father with child to\n",
      "           Jerusalem, and would compare it.\n",
      "\n",
      "14:025:023 And t\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6436\n",
      "_\n",
      "Whatever Mrs. Darling was past all before, though he was, the only summons of\n",
      "a table it had been broken up in such of the children so g\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6436\n",
      "ke the calamities of all these cities, and\n",
      "           the captains of thousands and the heart, which they had\n",
      "           set the point of \n",
      "\n",
      "Iteration nb : 420\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6425\n",
      "Man, libert, thou shouldest take the wings of the\n",
      "           household, and of the house of Judah unto this day.\n",
      "\n",
      "12:018:013 And the rest\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6422\n",
      "_\n",
      "PURPIST WITNNA L.447\n",
      "\n",
      "Monther are all the means of a free advantage to be the last\n",
      "\n",
      "supertritive body will not be diminished by the p\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6422\n",
      "in the city, and the stars of the tabernacle of the\n",
      "           congregation, whom they offer sin.\n",
      "\n",
      "04:007:018 And when Phinehasad gathere\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "252s - loss: 0.6417\n",
      "& If I only raised my heart to argue by married woman, growing many flight\n",
      "in the same better back.a\n",
      "\n",
      "While story is not the rather and i\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "259s - loss: 0.6417\n",
      "'s work shall be done with the sacrifices of man, and\n",
      "           the fat that is upon the fathers which he before him.\n",
      "\n",
      "21:007:027 For ou\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "370s - loss: 0.6416\n",
      "!\"\n",
      "\n",
      "He was always as well as down, the couch, and went\n",
      "down to draw in horrible connection. The Swallow and stuck the\n",
      "strongel congregat\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "#batch size equals to seq length here\n",
    "BATCH_SIZE=500 #100 slower and #>450 gets OOM\n",
    "#len of desired output\n",
    "GENERATE_LENGTH=140\n",
    "DIR=out_path+\"weights/weight_attempt_s02/\"\n",
    "flag=True\n",
    "\n",
    "try:\n",
    "    onlyfiles = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "    nb_files = len(onlyfiles)\n",
    "    print(\"Checkpoints : %s\" %onlyfiles)\n",
    "    iteration=[]\n",
    "    for files in onlyfiles:\n",
    "        iteration.append(int(get_iternb(files)))\n",
    "    iteration=max(iteration)\n",
    "\n",
    "    last_checkpoint=DIR+onlyfiles[0][0:21]+str(iteration)+'.hdf5'\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    onlyfiles=[]\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "    nb_files=0\n",
    "\n",
    "    \n",
    "print(nb_files)\n",
    "if nb_files>0:\n",
    "    model.load_weights(last_checkpoint)\n",
    "    print(\"Checkpoint %s loaded successfuly!\" % last_checkpoint)\n",
    "else:\n",
    "    iteration=0\n",
    "    \n",
    "print(\"Starting at iteration : %s\" %iteration)\n",
    "while flag==True:\n",
    "    print('\\n')\n",
    "    print('-'*20)\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, verbose=2, nb_epoch=1)\n",
    "    iteration += 1\n",
    "    bla=generate_text(model, GENERATE_LENGTH,VOCAB_SIZE, indices_char)\n",
    "    if iteration % 10 == 0:\n",
    "        print(\"\\n\\nIteration nb : %s\" %iteration)\n",
    "        #api.PostUpdate(status=bla[0:123])\n",
    "        model.save_weights(DIR+'checkpoint_{}_epoch_{}.hdf5'.format(HIDDEN_DIM, iteration))\n",
    "        #remove unecessary files:\n",
    "        for files in onlyfiles:\n",
    "            try:\n",
    "                if files:\n",
    "                    os.remove(DIR+files)\n",
    "            except:\n",
    "                pass\n",
    "        onlyfiles = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "\n",
    "    if iteration>=600:\n",
    "        print(\"Stopping...\")\n",
    "        flag=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Generate text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    if not os.path.exists(out_path+\"generate/\"):\n",
    "        os.makedirs(out_path+\"generate/\")\n",
    "    with open(out_path+\"generate/output.txt\",\"w\") as f:\n",
    "        f.write(('').join(y_char))\n",
    "    return ('').join(y_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seed with particular text:\n",
    "def generate_text_seeded(model,seed,length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    # char_indices\n",
    "    ix = [char_indices[x] for x in seed]\n",
    "    y_char = [x for x in seed]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(len(ix)) :\n",
    "        X[0, i, :][ix[i]] = 1\n",
    "        print(ix_to_char[ix[i]], end=\"\")\n",
    "    to_substract = len(ix)\n",
    "    for i in range(length-to_substract):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_text_seeded(model,normalize('NFKD',\"Who is god? \".decode('latin1')), 1000, VOCAB_SIZE, indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "out = save_text(model, 1500, VOCAB_SIZE, indices_char)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
