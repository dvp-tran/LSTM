{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout,TimeDistributed\n",
    "from keras.layers import LSTM,SimpleRNN\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os, os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from unicodedata import normalize\n",
    "import codecs, io\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- ### Check GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/gpu:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Check and set Twitter's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "api = twitter.Api(consumer_key='LyNVanTEQEOEGKfXAMeLv6AKG',\n",
    "                    consumer_secret='0lJvhaaOP5cRZWm6rxwyBIAypd1P7eiDx9f74KBDlLrSldNuBQ',\n",
    "                    access_token_key='855852332034265088-geTEVmA7xIsOD3WCZyfBNnqjRdS1MhW',\n",
    "                    access_token_secret='kJMwMl67e3nYrqaGWzIizxzQpRZhtBfOnwPflO1fk3cOt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Sat Apr 22 18:34:31 +0000 2017\", \"default_profile\": true, \"description\": \"Learning how to be creative\", \"followers_count\": 2, \"friends_count\": 1, \"id\": 855852332034265088, \"lang\": \"en\", \"location\": \"Somewhere in the cloud\", \"name\": \"ArtistBot\", \"profile_background_color\": \"F5F8FA\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/855852332034265088/1492892354\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/855878764143804417/r55Z2Js5_normal.jpg\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"screen_name\": \"TheTalkativeBot\", \"status\": {\"created_at\": \"Tue Apr 25 22:31:31 +0000 2017\", \"id\": 856999137753145349, \"id_str\": \"856999137753145349\", \"in_reply_to_screen_name\": \"TheTalkativeBot\", \"in_reply_to_status_id\": 856894659007844352, \"in_reply_to_user_id\": 855852332034265088, \"lang\": \"en\", \"media\": [{\"display_url\": \"pic.twitter.com/lMV1EeegY0\", \"expanded_url\": \"https://twitter.com/TheTalkativeBot/status/856999137753145349/photo/1\", \"id\": 856999135043620864, \"media_url\": \"http://pbs.twimg.com/media/C-SsLDkXkAAvT-S.jpg\", \"media_url_https\": \"https://pbs.twimg.com/media/C-SsLDkXkAAvT-S.jpg\", \"sizes\": {\"large\": {\"h\": 1200, \"resize\": \"fit\", \"w\": 900}, \"medium\": {\"h\": 1200, \"resize\": \"fit\", \"w\": 900}, \"small\": {\"h\": 680, \"resize\": \"fit\", \"w\": 510}, \"thumb\": {\"h\": 150, \"resize\": \"crop\", \"w\": 150}}, \"type\": \"photo\", \"url\": \"https://t.co/lMV1EeegY0\"}], \"source\": \"<a href=\\\"http://www.google.com\\\" rel=\\\"nofollow\\\">TheScenarioBot</a>\", \"text\": \"@dvp_tran Here what's your picture evokes to me ! https://t.co/lMV1EeegY0\"}, \"statuses_count\": 41}\n"
     ]
    }
   ],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "api.PostUpdate(\"Today I am learning German, watch me improve! ;) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Learning from corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. Load and convert data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Load and concatenate files:\n",
    "\n",
    "DIR=\"../../LSTM/data/Gutenberg/ebooks-unzipped/French/\"\n",
    "all_files = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "\n",
    "#choose how many files to concatenate:\n",
    "nb_files=7\n",
    "if nb_files>len(all_files):\n",
    "    nb_files=len(all_files)\n",
    "    \n",
    "    \n",
    "out_path=\"french/data/\"\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "if not os.path.exists(out_path+\"input/\"):\n",
    "    os.makedirs(out_path+\"input/\")\n",
    "    \n",
    "with open(out_path+'input/french2.txt', 'w') as outfile:\n",
    "    for fname in all_files[0:nb_files]:\n",
    "        with open(DIR+fname) as infile:\n",
    "            i=0\n",
    "            for line in infile:\n",
    "                if i>=50:\n",
    "                    outfile.write(line)\n",
    "                i=i+1\n",
    "        print (\"Done concatenating file : %s\" %fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done concatenating file : 249.txt\n",
      "Done concatenating file : 4740-8.txt\n",
      "Done concatenating file : 799-0.txt\n",
      "Done concatenating file : 4548-8.txt\n",
      "Done concatenating file : 4791-8.txt\n",
      "Done concatenating file : 803-8.txt\n",
      "Done concatenating file : 2650-0.txt\n"
     ]
    }
   ],
   "source": [
    "#Load and concatenate files:\n",
    "\n",
    "DIR=\"../../LSTM/data/Gutenberg/ebooks-unzipped/French/\"\n",
    "all_files = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "\n",
    "#choose how many files to concatenate:\n",
    "nb_files=7\n",
    "if nb_files>len(all_files):\n",
    "    nb_files=len(all_files)\n",
    "    \n",
    "    \n",
    "out_path=\"french/data/\"\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "if not os.path.exists(out_path+\"input/\"):\n",
    "    os.makedirs(out_path+\"input/\")\n",
    "    \n",
    "with io.open(out_path+'input/french2.txt', 'w', encoding='utf-8', errors='replace')  as outfile:\n",
    "    for fname in all_files[0:nb_files]:\n",
    "        with io.open(DIR+fname,'r',encoding='utf-8',errors=\"replace\") as infile:\n",
    "            i=0\n",
    "            for line in infile:\n",
    "                if i>=50:\n",
    "                    outfile.write(line)\n",
    "                i=i+1\n",
    "        print (\"Done concatenating file : %s\" %fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UTF-8'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ISO-8859-1\"\n",
    "\"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load file\n",
    "file_name=out_path+'input/french2.txt'\n",
    "text = open(file_name).read()\n",
    "text=normalize('NFKD',text.decode('latin1')).encode('ASCII', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = re.sub(\"\\n\\n+\" , \"\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 2504261\n",
      "total chars: 88\n"
     ]
    }
   ],
   "source": [
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "VOCAB_SIZE = len(chars)\n",
    "print('total chars:',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** The RNN takes in input numerical data hence the necessity to convert strings into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating mapping between indexes and characters\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re gonna use Keras to create and train our Network, so we must convert the data into this form: (number_of_sequences, length_of_sequence, number_of_features).\n",
    "- nb of features = length of the char array\n",
    "- length of sequence = batch size\n",
    "- nb of sequence = len(data) divided by batch size.\n",
    "\n",
    "**Warning : ** target sequence is setted by shifting the source/input sequence by one character with both having the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.01 s, sys: 164 ms, total: 2.18 s\n",
      "Wall time: 2.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "SEQ_LENGTH=100\n",
    "#Build three dimensional arrays\n",
    "X = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #input\n",
    "y = np.zeros((len(text)/SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE)) #target\n",
    "\n",
    "#Build sequences\n",
    "for i in range(0, len(text)/SEQ_LENGTH):\n",
    "    X_sequence = text[i*SEQ_LENGTH:(i+1)*SEQ_LENGTH]\n",
    "    X_sequence_ix = [char_indices[value] for value in X_sequence]\n",
    "    input_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "    X[i] = input_sequence\n",
    "\n",
    "    y_sequence = text[i*SEQ_LENGTH+1:(i+1)*SEQ_LENGTH+1]\n",
    "    y_sequence_ix = [char_indices[value] for value in y_sequence]\n",
    "    target_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        target_sequence[j][y_sequence_ix[j]] = 1.\n",
    "    y[i] = target_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. Build the network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM= 500 #500\n",
    "LAYER_NUM = 2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "for i in range(LAYER_NUM - 1):\n",
    "    model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT?*K)44ooo111111hhhh9[[[gg::::CC((III:(:C(IIyyyyyhhy''\\\\\\\\ddttttt  eeeeaaaaqqqqqqqqqqqqqqqqqqqqqqqq"
     ]
    }
   ],
   "source": [
    "# Generate some sample before training to know how bad it is!\n",
    "bla = generate_text(model, 100, VOCAB_SIZE, indices_char)\n",
    "#api.PostUpdate(status=bla[0:123])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Train network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_iternb(string):\n",
    "    return re.findall(r'checkpoint_500_epoch_(.*).hdf5', string)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at iteration : 10\n",
      "\n",
      "\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda2/lib/python2.7/site-packages/keras/models.py:834: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "93s - loss: 1.0778\n",
      "On de la marche de la mari12e de la mari12e de la mari12e de la mari12e de la mari12e de\n",
      "l'eau avec une i12le de la mari12e de l'i12le de la\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "92s - loss: 1.0469\n",
      "particulier de son mai12tre en avant de la maison de\n",
      "son mai12tre.\n",
      "Le docteur se trouva sur le sol de la carte, et le capitaine Nicholl\n",
      "se t\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 1.0215\n",
      ", et de la plus grande partie de la pointe de la pointe de la pointe de\n",
      "l'air de la place de la pointe de la pointe de la pointe de la point\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.9976\n",
      "6 le docteur Fergusson, et je ne puis me\n",
      "plaindre parler de l'ai12rostat de cette malheureuse profondeur de l'ai12rostat de\n",
      "cette foule se p\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.9741\n",
      "$12 deux heures du matin.\n",
      "Le docteur se rendit i12 l'extri12miti12 de la chaleur de l'ai12rostat.\n",
      "Le Victoria se trouvait i12 l'inti12rieur \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.9520\n",
      "wann avait rien de le contrecoup de cette\n",
      "chose qui se prAsente aux regards de la mort, de la vie de la vie de\n",
      "l'artillerie ou le contraire,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.9299\n",
      "bles de la poudre et de la porte et de la premiA re fois qu'il avait AtA le plus au prAsident du Gun-Club.\n",
      "--AAh! cela ne sera pas de la pet\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.9089\n",
      "s de cette maniA re de ces paroles de la mAmoire, et que les\n",
      "plaisirs qu'elle avait peu A  peu des amis au moyen de se percer de cette\n",
      "contr\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.8875\n",
      "6 le monde est si bien que le docteur la saisit\n",
      "de l'entreprise.\n",
      "i12 Mon mai12tre! i12tait-il di12ji12 fait de l'entreprise.\n",
      "--Cependant, re\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.8670\n",
      "par la main de la porti12e de l'ouragan.  Il est impossible de me retirer un peu de\n",
      "professeur de mi12talliers les plus intimes de l'air per\n",
      "\n",
      "Iteration nb : 20\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.8470\n",
      "+ les plus incertaines de ces paroles de ces paroles de son amie.\n",
      "Mais le docteur ne pouvait se rendre compte de se trouver de la nacelle,\n",
      "e\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.8271\n",
      "Eurent autant que les autres, de cette maniA re de demander de\n",
      "son Auvre de la porter de la poudre A  des propos que les autres fois et des\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.8076\n",
      "0\n",
      "--Et le directeur de l'Afrique au cas oi12 le coup de calme et le premier\n",
      "jour du sol, le Victoria prit perdait au dehors de l'i12le de Pa\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.7886\n",
      "ur le charme douloureux de l'air.\n",
      "Le Victoria fut i12ti12 impossible de se faire descendre un pareil voyage.\n",
      "Il ne put retenir une li12gi12r\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.7696\n",
      "Mais le comte d'Aliffe, fri12re de la chi12re frani12aise, mais il ne fallait pas se montrer i12\n",
      "cette i12poque relativement absolue.\n",
      "--C'es\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.7518\n",
      "on amour pour elle. Il n'y avait aucune raison d'argent, ne la\n",
      "connaissance de la communication de la poudre et de la tendresse et\n",
      "de son co\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.7343\n",
      "; mais, au lieu de la mer,\n",
      "le contrectuin avait li12 quelques pins, le consulter ne pouvait se\n",
      "prononcer de la maison quelqu'un qui le conna\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.7171\n",
      ", et les voyageurs eussent suffi i12\n",
      "traverser le sommeil au moyen de tirer de la marche.  Mais le\n",
      "professeur, suivant les bras de ma main l\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.7008\n",
      "Foundation\n",
      "Project Gutenberg-tm depends upon and cannot survive without wide\n",
      "spread public support and donations to carry out its mission of\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.6844\n",
      "Hans s'en tenir A  une partie de la porte du monde en contraire, et avec un sourire atteignAt par un\n",
      "entreprise de la porte extraordinaire, \n",
      "\n",
      "Iteration nb : 30\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.6691\n",
      "Zans doit voulu maintenant pour lui faire supposer que ce tAlesconnage\n",
      "dAsignA, elle n'Atait pas en effet les prAparations de ses parents,\n",
      "m\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.6539\n",
      "Kennedy y parvingrant les premiers jours du\n",
      "monde.\n",
      "--Je le savais bien, mon cher Dick, reprit le docteur, et je ne\n",
      "pouvais m'en servir.  Je \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.6394\n",
      "z le docteur.\n",
      "La nuit se passa sans accident, et les obstacles ne sont que des ouragans. Il\n",
      "se distinguait sur les rocs aigus avec le sucher\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.6252\n",
      "8\n",
      "--Oui, ri12pondit le professeur en pleine fori12t, et les trois voyageurs remercii12rent du\n",
      "moins, ces imaginations pri12ci12dentes allumi\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.6120\n",
      "\\                                                                                                                                           \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.5993\n",
      "y a lA  de chapel produisaient\n",
      "un de ces jours de tempArate oA1 toute la table de sa\n",
      "prAsence de Chartes, dans une solennitA de son prAside,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.5872\n",
      "Il se mettait A  la faire souffrir une petite ville de\n",
      "Carap se trouvA rent le temps oA1 le coup de sonnette de l'image, le\n",
      "souvenir de se r\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.5755\n",
      "le professeur Lidenbrock\n",
      "m'avait fait attention le docteur; souvent i12 ne pas la voir ses compagnons souvent\n",
      "sur la plaine liquide environn\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.5643\n",
      "e pas sa place\n",
      "d'animation en nous insistant la profondeur, la conservation n'Atait plus\n",
      "aucune personne qu'elle n'en avait pas encore trA s\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.5534\n",
      "y avait des bonnes intentions.\n",
      "i12 Nous ne tomberons pas, dit Kennedy, un chasseur ne serait pas\n",
      "emploisi12e pour provoquer li12 les trois v\n",
      "\n",
      "Iteration nb : 40\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.5428\n",
      "En effet, la pensAe qui avait pour eux deux plus rAcitA\n",
      "prudents et pour leur propre AmArique de la prAsence d'un artiste de ses\n",
      "supAritA. P\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.5335\n",
      "y a loose network of volunteer support.\n",
      "Project Gutenberg-tm eBooks are often created from several printed\n",
      "editions, all of which are confir\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.5242\n",
      "=ours le charme de la mer,\n",
      "comme les bois parfais, comme dans un mache joint du monde, dans un retour\n",
      "fermie d'amour protestique, de son cou\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.5143\n",
      ".  Les Anglais n'ont\n",
      "perdit pas, on a pour notre calme de parer A  sa dArive, ne pouvait\n",
      "arriver aucune sArie comme pour reconnaAtre le pays\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.5069\n",
      "Qu'est-ce que vous en gourtezez de ce que je voulais savoir ce qu'il y a de plus nous avait-on\n",
      "continuA plus longtemps une seule et mAame un\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.4987\n",
      "Odette Atait soudain songer, et, qui se\n",
      "disait Swann en suivant le mouvement. Mais ce sont les avait eurent\n",
      "prAfArAes. Dans ce bassin de sa \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.4902\n",
      "\\                                                                                                                                           \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.4827\n",
      "_________________________\n",
      "Acription de la\n",
      "corde, dans son i12cart, pouvait le refluir, et nous\n",
      "pouvons plainer l'imagi12niti12.\n",
      "Chose pour m\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.4759\n",
      "ks be for dumine a without further\n",
      "of the full Project Gutenberg-tm License for all works posted with the\n",
      "permission of the copyright holder\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.4682\n",
      "$12 complexiteurs, ces animaux spectacles i12tendues\n",
      "s'entrai12naient dans les flammes du coressis, sensibue, avec di12sespoir, le pri12te d\n",
      "\n",
      "Iteration nb : 50\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.4622\n",
      "En effet, le\n",
      "1, avec suivre et de constitution of comme un point de son esprit et de\n",
      "sommeil.\n",
      "Apri12s une heure importance, le docteur Fergu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.4560\n",
      "Il se montrait i12 l'i12cossais, et le vent soufflait d'une i12tendue\n",
      "de paysage de quatre mille livres de fulmis.\n",
      "Le sein i12pouvantait des\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.4499\n",
      "DivingA de les empAacher comme A  un\n",
      "os dont on connaissait les paroles qui lui ressemblaient\n",
      "bientiAsAs, et chacun Atait gravitait: ALe dou\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.4446\n",
      "s de ses activitA...\n",
      "Une lieue A  la pAin.  Et tous Aatres prAcA A A Aveilles de lui faire A \n",
      "jouer les autres toilettes, rendus paraissait \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.4387\n",
      "0\n",
      "--En attendant, ri12pondit mon oncle, et celui de Hans, qui\n",
      "se font un dome?i12\n",
      "Hans interreglait le capitaine de l'i12corce mi12docune d'\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.4346\n",
      "bles i12 rendre accueillirent l'enli12vement\n",
      "des arbres par les Bergatitueux. Il restait immobile en au-dessus.\n",
      "Tout entirons ses oreilles, \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.4288\n",
      ") allait donc prA s de la fAcondation des mondes A \n",
      "la semaine un peu indApendant, on parlait de sa pointure Atait A  la messe en\n",
      "regardant \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.4250\n",
      "t les mains et son\n",
      "manteau sur l'est i12 l'ouest. Si nous serons i12 une hallucination\n",
      "de ne point recourir i12 la dernii12re mode?\n",
      "et je pu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.4197\n",
      "+ Bruce i12 la rive du soir du marquis\n",
      "de Gilberte, mi12me d'aller, plus doucement de ces repas\n",
      "heureux de sa canation.  La nature de cette \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.4163\n",
      "+ Bruce i12tait un i12cossais dans l'habitude.\n",
      "--Sans doute, mon mai12tre, vous! fir de tout hail que les pierres saitions en pointures et g\n",
      "\n",
      "Iteration nb : 60\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.4122\n",
      "Je n'avais pas pu avoir suivie.\n",
      "--Est-ce que nous suivons des saillies de roc, pri12t i12 morda son passagement, et le petit noyau de\n",
      "scienc\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.4082\n",
      "Foundation is a non profit\n",
      "501(c)(3) educational corporation organized under the laws of the\n",
      "state applicable state law. The invalidity or u\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.4038\n",
      "9\n",
      "J.-T. Maston, dit Fagrari12di.\n",
      "--Oui!  aucune nai12te ne nourrit pas pour me reconnaAtre.  Ses deux compagnons la mi12denaient au pas.\n",
      "i12\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.4004\n",
      "par les applaudissements.\n",
      "Tout d'abord, j'ai ti12 plus de dix pieds, heureusement, dans\n",
      "quelle jour devenues ti12nessespersi12es, tout i12 f\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3954\n",
      "Mais qui m'eAt fait le savoir\n",
      "et qui n'Atait pas avec les Verdurin qu'elle venait de prendre chez\n",
      "le plus grand dAcemblement de la rue Dicka\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3930\n",
      ": AC'est la stupitA de la terre?  les autres!  rApliqua le prAsident.\n",
      "--Et disant, mais non seulement aussi que vous venz A  la prAsence, il\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3898\n",
      "Oh! que c'est drA le, dA s le saint, j'avais vu M. Vinteuil si ont\n",
      "AtA achetAe pour toujours. Je lui ai dit que vous connaissez\n",
      "bien de prof\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3864\n",
      "12 la mi12me laturiti12 mysti12rale, le\n",
      "portabiliti12 parfait particulii12rement au livre.  Les clameurs se pri12cipitaient cette absence de\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3834\n",
      "A  l'Agard du cAur, celle\n",
      "de M. de Charlus. L'adrire lunaire de l'_Emme de Gilleube, c'Atait la\n",
      "premiA re fois qu'on l'a puisse exactement c\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3809\n",
      "ge et luisant comment il passait son discuer\n",
      "et de leur misAe de cinquante livres. C'est pourquoi elles auraient AtA composA de moi, qui Ata\n",
      "\n",
      "Iteration nb : 70\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3780\n",
      "on avait dit qu'Odette avait surtout A  se rendre.\n",
      "--AOci Atait donc comment les sens tenues au quelconque de trop\n",
      "orgues, de gAnAral et d'o\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3750\n",
      "4.  Except for the limited right of replacement or refund set forth\n",
      "in the General Terms of Use part of this license, apply to chaising the \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3724\n",
      "je connaissais avoir pris sa place A  la Maison des\n",
      "lois chez le peintre qui remplissait mes passer pour moi aux\n",
      "raisons de l'amour, de son \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3705\n",
      "bientA t l'objet d'un canon clocher de la mAcanique tendant\n",
      "l'Atlique interlectuelle. Ses efforts AplouAaient avec un tel favorit,\n",
      "immAe les\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3681\n",
      "bre l'obscuritA, elle laissa Aatre vue des arbres de son Ame. Mais\n",
      "il pouvait me chercher A  Atait immenser une Atoque de printemps. Puis el\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3657\n",
      "12 la si12rie des terrains de largeur.\n",
      "--Ce qui est fort possible!\n",
      "--Et, chose en ri12signi12ri12, tu versais venir, ri12ponse, vous savez l\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3627\n",
      "Bah! Monsieur, il n'y a qu'i12 suivre les i12chelons de Barth.\n",
      "--Cela n'en quittent pas les di12parvents du docteur Fergusson.\n",
      "Et cela donne\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3600\n",
      "Foundation\n",
      "Project Gutenberg Trop.ous Wen avait www.gutenberg...\n",
      "Mett but heau et recouvert you donate  the Project Gutenberg Literary Archi\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3583\n",
      "Oh! pas avant midi, rApondait ma tante d'un ton rAsignA n'exemplaient un plus\n",
      "accurA par une main A  la pointe d'un chapeau de fleurs, il es\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3554\n",
      "re de la ri12aliti12.  A mercice,\n",
      "sous les ordins, et, les deux ans roines, les informunts\n",
      "d'i12quoliers se relevaient les mondes pour un bo\n",
      "\n",
      "Iteration nb : 80\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3545\n",
      "Z pays grann sans-nous pour lui recevoir de ce que je\n",
      "choisissais ces secrAtaires que cette science di12couverte de l'eau.\n",
      "i12 Nous en arren\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3531\n",
      ") allait renfermer, quand il savait pourtant qu'on doit\n",
      "pour lui-mAame lui plaisir A  chercher un seul join le\n",
      "chemin Atait succer de la por\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3509\n",
      "000 livres\n",
      "Tel i12tant n'ayant su pri12dre une seule gouffre, ce phrase, un incendie\n",
      "cabine.\n",
      "Barbicane ne bougeait pas.  Je reviens au momen\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3469\n",
      ": ACe n'est pas cela usque lui?  Francisson?\n",
      "--Non; mais non!  pas mien?  s'Acria la face du champ de frA le, ce\n",
      "n'eutendait que cet animal,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3474\n",
      "de la vie de J.-T. Maston, soupirait et qui s'en vaissait seulement sa tengA re\n",
      "touchante insupportable.  Le cinquii12me juypa de saines par\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3451\n",
      "'entrai12ner avec lui. Le cardinal, mille\n",
      "franchis l'attachi12 en baste et aussi de celles-ci; il en avait fait le\n",
      "temps de la ri12flexion.\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3436\n",
      "le docteur i12tonna bien ses\n",
      "compagnons en leur apprenant que cet embonpoit. C'est un\n",
      "peu i12coura:\n",
      "--Tu arrivez mes amis, Joe fit signe de \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3412\n",
      "wann d'un air bal, mais s'il avait absolument\n",
      "raison; je voudrais l'arrAater en lui parlant un homme de petites gens qui ont rAglA les\n",
      "effor\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3402\n",
      "\u0019 Sannue des lacs\n",
      "leurs faire, i12 ce voyage. i12\n",
      "Le soir mi12me, il ne faut pas preuve, le sol marchait accrue sans rapport avec\n",
      "l'ai12rost\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3381\n",
      "le de sa fille et de mon pA re et au nom de Pout.\n",
      "C'est A  devait constamment son imbassification par le sujet de jour je trouvai\n",
      "le temps q\n",
      "\n",
      "Iteration nb : 90\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3358\n",
      "s de ses regards.\n",
      "Alors voyageurs entours deux ans! i12\n",
      "En feu, plus de quatre milles environ entre ses fli12ches assocuais du volcan.  S'i1\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3344\n",
      "7...........................................................................................................................................\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3336\n",
      "RIBUTOR UNDER THIS AGREEMENT WILL NOT BE\n",
      "LIABLE TO YOU FOR ACTUAL, DIRECT, INDIRECT, CONSEQUENTIAL, PUNITIVE OR\n",
      "INCIDENTAL DAMAGES EVEN IF Y\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3319\n",
      "Victor celui-ci devait bienvers\n",
      "l'escalier insinuait toujours par le portrait du professeur.\n",
      "Il i12tait i12vident, cependant, que l'air, le \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3306\n",
      "wann arriva trop de la diverse ci12lante\n",
      "de la chemini12e qui frappe du docteur, qui aurait pu se di12velait; il semblait\n",
      "trop compli12te et\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3299\n",
      "Bah! Monsieur, il n'avait pas, cependant, en attendant, et on retirant et\n",
      "n'enli12ont guA re que de faire des siges.i12\n",
      "Le chi12teau de Deck\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3286\n",
      "?  demanda le major.\n",
      "--Je ne le pense pas, faire des brocles quand, soytaits\n",
      "qui seraient le plus diffArent de tout le monde!A--AJe vois qu'\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3271\n",
      "2 la mi12lancolie de son ami avec la\n",
      "plus plus loin. Je ne chargai pas de voir, et sur ce singulier phi12nomi12nal dont\n",
      "il y fallait de plus\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3266\n",
      "'autres si flexieuse et ligres.\n",
      "--Je te le dir, tranquille, mon oncle, dit le docteur, i12 quoi bon marche\n",
      "18,000\n",
      "pareil unis, et la carabin\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3228\n",
      "82.01.11\n",
      "_________________________\n",
      "AffA elleci12 de l'i12le de\n",
      "Zanzibar, pen ajouter que l'on but au moins! grame trapeill envioonna\n",
      "fasse, \n",
      "\n",
      "Iteration nb : 100\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3234\n",
      "Wand\n",
      "redescenda cinq mille pieds.\n",
      "--Un domai-partic! Ax!...\n",
      "--En effet, ri12pondit le docteur avec i12mehtrace, dont que nous\n",
      "trouverons de \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3222\n",
      "!  toutes ces petits points importantes, par des ruisses de son\n",
      "simple ronimait place i12 une couverture de granit.\n",
      "Certains souffles oi12 s\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3213\n",
      "Virland, quand il est vrai, pri12t i12 confection, et je me\n",
      "rendis ri12pondit: i12Vors, mais ce sera le docteur.\n",
      "--Suis-nous, cet uns conson\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3191\n",
      ") que\n",
      "j'apprAats laissaient peut-Aatre de la facilitA le rendez-voudait, A  la fois le jour oA1 il\n",
      "n'avait plus l'on apport A  leur rivage. \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3181\n",
      "Dick, veux-tu donc, faux ami, qui aurait-il\n",
      "dit votre pas, et, bon i12tre, c'est de cette di12noncesse quatre\n",
      "degri12s avoir bardi l'un acti\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3177\n",
      "=oyaled to makino providing it the pull Project\n",
      "Gutenberg-tm works.\n",
      "- You provide, in accordance with paragraph 1.F.3, a full refund\n",
      "of anyo\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3162\n",
      "nt pas une expression\n",
      "ri12eux qui empii12chait d'i12crire la succession de ces ri12gions souterraines,\n",
      "qui, pendant les instants le 23 seign\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3152\n",
      "8212 Joe.--Il n'y a pas que cette eau! il\n",
      "est vrai!\n",
      "--En tout cas, vous ne voulez pas que nous entrains,\n",
      "du moins de mon oncle.\n",
      "i12Non, sain\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3141\n",
      "Foundation\n",
      "Project Gutenberg-tm License must appear prominently whenevary or y oftlesser la cultit\n",
      "foi the led this work or return of the wo\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3134\n",
      "/de latitude de Tampa-Towe.  Tous concA es\n",
      "m'envahissent dans la fille de cuisine, ne se continait-elle pas en elles que j'avais\n",
      "toujours ex\n",
      "\n",
      "Iteration nb : 110\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3122\n",
      "7...........................................................................................................................................\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3111\n",
      "501!  Je crois donc avoir acqueill. Ce fut un fier i12ton de\n",
      "feu, faisaient couler i12 ses compagnons d'air, le Victoria se\n",
      "trouvait en fais\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3106\n",
      "[Cinq cents\n",
      "kilogrammes.] aux ri12cits d'Elbech to de nouveau du Dieu et nul de Juhitme? Mais\n",
      "nous marchifierons de volumes pas s'i12tendren\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3097\n",
      "(any work on which the\n",
      "phrase \"Project Gutenberg\" appears, or with which the phrase \"Project Gutenberg\" is associated) is accessed, displaye\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3082\n",
      "Kennedy. Ce n'est qu'un\n",
      "extri12me une histoire gination, vasait entrer elles ne\n",
      "pouvait se rendre compte.  L'air drain aupait un mot d'une\n",
      "c\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3081\n",
      "s de celles qui portent les bras crostAs\n",
      "des ArapesA, quand la phrase de la sonate de Mme de Franquetit A \n",
      "Biboo, dans le Diajoc; les cartes\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3068\n",
      "verte, la pensAe de Swann les avait\n",
      "AtA sorties avec au plus grand plaisir et pour qui\n",
      "il Atait revenue; elle remplaAait les yeux. Mais ce n\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3086\n",
      "829, il rentra en Aatre au dehors.\n",
      "Quelle eupace des chance voisineuses pierres qui n'abi12ient pas une\n",
      "nivitiente de faire comme tout le mo\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2996\n",
      "?  Par un procAdA brA ve immobile, et je\n",
      "condit ainsignA A  un de ces petits batagles aussi grapmisaient et se rAenter la\n",
      "vAritable et bon g\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3047\n",
      "Mais quel rAveille?A\n",
      "Elle eAt aimA que fAdiles, disait: AComme ils son felle, auprA s de\n",
      "cette froide notre vain entendant d'une sa pension \n",
      "\n",
      "Iteration nb : 120\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3038\n",
      "+ Bruce i12tait un i12tonnant!  Direl\n",
      "1001. Cect bien l'on ne di12passera pas!  i12tre trouverons la sille est traversi12e de\n",
      "canica? demand\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3040\n",
      "Project Gutenberg volunteers and employees expend considerable\n",
      "effore hubelling of the work.  Disclabli12t maring, or distributing any (trea\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3009\n",
      "me paraisse d'un seul\n",
      "chemin de fer grisce, pour ne goAt plus que vous savez bientA,\n",
      "Swann?A\n",
      "--AMais les bals qui voient le faire disposait,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2988\n",
      "ks that can be\n",
      "freely distributed in machine reapable fee for access to ew or cherghints frontan\n",
      "site of this agreement voiles enveloppeas (\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.3018\n",
      "!  criait l'un de notre course.\n",
      "--Tu vous prends si je vous ai faite une admiration.\n",
      "--Est-ce qu'il y a quelques annAes, que j'aie envie Ave\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.3006\n",
      "Project Gutenberg-tm electronic work, you indicate that you have read, understand, agree to\n",
      "and accept all the terms of this license and int\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2995\n",
      "!  criait l'un des plus grands chagrins qui eussent AtA tenuA.\n",
      "--AMais non, ce n'est pas la peine de lui demander de venir, j'avais eu\n",
      "l'eau\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2987\n",
      "e saisir la corde de l'ancre,\n",
      "et d'ailleurs ils expi12raient son niveau\n",
      "ramena les interves artificiels d'une ouverture fri12quente.\n",
      "i12Eh b\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2978\n",
      "Hier sont\n",
      "incomparable pour si nouvellement que vous voulez qu'elle circulait\n",
      "vers lui-mAame, que le nombre clourit de notre markinalle et\n",
      "l\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2969\n",
      "Kernak, sa capitale.\n",
      "Le Victoria se trouvait par le tuyant vers le nord, et le\n",
      "plus ariti12 se laissait faire.  Hans et moi,\n",
      "nous verrons si\n",
      "\n",
      "Iteration nb : 130\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2969\n",
      "2 de di12couvrir cette\n",
      "traversi12e nourrit du but de la traversi12e d'un blessaste i12 notre nid, retenant\n",
      "la blessure du centre!\n",
      "--Huit cen\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2950\n",
      "$12 onze jolies d'icili12A melle magnifique et\n",
      "directe.\n",
      "Le lendemain, 27 Volurte maintenant non, je m'attendais i12 la\n",
      "dernii12re maison une\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2943\n",
      "9.\n",
      "1.E.3.  If an individual Project Gutenberg-tm electronic work is derived\n",
      "from the public domain (does not contain a notice indicating tha\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2935\n",
      "Qui s'est pas i12 ses mouvements.  Pour mon compte, je\n",
      "pri12occupaissais le bruit de la double caravane de Juelet, et ses i12li12mes\n",
      "s'aband\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2930\n",
      "3 below.\n",
      "1.F.\n",
      "1.F.1.  Project Gutenberg volunteers and employees expend considerable\n",
      "effort to identify, do copyright researc stribution of \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2925\n",
      "=ollaient chaque montre est bri12la\n",
      "i12 se pri12cipiter la traversi12e du feuil.\n",
      "XXXIX\n",
      "Pendant cette journi12e li12, s'i12cria le docteur.\n",
      "i\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2925\n",
      "s des bagages, l'un des\n",
      "principaux i12tinces, ils accoschi12rent i12 cette terre dont les obstacles\n",
      "instants pour entendre la ci12te occiden\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2908\n",
      "$12 onze jolies d'impatience.\n",
      "L'esprit sa destini12e suivait les chemins qui seraient arrivi12s i12 une ceinture\n",
      "racoeisse sur les rivages d\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2907\n",
      "t le plaisir que lui\n",
      "donnait la musique et qui allait bientA t crAer chez lui un vAritable\n",
      "besoin, retour au courant de la sainte provincial\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2898\n",
      "La calotte de l'i12le, oi12 le vide se fut debout de\n",
      "se trouver i12 son visage, les voyageurs i12taient les derniers ressautes\n",
      "sous la main,\n",
      "\n",
      "Iteration nb : 140\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2891\n",
      "501! _Kennedy y puis le mi12me?i12\n",
      "En compte plus beaucoup pour moi au moins d'en faire la voir des\n",
      "courantes.\n",
      "Pendant cette extri12me septe\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2884\n",
      "t pas de voui--joie. Je se tiennente de la bonne Marthe, ri12vitait Joe, se penchant au milieu de\n",
      "la chaleur et de la bouteille puissaient l\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2885\n",
      "+ Bruce i12tait un i12cossais dans tous les temps?\n",
      "Je compris toute la dimanche d'un volume, et mon imagination, singulii12r i12 son\n",
      "ballon \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2878\n",
      "Dick.\n",
      "--Et tu auras trouver la profession.--Une heure du matin, dit le\n",
      "jour de ri12souvre et j'espi12re qu'elle me donna une fixs et de ses \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2866\n",
      "z logique.\n",
      "i12Je suis donc condre, gui12re au terme le chasseur.\n",
      "--Viend, dit Kennedy, et ce serait une promenade plus audacieusement que no\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2860\n",
      " de la faAon la plus certaine que ma\n",
      "grand'tante avait eu une jeune de ces petites gens qui\n",
      "apparAent, s'il l'avait cuA res, les ours, de gr\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2843\n",
      "Une idi12e unique me dit que cela sortire que fit Hans.\n",
      "Tout il faut que je pronons si je n'y pas exi12cu entendu que ce\n",
      "point li12cheveur, \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2859\n",
      "ges qu'il avait achetAes tant de demander comme\n",
      "il s'exerce autrefois avec plus de plus belle, il regarda l'heure\n",
      "de la dAmanche. Je te le r\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2844\n",
      "*\n",
      "Sanvette, A  sa chambre, le boulet du vint de la guerre fAt de\n",
      "recourir il avait consolidi12 le dire: APeut-Aatre que c'est un peu\n",
      "facile!\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2865\n",
      "12 terre sans arrAater.  Mais\n",
      "que la foi de la tAate leur intention Atait fint rAcroyer en faisant A  la nuit\n",
      "du recevoir de la recrAe blanc\n",
      "\n",
      "Iteration nb : 150\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2846\n",
      "--Di12pi12che-toi donc de la descendre, ou tu vas nous faire manquer\n",
      "le train!i12\n",
      "Lutterain.\n",
      "Oi12 allons-mourize! i12 s'i12cria Joe.\n",
      "Kennedy\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2835\n",
      "XXIII\n",
      "                                                                                                                                      \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2818\n",
      "This and all associated files of Hurgemary disk ot or creating copy, add donations concerning the In the\n",
      "U.S do not agree to addathe a sol a\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2816\n",
      "e souvenir\n",
      "Swann reliait ces parcelles, abolissait les intervalant la raison un peu de\n",
      "sa personne A  qui Atait sa passion mue et leur vieil\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2809\n",
      "\u0019 Gutenberg-tm eBooks are often created from several printed\n",
      "editions, all of which are confir or Palinch now sottenth'law internationation\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2814\n",
      "qui nous l'avions\n",
      "derniA rement rencontrA, A  se rappeler, que de gravures et\n",
      "concectionnues de son amie. Ma coupAes par un coup de fumAe, u\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2812\n",
      "$12 en fait de chasser avec les bras de\n",
      "magi12rite, oi12 nous sommes magis, d'un air indiffi12rent de la si12rie particulii12re,\n",
      "ot, ri12pon\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2804\n",
      "\\ DIMITEDR BYIT YOU GATE OR THIT THERE THIS NEROENTE UN AS'ITAAER THIT BEFOANTICE XVI\n",
      "Ce s'Atait capable de sa place, mais du moins il n'y a\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2787\n",
      "This and all assofiement respectif (project Gutenberg-tm\n",
      "electronic works, harmless from all liability, costs and expenses, including legal\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2787\n",
      "This and all associated files of variosted.  Of the segon daws any a pear to  Project Gutenberg-tm\n",
      "Project Gutenberg-tm is synonymous with t\n",
      "\n",
      "Iteration nb : 160\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2773\n",
      "; il parait qu'il\n",
      "parvint sur une chaise, assez l'avoir conduit i12 ses\n",
      "sentiments pri12pautiques en accuet\n",
      "au-dessus deux lieues sur le tem\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2769\n",
      "Nous nous femme on nous souli12ve; il remarqua au\n",
      "moment le propre du gouffre et je remonte la bourgeoccident nous demeur compris entre la\n",
      "p\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2784\n",
      "6 fi12vrier 1823 i12 Kouka, pri12s du lac Tchadue de Juan Hillawa, vers\n",
      "le docteur Fergusson, Barthal.\n",
      "La mer voulona le conserver i12 cette\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2765\n",
      "; elle nous condoirait avec expredant du son, et\n",
      "soi, pour les peuvons mousses qui se pri12chait parfois d'avoir ossement\n",
      "i12gale i12 cent p\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2757\n",
      "?  demanda le major.\n",
      "--Je ne le pense pas, j'en ai engui le dernier dessinA!A mais il n'a rien\n",
      "d'extraordinaire, en pareille journir Mille c\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2755\n",
      "Je le suivis, et\n",
      "bienti12t le roi l'automne, celle de 12sai12chan a bien des animaux; on le manqua beanc;\n",
      "m'impossible.  C'est i12 peine si \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2728\n",
      "En effet, le\n",
      "meriage i12tait di12sordonni12 quadreli12e par de jours Borthode, di12collentera pour se\n",
      "monthoyoro, grosmissant des di12serts \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2763\n",
      "i12 l'extri12miti12 d'une ville.\n",
      "--Monsieur.--Peut-i12tre!  Mais on voulait donner le coeur\n",
      "du Niger remontation de M. Dicamps. On a massagn\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2734\n",
      "Et le docteur reconnut le filet bleu par le reste\n",
      "d'un bois arri12ti12 i12 un tableau. La chaleur soit par les fourrs, des\n",
      "indiffi12rentes, \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2762\n",
      "e souvenir\n",
      "Swann reliait ces parcelles, abolissait les intervalles, chauffes\n",
      "d'un sourire au Gun-Club, reste en prAsence dans une joie\n",
      "que c\n",
      "\n",
      "Iteration nb : 170\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2753\n",
      "Project Gutenberg volunteers and employees expend considerable\n",
      "effort to identify, do copyright research on, transcribe and proofread\n",
      "public\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2738\n",
      "Gutenberg-tm electronic works. Nearly all the individual\n",
      "works in the collection are in the public domain in the United\n",
      "States. If an indivi\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2729\n",
      "; elles me\n",
      "doublent une nuit que l'on juge avec un biblion et elle n'avait pas laissA le\n",
      "princer.\n",
      "Comme il at obisA, attentive en cela au or\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2735\n",
      "Oh! que c'est drA le qu'il aimait Odette!A C'est un plaisir d'entende que cela ne\n",
      "vouloyt pas trop tranquille A  M. de Foyerveule: c'Atait u\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2723\n",
      "4.  Except for the limited roges of refund settoncelle, viewed to the Project\n",
      "Gutenberg Literary Archive Foundation was created to provide a\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2728\n",
      "bien que cela ne se fatigue\n",
      "pas.  Mais aussi quelle villait laisser---et dire?A\n",
      "--ATu donc a suppopAtencA A  une antilope, un boulet au delA\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2716\n",
      ".  Mais, pour le bon ton le vent, qui nous di12sespi12rer\n",
      "dans ce temps.\n",
      "C'est lui va-t-il couru que la science absable quand il serait part\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2701\n",
      "@pagnons envolAes jouissants de la zuivre. On\n",
      "lui avait dit qu'elle en avait pu en voir une armAe en matinalisante. Peut-Aatre les\n",
      "torrents \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2708\n",
      ": AC'est la petite phrase de\n",
      "la science!  s'Atait enlevA Odette. La journAe sArade, nous enganterons de cette\n",
      "femme, il s'en fallait sous pr\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2707\n",
      "[Cinq cents\n",
      "kilogramment [Environ un rideau et vint trA s land du cAur de ma vie\n",
      "pourrait faire une maladie morale. Et dans le monde en rAal\n",
      "\n",
      "Iteration nb : 180\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2701\n",
      "________________________\n",
      "D'inconnu de\n",
      "ses montagns en 1886, s'aperi12us, et qu'il\n",
      "n'existait aucun inconnais me ramena les poids des montagn\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2697\n",
      "Project Gutenberg-tm electronic work is posted\n",
      "with the permission of the copyright holder, your use and distribution\n",
      "muscevan et employent \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2667\n",
      "; il\n",
      "parla absenter la plaine qui ne serait pas plus si12rieusement\n",
      "quand il entendit peu i12 peu autrefois le mot i12gale les eaux,\n",
      "nous li\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2685\n",
      "`de ce roc a encore, et j'ai du coir ma\n",
      "faiblialiste, non sans qu'elle leur approcuait, sur un Acar sentiment\n",
      "des cloches de forme, celles q\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2675\n",
      "Web sithe \"Phoje seas of habiting nap, you may obtain a refund in all 50  Zocah.\n",
      "                                                   XXI\n",
      "    \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2681\n",
      "\n",
      "--Non!  ri12pliqua fort la plus peindre?\n",
      "--Oui, certes il ne fallait pas pour me voir!\n",
      "--Voili12 un hardi sauvage, i12 mes animaux; or ta m\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2677\n",
      "[Cinq cents pieds envoyi12es oi12 s'i12tendent\n",
      "par des trois ours i12 leur vex\n",
      "sont pour sa fai12on le voyageur Diane, et comment il apparte\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2670\n",
      "'il ne jugeait pas seulement un projet si cruel\n",
      "qu'il n'avait pas vu la voiture A  rendre moi.  Ils n'avaient que cela A \n",
      "peise piA ge, elle\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2667\n",
      "Y OR BREACH OF CONTRACT EXCEPT THOSE\n",
      "PROVIDED IN PARAGRAPH 1.F.3.  YOU AGREE THAT THE FOUNDATION, THE\n",
      "TRADEMARK OWNER, AND ANY DISTRIBUTOR U\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2657\n",
      "Y OR FITNESS FOR ANY PURPOSERT\n",
      "BARLIITY OF TIS GIAPIIIVE IN LICHE FOUnE GINEBLITORO K LENNIS YOA  OR MINTEDE FULE PIVENSE\n",
      "I1BERRE philase af\n",
      "\n",
      "Iteration nb : 190\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2661\n",
      "Vingt elle lui avait dit avoir fait de ses notes\n",
      "que les plus mires de ses gardans goAts et la situation\n",
      "A  ce que nous avait vu une de cett\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2656\n",
      "Une idi12e unique me domina.\n",
      "i12 L'i12le de Zanzibar sont presque i12 l'hi12tel du Paille; au milieu de cette\n",
      "musture, tu ne seras pas, Dick\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2649\n",
      "faire partie; elle publie des\n",
      "enfants l'extri12miti12 de l'Usadeur. La mi12me service se\n",
      "promi12tre entre les cinq parties du port ne pouvai\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2644\n",
      "\u0019 Swann nous avancons, ce\n",
      "que j'ai envie d'entendre A  qui jamais vous promener des Acroses\n",
      "Carcles, et que la lumiA re allait revenir A  la\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2636\n",
      "(et quand il croyait cette proposition du soir, ou\n",
      "quand on vout fait rentrer dans sa grAce et de se trouver ni le\n",
      "plaisir au bon distribu. \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2632\n",
      "les pommits parfaitement inutiles, et pour causer des\n",
      "Alanations de tableaux qu'avaient un peu le priver que je pensais que ce fut la\n",
      "saveur\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2629\n",
      "?  Par un part une compagne.A\n",
      "--ACe n'est pas de la garde de notre retour.  Celui des sons sans\n",
      "descriptions supArieurs.\n",
      "Il n'en rassa qu'au\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2627\n",
      "6 D0 CF C5_BC_    _Chibe de langers.  Il avait laissA faire au contraire jusqu'A  ma\n",
      "tente; ce ne fAt nous eux chassA sont sur la place, qua\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2614\n",
      "829, il remontait,\n",
      "en compagnon de neige sur la gri12ve bouillonientie de capicaine et une ville\n",
      "approvisionnelle par le docteur, et auquel \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2604\n",
      "$12 onze jolies gou; ils\n",
      "permit d'aplomi12e par 1.12.02  Ici 18,00, le Sneffels Royallet, Bejoter, Lamgrer,\n",
      "l'Hefais, peut-i12tre peut-i12tr\n",
      "\n",
      "Iteration nb : 200\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2622\n",
      "without paying any part fort, including obsolete\n",
      "aser of compre, de Mo. simple ascension A  la vue de MM.\n",
      "Michelline a coutageur, de nos ado\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2618\n",
      "\\ DIMITCOTER BREACH OF WARRANTY OR BREACH OF CONTRACT EXCEPT THOSE\n",
      "PROVIDED IN PARAGRAPH 1.F.3. YOU AGREE THIS YON RETINT OF REMTIBE DE L'IT\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2612\n",
      "par tout le\n",
      "monde sans en avant.\n",
      "A midi la Aglive soir et le sang-fort A  sa maniA re en quelqu'un chez\n",
      "Castude davantait-il comprendre qu'i\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2575\n",
      ": ACe n'est pas comme dit A  me livrer, sans\n",
      "avis un champ de joue.--Il l'emmA re de vous.\n",
      "--Pour trop loin, voici les petites roses auxquem\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2608\n",
      " de ses amis, mais dont l'autre!\n",
      "Et en effet, le seul fie ratoinent autour de lui; arrivi12e i12 la\n",
      "duri12e par une nature.\n",
      "Le silence se fa\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2603\n",
      "Un or Sneffels, applicable\n",
      "pendant lesquelles elle garde la poussii12re frani12aise, de plus de cristallisses\n",
      "l'on but de bien, un pet pouve\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2601\n",
      "$12 en face assez.; alors, il faut tenti12 le\n",
      "traverser. Le ballon, peu i12 peu venait au fond i12 l'apri12s des lumii12res ou\n",
      "les classins \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2586\n",
      "* PGojEDEt therencary dans le sud, ici comment elle variAe effective, car ce bruit y avait reAu chercher la\n",
      "connaissance d'une caisse de nom\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2592\n",
      "\u0019 Samuel Fergusson. De l'attel huit donc sa\n",
      "position noirmance que ma vie lui en vienne perdre quelque\n",
      "major, de la promenade dans une maiso\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2592\n",
      "ves; de la glaise\n",
      "outre quelque cuirbulsiti12 au-dessus des nots i12 nouveau dans les airs.\n",
      "Receurl aujourd'hui appartenant une dizaine de m\n",
      "\n",
      "Iteration nb : 210\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2592\n",
      "9.\n",
      "1.E.3.  If an individual Project Gutenberg-tm electronic work withen wh  agree to you diginat\n",
      "with of theig Boowace ettre agotte quodide \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2586\n",
      "jours. Malheureusement, il inclinait encore plus amas sur un\n",
      "livre, quelque forme d'undimet de mon esprit se restA rent en Allemagne, pour\n",
      "n\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2586\n",
      "+ Samuel nous aimeit aussi\n",
      "intelligente. Je les vois alors, en reblettant, telles elles semblaient rApondre dans notre\n",
      "personnelle qu'elle n\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2587\n",
      "Oh! pas avant midi, rApondait ma tante d'un bAtet, il rAsistant ses\n",
      "regards de la robe de sa fAmAe, comme on persait dans le castoca, qui\n",
      "l'\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2559\n",
      "?  Par un biscue indeucianx.  A cent\n",
      "pas de la mi12moire celle de l'oncle qui s'aventionnait i12 la surface\n",
      "d'une chaleur plus fouctionnelle\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2538\n",
      "Je ne sais pas penser, qu'il\n",
      "est plus purement simple dont je ne sais rien de tout camarade. Elle aimait\n",
      "la maAtresse quatre-vingt-quatre li\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2568\n",
      "je vous dis que je ne veux pas trop comprendre notre place dans la langue des gestes.\n",
      "AprA s la question sous la MontagneureA, je cherchais \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2560\n",
      "bien percevoir si je pris en coAtenter les membres du Gun-Club, avant\n",
      "des relaines le capitaines fermAes en rangAes-l'A -jadaises\n",
      "expirient \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2561\n",
      "Et le ciel et les quelques balles d'actions\n",
      "laissaient voir l'Atudes sensibles en quatre centres\n",
      "qu'A  la voix de Swann?A\n",
      "dit-elle A  Tampa-\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2556\n",
      "; il ne faut pas perdre une pareille\n",
      "occasion. i12 Le docteur chercha du duc, le chef de Londement, Champ un\n",
      "professeur de gymnastien, d'aut\n",
      "\n",
      "Iteration nb : 220\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2550\n",
      "12tang,\n",
      "dans cette vaste i12tendue de pays de coutil de l'Islande, cette ti12ne,\n",
      "puisque voulait-il empi12chors de ses yeux.\n",
      "--Oh!  cela me \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2547\n",
      "========\n",
      "Kennedy; je n'aimais pas i12 peine si je puis admet sel comptant.\n",
      "La chemini12e d'un ennemi retarde, il avait l'air de\n",
      "tenter deux \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2544\n",
      ": AC'est la petite phrase de\n",
      "la sonate de Vinceville, descendront A  un ami de cinquii12me, dans lequel\n",
      "se trouvaient aupri12s de lui.\n",
      "i12 C\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2531\n",
      "Bade jusqu'A  six cent quarante-deux milles [Cinq cent\n",
      "dix mille deux cent cinquante livres.  Quatre milles et descendu\n",
      "fugette de ces seule\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2554\n",
      "Bah! Monsieur, il ne voulait mAame pas avant que j'avais tort\n",
      "d'un ton mari avant les arceaux et bombA rent tout A  coup, j'avais encore jus\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2549\n",
      " de la visite, ils Ataient touchAs\n",
      "par la gale dans laquelle on savait qu'il faisait admirer un rivage de\n",
      "cet amour, qui l'avait retirAs, et\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2512\n",
      "pas au dongait, son apparition souterait sa main sArA, Atait loin\n",
      "la messe auraite dans le parc du puits et oA1 il fallait d'Aatre longue\n",
      "qu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2547\n",
      "Je n'avais pas fait cent pas que des pensAes se rAvA lent le temps\n",
      "qu'il s'agissait de choisir une haute montagne, si pressant leurs apprend\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2541\n",
      "RIBUTOR UNDER THIS AGREEMENT WILL NOT BE\n",
      "LIABLE TO YOU FOR ACTUAL, DIRECT, INDIRECT, CONSEQUENTIAL, PUNITIVE OR\n",
      "INCIDENTAL DAMAGES EVEN IF Y\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2533\n",
      "t pas ici que\n",
      "je ne laisse pouvoyaient provisionnement, saisissait en mot.  Ne faisant\n",
      "que cela n'aurait jamais dissiptant cette petite forc\n",
      "\n",
      "Iteration nb : 230\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2532\n",
      "[Cinq cents\n",
      "kilogrammes.]) quelques morceaux par eux-mAames qu'une fois\n",
      "finires que tout avais AtA dix fois, ni par la Lune sans avoir\n",
      "jamai\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2537\n",
      "me des travaux, des choses nouvelles, ne trouveraient pas en elle certainement j'avais une\n",
      "parfaite aimable.\n",
      "Cer esprit se voilait beaucoup \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2528\n",
      "e de se faire Apouser par lui),--cette amitation pour faire\n",
      "une complicitA au linvre qu'elle avait des hommes lui mAame plus indirectement\n",
      "p\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2518\n",
      "it comme quatre; mais le\n",
      "stelle i12tait parvenu i12 une hauteur de quatre\n",
      "mille pieds. Je n'avais pas calculant de s'oblire.  Seulement, i12\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2515\n",
      "* Swann n'est pas mAame de la peine A  apprendre\n",
      "que cela lui plaAt, lui apprendre qu'elle ne possAdait pas selon\n",
      "les regrets pour lequel jo\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2526\n",
      "Quant aux\n",
      "personnalitAs polaires, qui s'Ataient amenAus A  elle; c'est\n",
      "que n'avait AtA passA et que s'il ne l'avait pas anAantueA en voyant \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2500\n",
      "4.  Except for the ligte for atats you copyin or cies of\n",
      "P  work an Confroyable future and the Foundation is comted to\n",
      "of the Project Gutenb\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2526\n",
      "s de ses deux compagnons l'imaginaises,\n",
      "s'enflammait au souffle de la tente; celle qui s'ouvrit l'aspect et se\n",
      "produisit dans les ruches, et\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2487\n",
      "ks based on this work or any\n",
      "other Project Gutenberg-tm work. The Foundation was le terms of this foraty mission of le fel\n",
      "isoledy in Swann \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2508\n",
      "6 fi12vrier des phasailes de lave\n",
      "jette quel ondwli12ge prenait la vi12gi12tation exacte du volcan, et cela ne\n",
      "l'eau pas mystArieux i12 la l\n",
      "\n",
      "Iteration nb : 240\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2500\n",
      "with the terms of this agreement by keeping\n",
      "thalage ager and les refusedond\n",
      "whareusy by Jeective you can do with Project Gutenberg-tm electr\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2507\n",
      "Y OR FITNESS FOR ANY PURPOSE.\n",
      "1.F.5.  Some states do not allow disclaimers of deriva in the United States without paying any fees\n",
      "or charges\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2503\n",
      "!  criait l'un de ces\n",
      "caractA res affaiblirants l'avantaire, et il avait A  faire, avait sautA\n",
      "d'une siffinule A  laquelle illus ou trop lon\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2494\n",
      "Web site includes information about Project Gutenberg-tm,\n",
      "including how to make donations to the Project Gutenberg Literary\n",
      "Archive Foundati\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2478\n",
      "--AMadame Octave, je veux dire.\n",
      "Tiens, en Sandons, couvert du nAanme en prodigant des oraces.\n",
      "Joe se glissa peu de chemis, mais le vent souf\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2496\n",
      "me et A  lui reprAsenter son pA re par le projectile, des\n",
      "jardiniers aime autour d'eux rAuns ou A  Saint-Marc qui avait-il dit qu'A  exAcute\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2489\n",
      "Foundation is committuduatikes.  If you are redistributing or providing access to a work\n",
      "with the phrade danaine wheka. Sans to ferents notr\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2487\n",
      "Oh! que c'est drA le! Vous avez donnA sa fille, A  peine si ce\n",
      "n'Atait pas tout A  fait encore superbe?\n",
      "--Ma dotte, du secouds, le perce mAa\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2490\n",
      "(et presque autant que pour Odette, comme il avait\n",
      "l'habitude de comprendre le sens que je consultai naturellement en des\n",
      "gens pour mon four\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2473\n",
      "journaux de l'Union\n",
      "cAlAbraient avec une personne pour vers une certaine attente d'oiseaux dont le modA le faut avec un\n",
      "air un mot la pluie.\n",
      "\n",
      "Iteration nb : 250\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2478\n",
      "Nous nous rencontrions.\n",
      "i12J'y pensais,i12 dit mon oncle.\n",
      "Je porte le di12ner de la porte vingt-cloire que nous presions\n",
      "avoir de me transpo\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2476\n",
      "de son\n",
      "i12vi12nement.\n",
      "Le radeau demeura absolument accentu.  En centre un fils, au moment\n",
      "oi12 le roc fi12cri12le, mais aussi de veinterie e\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2459\n",
      "\n",
      "--Li12aba, i12 deux mois de plus grande espace.\n",
      "--C'est convenu. i12\n",
      "Les conversations du bi12t mi12ne i12loigni12e de ma tante ne savaient\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2471\n",
      "Project Gutenberg Literary Archive Foundation\n",
      "The Project Gutenberg Literary Archive Foundation and Michael\n",
      "Hart, the owner of the Project G\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2465\n",
      "+ Bruce i12 l'eau du Hanze-bien\n",
      "prononAAs de l'aprA s-midi, la Lune, les obusiers du violont, leur tour de moyense Atait\n",
      "agrAe, d'une immens\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2464\n",
      "on exacte de son propre voyage;\n",
      "il offrit alors ses services au gouvernement pour compli12ter la\n",
      "reconnai12tre, et j'ai eu le temps\n",
      "de me re\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2458\n",
      "z pur mille;\n",
      "mais, hi12sitaines, Samuel!\n",
      "--Tri12s racotte, fit Kennedy.\n",
      "--Une idi12pie donc!  dit Joe l'espace.\n",
      "--Soit chercherait jamais un\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2450\n",
      "3 below.\n",
      "1.F.\n",
      "The Project Gutenberg Literary Archive Foundation (\"the Foundation\"\n",
      "or PGLAF), owns a compilation copyright in the collection \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2453\n",
      "Il ne dit rien, mais immobile; la vie\n",
      "je ne surprivenai pas la maison de Ki12nig-strasse; mais, enfin le brave galorie\n",
      "de Hans, qui, sans do\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2453\n",
      "Mais quel phi12nomi12ne a pu\n",
      "ce qu'il s'agit. Joe ne pouvait plus faire i12re, ti12me n'arrii12ra i12 la\n",
      "duchesse, et sans se donner la mesu\n",
      "\n",
      "Iteration nb : 260\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2458\n",
      "Nous sommes glaci12s d'effroi; la boule mi-partie blanche,\n",
      "mysti12rieuse, avait le moyen de mettre le feu i12 la doute, on a\n",
      "des i12lever le\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2449\n",
      "9.\n",
      "1.E.3.  If an individual Project Gutenberg-tm electronic work is posted\n",
      "with the permission of the copyright holder.  Information on\n",
      "the \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2448\n",
      "% Zambourg en 1838, charger les chocodifs, ne\n",
      "demandant i12 mort.  Mais le duc de Palliano avait impossi12 le cap Portler. La\n",
      "destination at\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2439\n",
      "541.  Its 501(AM3 F RAnA, Phine with\n",
      "F You y a restrer, with orlect in the United States without paying any fees\n",
      "or charges.  If you are red\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2436\n",
      "e de renouveli12 que nous sommes aimables, sans se gi12ner\n",
      "d'allerir l'i12norme que je venais donc moins i12 quelques testes eurours.i12\n",
      "Je \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2438\n",
      "Project Gutenberg Literary Archive Foundation is a non profit\n",
      "501(c)(3) educational corporateur or the provided agreed will and fective op t\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2431\n",
      "Et si Swann lui demandait ces premiers architectes\n",
      "et maAin, comme Atait la garna-derviA re vers le nord des bien avec\n",
      "mAame que l'homme se \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2423\n",
      "Vingt fois Joe i12 en possible.\n",
      "A nous deux, on reste en mouvel dans la rayenei12 de quelque Martour\n",
      "de Joe, Hans, nous revenir-tions avec p\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2430\n",
      " de la vie de son\n",
      "appareil d'oportane et d'une boule d'entraAner A  mon mouvre quand\n",
      "nous arrivions rue Saint-Simon qui ne sont pas donnAs p\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2427\n",
      "que je me souciasse de la continuitA,\n",
      "l'impression laissAe entre les raisonnements des autres pareils qu'elle avait\n",
      "rencontrA chez elle: Aje\n",
      "\n",
      "Iteration nb : 270\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2429\n",
      "________________________\n",
      "Di12sir au pair\n",
      "perdestive dans la galerie\n",
      "de Hans, qui, sans l'un sertimenter entii12rement di12pourvu de\n",
      "grandes \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2423\n",
      "*\n",
      "Samuel, nous marchons sans doute! tu en faisais le gari12cent pour regagner le\n",
      "pari12on.\n",
      "i12tait ce coheril, ce nuage naissant, j'avais be\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2424\n",
      "vait l'Atendue de la campagne pour laquelle il eAt\n",
      "jamais connues toute seule en ce tenant:\n",
      "--AMais je ne vois pas qu'on cAur parfaitement l\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2416\n",
      "vant aussi mieux que le temps\n",
      "je l'avais prim, il Atait curieux de l'hosi tompait fini, et mit qu'ils n'avaient guA re\n",
      "personne en instant a\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2412\n",
      ", et un reste d'espoir me revint au coeur.\n",
      "Voici pourquoi.\n",
      "Des trois routes ouvertes sous nos pas, un puits, embarquaient\n",
      "ses flancs, ce vil\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2412\n",
      "x cents toises, une\n",
      "main principalement de la chambre mAame de Swann, bien que tout autres annAgeants et\n",
      "mApariant) qui la consolerons, le m\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2417\n",
      "7. Norreh nourcherronin a refustibe long (project Gutenberg-tm\n",
      "electronic works, and the medium on which they may be stored, may contain\n",
      "\"De\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2408\n",
      "z purement\n",
      "muse de cabines de mille peuvent, qui n'Atait pas descendu avec\n",
      "l'emportument duquel appelant leur visage tout en son\n",
      "monde et re\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2411\n",
      "ait de se di12plumer i12 son tour.\n",
      "De haut en bullon, craque si heureux chose-li12 gomme\n",
      "foudait dans un serpenti12, i12 la vule\n",
      "par ses i12\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2397\n",
      "YOU HAVE NO REMEDIES FOR NEGLIGENCE CRECS COMATRIES THE PROVICANGIS\n",
      " BUTRADEN, OR, MENT BE  YOU JE MERTRE FUR NOT GULE\n",
      "ProJeCTY UNE PUUDIL\n",
      " \n",
      "\n",
      "Iteration nb : 280\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2382\n",
      "works\n",
      "1.A. By reading or ustins and distribution of Project Gutenberg-tm\n",
      "electronic works, harmless from all liability, costs and expenses, \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2394\n",
      "ce moment-lA  encore\n",
      "cette faiblesse de ces boutons de cinq milliors, cette\n",
      "poussiA re, le sentiment qu'il avait donnA une substance rien de\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2403\n",
      "9.\n",
      "1.E.3.  If an indivaled access to alemany.\n",
      "The foe future and appratications wank enlevant all refective the work from.  If you\n",
      "received \n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2404\n",
      "% Zambourg insembleit de la baie du ci12ne\n",
      "commencemant, et de la salle, du Ny heverd et l'ome en\n",
      "aimant l'air versonne.  Cela fait quelques\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "90s - loss: 0.2393\n",
      "Bade jusqu'A  six cents pieds dans le ciel! ri12pondit le\n",
      "docteur i12 six mille pieds.\n",
      "Enfin, apri12s avoir essayais de reconserver la mort,\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2396\n",
      "), la nextite tensue au-dessus des flots\n",
      "matinamment, sans en avoir jamais pu Aatre exprimAe par son visage et doux de notre\n",
      "tempAratures qu\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "91s - loss: 0.2401\n",
      "ait les gestes, une bouchie mication\n",
      "en respirant les Arabes, et quelques mA tres, devaient aller invisible\n",
      "bien nette la mAame et balbe les\n",
      "\n",
      "--------------------\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c2b41a0a4ac7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mbla\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGENERATE_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#batch size equals to seq length here\n",
    "BATCH_SIZE=100\n",
    "#len of desired output\n",
    "GENERATE_LENGTH=140\n",
    "DIR=out_path+\"weights/weight_attempt_s03_2/\"\n",
    "flag=True\n",
    "\n",
    "try:\n",
    "    onlyfiles = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "    iteration=[]\n",
    "    for files in onlyfiles:\n",
    "        iteration.append(int(get_iternb(files)))\n",
    "    iteration=max(iteration)\n",
    "\n",
    "    last_checkpoint=DIR+onlyfiles[0][0:21]+str(iteration)+'.hdf5'\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    onlyfiles=[]\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "    nb_files=0\n",
    "\n",
    "if nb_files>0:\n",
    "    model.load_weights(last_checkpoint)\n",
    "else:\n",
    "    iteration=0\n",
    "    \n",
    "print(\"Starting at iteration : %s\" %iteration)\n",
    "while flag==True:\n",
    "    print('\\n')\n",
    "    print('-'*20)\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, verbose=2, nb_epoch=1)\n",
    "    iteration += 1\n",
    "    bla=generate_text(model, GENERATE_LENGTH,VOCAB_SIZE, indices_char)\n",
    "    if iteration % 10 == 0:\n",
    "        print(\"\\n\\nIteration nb : %s\" %iteration)\n",
    "        #api.PostUpdate(status=bla[0:123])\n",
    "        model.save_weights(DIR+'checkpoint_{}_epoch_{}.hdf5'.format(HIDDEN_DIM, iteration))\n",
    "        #remove unecessary files:\n",
    "        for files in onlyfiles:\n",
    "            try:\n",
    "                if files:\n",
    "                    os.remove(DIR+files)\n",
    "            except:\n",
    "                pass\n",
    "        onlyfiles = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "\n",
    "    if iteration>=900:\n",
    "        print(\"Stopping...\")\n",
    "        flag=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Generate text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    if not os.path.exists(out_path+\"generate/\"):\n",
    "        os.makedirs(out_path+\"generate/\")\n",
    "    with open(out_path+\"generate/output.txt\",\"w\") as f:\n",
    "        f.write(('').join(y_char))\n",
    "    return ('').join(y_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seed with particular text:\n",
    "def generate_text_seeded(model,seed,length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    # char_indices\n",
    "    ix = [char_indices[x] for x in seed]\n",
    "    y_char = [x for x in seed]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(len(ix)) :\n",
    "        X[0, i, :][ix[i]] = 1\n",
    "        print(ix_to_char[ix[i]], end=\"\")\n",
    "    to_substract = len(ix)\n",
    "    for i in range(length-to_substract):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generate_text_seeded(model,normalize('NFKD',\"le chien \".decode('latin1')), 1000, VOCAB_SIZE, indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "out = save_text(model, 1500, VOCAB_SIZE, indices_char)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
