{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os, os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import urllib2\n",
    "import time\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw \n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Credentials\n",
    "api = twitter.Api(consumer_key='LyNVanTEQEOEGKfXAMeLv6AKG',\n",
    "                    consumer_secret='0lJvhaaOP5cRZWm6rxwyBIAypd1P7eiDx9f74KBDlLrSldNuBQ',\n",
    "                    access_token_key='855852332034265088-geTEVmA7xIsOD3WCZyfBNnqjRdS1MhW',\n",
    "                    access_token_secret='kJMwMl67e3nYrqaGWzIizxzQpRZhtBfOnwPflO1fk3cOt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Bot sniffing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# api.GetReplies(count=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# api.GetUserTimeline(exclude_replies=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get latest message\n",
    "timeline=api.GetHomeTimeline(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if timeline[1].user.screen_name!=u'TheTalkativeBot' and timeline[1].media:\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timeline(count):\n",
    "    timeline=api.GetHomeTimeline(count=count)\n",
    "    return timeline\n",
    "\n",
    "\n",
    "def get_media_reply(timeline, last=True):\n",
    "    for statuses in timeline:\n",
    "        if statuses.media and statuses.user.screen_name!=u'TheTalkativeBot':\n",
    "            index=statuses.id\n",
    "            user_name=statuses.user.screen_name\n",
    "            media_url=statuses.media[0].media_url\n",
    "            status_text=statuses.text\n",
    "            if last==True:\n",
    "                break\n",
    "    return index,user_name,media_url,status_text\n",
    "\n",
    "def save_media(media_url):\n",
    "    DIR=\"images/\"\n",
    "    try:\n",
    "        onlyfiles = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n",
    "        nb_files = len(onlyfiles)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        if not os.path.exists(DIR):\n",
    "            os.makedirs(DIR)\n",
    "        nb_files=0\n",
    "    img = urllib2.urlopen(media_url)\n",
    "        \n",
    "    with open(\"images/%s.jpg\" %(nb_files+1), 'wb') as f:\n",
    "        f.write(img.read())\n",
    "    img=mpimg.imread(\"images/%s.jpg\" %(nb_files+1))    \n",
    "    plt.imshow(img)\n",
    "    return"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#to send mail\n",
    "api.PostDirectMessage(\"De rien\",screen_name=\"dvp_tran\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Post media"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "api.PostMedia(status, media, possibly_sensitive=None, in_reply_to_status_id=None, latitude=None, longitude=None, place_id=None, display_coordinates=False)[source]\n",
    "Post a twitter status message from the user with a picture attached.\n",
    "\n",
    "Parameters:\t\n",
    "status – the text of your update\n",
    "media – This can be the location of media(PNG, JPG, GIF) on the local file system or at an HTTP URL, it can also be a file-like object\n",
    "possibly_sensitive – set true if content is “advanced.” [Optional]\n",
    "in_reply_to_status_id – ID of a status that this is in reply to. [Optional]\n",
    "lat – latitude of location. [Optional]\n",
    "long – longitude of location. [Optional]\n",
    "place_id – A place in the world identified by a Twitter place ID. [Optional]\n",
    "display_coordinates – Set true if you want to display coordinates. [Optional]\n",
    "Returns – A twitter.Status instance representing the message posted."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#to send mail\n",
    "api.PostDirectMessage(\"De rien\",screen_name=\"dvp_tran\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def auto_answer():\n",
    "    flag=True\n",
    "    i=0\n",
    "    while flag==True:\n",
    "        try:\n",
    "            time.sleep(10)\n",
    "            print(\"Iteration : %s\" %i)\n",
    "            timeline=get_timeline(3)\n",
    "            status_id,user,media_url,status_text = get_media_reply(timeline,last=True)\n",
    "            if not os.path.exists('images/list/'):\n",
    "                os.makedirs('images/list/')\n",
    "            with open('images/list/list.txt','r') as f:\n",
    "                text = f.read()\n",
    "            text=text.split(\"\\n\")\n",
    "\n",
    "            if media_url not in text:\n",
    "                with open('images/list/list.txt', \"a\") as f:\n",
    "                    f.write(media_url+\"\\n\")\n",
    "                save_media(media_url)\n",
    "                api.PostUpdate(\"Automamte answer 2 !\", media=None, media_additional_owners=None, media_category=None,\n",
    "                   in_reply_to_status_id=status_id, auto_populate_reply_metadata=True,\n",
    "                   exclude_reply_user_ids=None, latitude=None, longitude=None, place_id=None,\n",
    "                   display_coordinates=False, trim_user=False, verify_status_length=True, attachment_url=None)\n",
    "                print(\"Status id : %s, answered.\" %status_id)\n",
    "            \n",
    "                time.sleep(60)\n",
    "            i=i+1\n",
    "            if i==25:\n",
    "                flag=False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            if \"Rate limit exceeded\" in str(e):\n",
    "                print(\"Sleeping  because of rate limit.\")\n",
    "                time.sleep(60)\n",
    "                print(\"Restarting\")\n",
    "                \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# auto_answer()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Answering to a post\n",
    "api.PostUpdate(\"Thanks !\", media=None, media_additional_owners=None, media_category=None,\n",
    "               in_reply_to_status_id=856439298903732224, auto_populate_reply_metadata=True,\n",
    "               exclude_reply_user_ids=None, latitude=None, longitude=None, place_id=None,\n",
    "               display_coordinates=False, trim_user=False, verify_status_length=True, attachment_url=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Create picture to send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = Image.open(\"images/1.jpg\")\n",
    "draw = ImageDraw.Draw(img)\n",
    "font = ImageFont.truetype(\"font/Tangerine_Regular.ttf\", 56)\n",
    "# draw.text((x, y),\"Sample Text\",(r,g,b))\n",
    "draw.text((0, 0),\"Woof woof wooof <3\",(255,255,255),font=font)\n",
    "img.save('output/sample-out.jpg')\n",
    "\n",
    "img=mpimg.imread(\"output/sample-out.jpg\")    \n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = Image.open(\"images/Feeling-Grey.jpg\")\n",
    "size = 600, 600\n",
    "text =\"Woof woof wooof  Woof woof wooof <3 Woof woof wooof  hehehehehe\"*10\n",
    "text=textwrap.wrap(text, width=50)\n",
    "\n",
    "try:\n",
    "    img.thumbnail(size, Image.ANTIALIAS)\n",
    "except IOError:\n",
    "    print \"cannot create thumbnail for '%s'\" % infile\n",
    "\n",
    "img_w, img_h = img.size\n",
    "background = Image.new('RGBA', (900, 1200), (255, 255, 255, 255))\n",
    "bg_w, bg_h = background.size\n",
    "offset = ((bg_w - img_w) / 2, (bg_h - img_h) / 6)\n",
    "background.paste(img, offset)\n",
    "draw = ImageDraw.Draw(background)\n",
    "font = ImageFont.truetype(\"font/SpecialElite.ttf\", 30)\n",
    "# draw.text((x, y),\"Sample Text\",(r,g,b))\n",
    "offset_=0\n",
    "for line in text:\n",
    "    w, h = draw.textsize(line, font=font)\n",
    "    draw.text(((900-w)/2, 650+offset_),line,(0,0,0),font=font)\n",
    "    offset_ += h+5\n",
    "\n",
    "background.save(\"output/sample-out.jpg\")\n",
    "\n",
    "img=mpimg.imread(\"output/sample-out.jpg\")    \n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_answer(file_,text_input):\n",
    "    file_name=file_\n",
    "    img = Image.open(\"images/\"+file_name)\n",
    "    size = 600, 600\n",
    "    text = text_input\n",
    "    text=textwrap.wrap(text, width=50)\n",
    "\n",
    "    try:\n",
    "        img.thumbnail(size, Image.ANTIALIAS)\n",
    "    except IOError:\n",
    "        print \"cannot create thumbnail for '%s'\" % infile\n",
    "\n",
    "    img_w, img_h = img.size\n",
    "    background = Image.new('RGBA', (900, 1200), (255, 255, 255, 255))\n",
    "    bg_w, bg_h = background.size\n",
    "    offset = ((bg_w - img_w) / 2, (bg_h - img_h) / 6)\n",
    "    background.paste(img, offset)\n",
    "    draw = ImageDraw.Draw(background)\n",
    "    font = ImageFont.truetype(\"font/SpecialElite.ttf\", 30)\n",
    "    # draw.text((x, y),\"Sample Text\",(r,g,b))\n",
    "    offset_=0\n",
    "    for line in text:\n",
    "        w, h = draw.textsize(line, font=font)\n",
    "        draw.text(((900-w)/2, 650+offset_),line,(0,0,0),font=font)\n",
    "        offset_ += h+5\n",
    "\n",
    "    background.save(\"output/\"+file_name)\n",
    "    print(\"Done drawing answer!\")\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def post_media(text_answer,media_path,post_id):\n",
    "    api.PostUpdate(\"Here what's your picture evokes to me !\",\n",
    "                media=media_path, media_additional_owners=None,media_category=None,\n",
    "               in_reply_to_status_id=post_id, auto_populate_reply_metadata=True,\n",
    "               exclude_reply_user_ids=None, latitude=None, longitude=None, place_id=None,\n",
    "               display_coordinates=False, trim_user=False, verify_status_length=True, attachment_url=None)\n",
    "    print(\"Answer sent!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Generate text from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 87 and 91 for 'Assign' (op: 'Assign') with input shapes: [87,2000], [91,2000].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4d7ef51612d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgenerate_from_image\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0menglish_lstm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/paul/Git_Repository/Data_Science/ENSAE/Projet_Python/LSTM/04-twitter_bot/english_lstm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#loading learned parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   2911\u001b[0m                              ' elements.')\n\u001b[1;32m   2912\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2913\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2020\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[1;32m   2021\u001b[0m                                                     shape=value.shape)\n\u001b[0;32m-> 2022\u001b[0;31m                 \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2023\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2024\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.pyc\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking)\u001b[0m\n\u001b[1;32m    520\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \"\"\"\n\u001b[0;32m--> 522\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.pyc\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     45\u001b[0m   result = _op_def_lib.apply_op(\"Assign\", ref=ref, value=value,\n\u001b[1;32m     46\u001b[0m                                 \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                                 use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    761\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    762\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2327\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2329\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2330\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2331\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1715\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 87 and 91 for 'Assign' (op: 'Assign') with input shapes: [87,2000], [91,2000]."
     ]
    }
   ],
   "source": [
    "from generate_from_image import *\n",
    "from english_lstm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blabla = test(sess,image,generated_words,ixtoword, \"images/1.jpg\")\n",
    "print(blabla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blabla=generate_text_seeded(model,normalize('NFKD',blabla.decode('latin1')), 1000, VOCAB_SIZE, indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw_answer(\"images/1.jpg\",blabla)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "draw_answer('1.jpg',\"blahbalhaakzepokapzoekpakezpoakzepokazepokzpekopoekapoekza\")\n",
    "post_media('azejpaozkkepoazkepookazzpekpazkepoakzepkazpoekpazkepazkepazke âzkeazeazêkazeja poazeopazkekazkne ',\n",
    "          \"output/1.jpg\",856894659007844352)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
